DEBUG:root:[ Iteration 0 ] Training loss: 0.173617
DEBUG:root:[ Iteration 0 ] Test loss: 0.167575
DEBUG:root:[ Iteration 3 ] Training loss: 0.171808
DEBUG:root:[ Iteration 6 ] Training loss: 0.157945
DEBUG:root:[ Iteration 9 ] Training loss: 0.155951
DEBUG:root:[ Iteration 12 ] Training loss: 0.178033
DEBUG:root:[ Iteration 15 ] Training loss: 0.161198
DEBUG:root:[ Iteration 18 ] Training loss: 0.169006
DEBUG:root:[ Iteration 20 ] Test loss: 0.164082
DEBUG:root:[ Iteration 21 ] Training loss: 0.151584
DEBUG:root:[ Iteration 24 ] Training loss: 0.162811
DEBUG:root:[ Iteration 27 ] Training loss: 0.16577
DEBUG:root:[ Iteration 30 ] Training loss: 0.169345
DEBUG:root:[ Iteration 33 ] Training loss: 0.162159
DEBUG:root:[ Iteration 36 ] Training loss: 0.161171
DEBUG:root:[ Iteration 39 ] Training loss: 0.160031
DEBUG:root:[ Iteration 40 ] Test loss: 0.160344
DEBUG:root:[ Iteration 42 ] Training loss: 0.158838
DEBUG:root:[ Iteration 45 ] Training loss: 0.174164
DEBUG:root:[ Iteration 48 ] Training loss: 0.156974
DEBUG:root:[ Iteration 51 ] Training loss: 0.17087
DEBUG:root:[ Iteration 54 ] Training loss: 0.162857
DEBUG:root:[ Iteration 57 ] Training loss: 0.156162
DEBUG:root:[ Iteration 60 ] Training loss: 0.148666
DEBUG:root:[ Iteration 60 ] Test loss: 0.159288
DEBUG:root:[ Iteration 63 ] Training loss: 0.161749
DEBUG:root:[ Iteration 66 ] Training loss: 0.150905
DEBUG:root:[ Iteration 69 ] Training loss: 0.170554
DEBUG:root:[ Iteration 72 ] Training loss: 0.154744
DEBUG:root:[ Iteration 75 ] Training loss: 0.147863
DEBUG:root:[ Iteration 78 ] Training loss: 0.162291
DEBUG:root:[ Iteration 80 ] Test loss: 0.159073
DEBUG:root:[ Iteration 81 ] Training loss: 0.162764
DEBUG:root:[ Iteration 84 ] Training loss: 0.147911
DEBUG:root:[ Iteration 87 ] Training loss: 0.139189
DEBUG:root:[ Iteration 90 ] Training loss: 0.168601
DEBUG:root:[ Iteration 93 ] Training loss: 0.151303
DEBUG:root:[ Iteration 96 ] Training loss: 0.153591
DEBUG:root:[ Iteration 99 ] Training loss: 0.159805
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h05m53s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.186004
DEBUG:root:[ Iteration 0 ] Test loss: 0.187346
DEBUG:root:[ Iteration 3 ] Training loss: 0.177744
DEBUG:root:[ Iteration 6 ] Training loss: 0.19548
DEBUG:root:[ Iteration 9 ] Training loss: 0.186236
DEBUG:root:[ Iteration 12 ] Training loss: 0.186154
DEBUG:root:[ Iteration 15 ] Training loss: 0.18407
DEBUG:root:[ Iteration 18 ] Training loss: 0.187182
DEBUG:root:[ Iteration 20 ] Test loss: 0.181616
DEBUG:root:[ Iteration 21 ] Training loss: 0.183707
DEBUG:root:[ Iteration 24 ] Training loss: 0.180565
DEBUG:root:[ Iteration 27 ] Training loss: 0.184745
DEBUG:root:[ Iteration 30 ] Training loss: 0.1812
DEBUG:root:[ Iteration 33 ] Training loss: 0.186996
DEBUG:root:[ Iteration 36 ] Training loss: 0.174902
DEBUG:root:[ Iteration 39 ] Training loss: 0.177699
DEBUG:root:[ Iteration 40 ] Test loss: 0.177504
DEBUG:root:[ Iteration 42 ] Training loss: 0.180098
DEBUG:root:[ Iteration 45 ] Training loss: 0.170354
DEBUG:root:[ Iteration 48 ] Training loss: 0.181157
DEBUG:root:[ Iteration 51 ] Training loss: 0.179292
DEBUG:root:[ Iteration 54 ] Training loss: 0.177847
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h07m35s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.166048
DEBUG:root:[ Iteration 0 ] Test loss: 0.167573
DEBUG:root:[ Iteration 3 ] Training loss: 0.165956
DEBUG:root:[ Iteration 6 ] Training loss: 0.165796
DEBUG:root:[ Iteration 9 ] Training loss: 0.165613
DEBUG:root:[ Iteration 12 ] Training loss: 0.165421
DEBUG:root:[ Iteration 15 ] Training loss: 0.165229
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h08m31s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.174003
DEBUG:root:[ Iteration 0 ] Test loss: 0.174534
DEBUG:root:[ Iteration 3 ] Training loss: 0.170861
DEBUG:root:[ Iteration 6 ] Training loss: 0.166844
DEBUG:root:[ Iteration 9 ] Training loss: 0.163321
DEBUG:root:[ Iteration 12 ] Training loss: 0.160155
DEBUG:root:[ Iteration 15 ] Training loss: 0.157431
DEBUG:root:[ Iteration 18 ] Training loss: 0.155183
DEBUG:root:[ Iteration 20 ] Test loss: 0.161487
DEBUG:root:[ Iteration 21 ] Training loss: 0.153413
DEBUG:root:[ Iteration 24 ] Training loss: 0.15212
DEBUG:root:[ Iteration 27 ] Training loss: 0.151241
DEBUG:root:[ Iteration 30 ] Training loss: 0.150681
DEBUG:root:[ Iteration 33 ] Training loss: 0.150343
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h09m23s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.173845
DEBUG:root:[ Iteration 0 ] Test loss: 0.177812
DEBUG:root:[ Iteration 3 ] Training loss: 0.172451
DEBUG:root:[ Iteration 6 ] Training loss: 0.169804
DEBUG:root:[ Iteration 9 ] Training loss: 0.16671
DEBUG:root:[ Iteration 12 ] Training loss: 0.162978
DEBUG:root:[ Iteration 15 ] Training loss: 0.158517
DEBUG:root:[ Iteration 18 ] Training loss: 0.154642
DEBUG:root:[ Iteration 20 ] Test loss: 0.162808
DEBUG:root:[ Iteration 21 ] Training loss: 0.1523
DEBUG:root:[ Iteration 24 ] Training loss: 0.151724
DEBUG:root:[ Iteration 27 ] Training loss: 0.151624
DEBUG:root:[ Iteration 30 ] Training loss: 0.151282
DEBUG:root:[ Iteration 33 ] Training loss: 0.150821
DEBUG:root:[ Iteration 36 ] Training loss: 0.150503
DEBUG:root:[ Iteration 39 ] Training loss: 0.150303
DEBUG:root:[ Iteration 40 ] Test loss: 0.159248
DEBUG:root:[ Iteration 42 ] Training loss: 0.15012
DEBUG:root:[ Iteration 45 ] Training loss: 0.14995
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h11m28s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.20273
DEBUG:root:[ Iteration 0 ] Test loss: 0.203702
DEBUG:root:[ Iteration 3 ] Training loss: 0.173312
DEBUG:root:[ Iteration 6 ] Training loss: 0.16989
DEBUG:root:[ Iteration 9 ] Training loss: 0.165847
DEBUG:root:[ Iteration 12 ] Training loss: 0.162718
DEBUG:root:[ Iteration 15 ] Training loss: 0.162961
DEBUG:root:[ Iteration 18 ] Training loss: 0.163639
DEBUG:root:[ Iteration 20 ] Test loss: 0.161406
DEBUG:root:[ Iteration 21 ] Training loss: 0.163617
DEBUG:root:[ Iteration 24 ] Training loss: 0.163235
DEBUG:root:[ Iteration 27 ] Training loss: 0.162896
DEBUG:root:[ Iteration 30 ] Training loss: 0.162651
DEBUG:root:[ Iteration 33 ] Training loss: 0.162534
DEBUG:root:[ Iteration 36 ] Training loss: 0.16252
DEBUG:root:[ Iteration 39 ] Training loss: 0.162555
DEBUG:root:[ Iteration 40 ] Test loss: 0.16043
DEBUG:root:[ Iteration 42 ] Training loss: 0.162579
DEBUG:root:[ Iteration 45 ] Training loss: 0.162577
DEBUG:root:[ Iteration 48 ] Training loss: 0.162563
DEBUG:root:[ Iteration 51 ] Training loss: 0.162546
DEBUG:root:[ Iteration 54 ] Training loss: 0.16253
DEBUG:root:[ Iteration 57 ] Training loss: 0.162519
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h14m06s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.326788
DEBUG:root:[ Iteration 0 ] Test loss: 0.353377
DEBUG:root:[ Iteration 3 ] Training loss: 0.141189
DEBUG:root:[ Iteration 6 ] Training loss: 0.162673
DEBUG:root:[ Iteration 9 ] Training loss: 0.161024
DEBUG:root:[ Iteration 12 ] Training loss: 0.152084
DEBUG:root:[ Iteration 15 ] Training loss: 0.149768
DEBUG:root:[ Iteration 18 ] Training loss: 0.150066
DEBUG:root:[ Iteration 20 ] Test loss: 0.159789
DEBUG:root:[ Iteration 21 ] Training loss: 0.149943
DEBUG:root:[ Iteration 24 ] Training loss: 0.149249
DEBUG:root:[ Iteration 27 ] Training loss: 0.148334
DEBUG:root:[ Iteration 30 ] Training loss: 0.147519
DEBUG:root:[ Iteration 33 ] Training loss: 0.146924
DEBUG:root:[ Iteration 36 ] Training loss: 0.146423
DEBUG:root:[ Iteration 39 ] Training loss: 0.14591
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h20m10s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.172972
DEBUG:root:[ Iteration 0 ] Test loss: 0.166191
DEBUG:root:[ Iteration 3 ] Training loss: 0.157606
DEBUG:root:[ Iteration 6 ] Training loss: 0.152339
DEBUG:root:[ Iteration 9 ] Training loss: 0.142891
DEBUG:root:[ Iteration 12 ] Training loss: 0.128625
DEBUG:root:[ Iteration 15 ] Training loss: 0.105197
DEBUG:root:[ Iteration 18 ] Training loss: 0.0751605
DEBUG:root:[ Iteration 20 ] Test loss: 0.166481
DEBUG:root:[ Iteration 21 ] Training loss: 0.0455712
DEBUG:root:[ Iteration 24 ] Training loss: 0.0396058
DEBUG:root:[ Iteration 27 ] Training loss: 0.121889
DEBUG:root:[ Iteration 30 ] Training loss: 0.186032
DEBUG:root:[ Iteration 33 ] Training loss: 0.13746
DEBUG:root:[ Iteration 36 ] Training loss: 0.136323
DEBUG:root:[ Iteration 39 ] Training loss: 0.130602
DEBUG:root:[ Iteration 40 ] Test loss: 0.296368
DEBUG:root:[ Iteration 42 ] Training loss: 0.131622
DEBUG:root:[ Iteration 45 ] Training loss: 0.129476
DEBUG:root:[ Iteration 48 ] Training loss: 0.127099
DEBUG:root:[ Iteration 51 ] Training loss: 0.126882
DEBUG:root:[ Iteration 54 ] Training loss: 0.126722
DEBUG:root:[ Iteration 57 ] Training loss: 0.126376
DEBUG:root:[ Iteration 60 ] Training loss: 0.126209
DEBUG:root:[ Iteration 60 ] Test loss: 0.302619
DEBUG:root:[ Iteration 63 ] Training loss: 0.126118
DEBUG:root:[ Iteration 66 ] Training loss: 0.125928
DEBUG:root:[ Iteration 69 ] Training loss: 0.125747
DEBUG:root:[ Iteration 72 ] Training loss: 0.12568
DEBUG:root:[ Iteration 75 ] Training loss: 0.125582
DEBUG:root:[ Iteration 78 ] Training loss: 0.125477
DEBUG:root:[ Iteration 80 ] Test loss: 0.306011
DEBUG:root:[ Iteration 81 ] Training loss: 0.125452
DEBUG:root:[ Iteration 84 ] Training loss: 0.125405
DEBUG:root:[ Iteration 87 ] Training loss: 0.125366
DEBUG:root:[ Iteration 90 ] Training loss: 0.125342
DEBUG:root:[ Iteration 93 ] Training loss: 0.12531
DEBUG:root:[ Iteration 96 ] Training loss: 0.125295
DEBUG:root:[ Iteration 99 ] Training loss: 0.125281
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h20m35s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.180192
DEBUG:root:[ Iteration 0 ] Test loss: 0.172456
DEBUG:root:[ Iteration 3 ] Training loss: 0.163634
DEBUG:root:[ Iteration 6 ] Training loss: 0.157531
DEBUG:root:[ Iteration 9 ] Training loss: 0.155372
DEBUG:root:[ Iteration 12 ] Training loss: 0.153731
DEBUG:root:[ Iteration 15 ] Training loss: 0.15043
DEBUG:root:[ Iteration 18 ] Training loss: 0.146143
DEBUG:root:[ Iteration 20 ] Test loss: 0.17418
DEBUG:root:[ Iteration 21 ] Training loss: 0.143622
DEBUG:root:[ Iteration 24 ] Training loss: 0.142222
DEBUG:root:[ Iteration 27 ] Training loss: 0.138763
DEBUG:root:[ Iteration 30 ] Training loss: 0.136822
DEBUG:root:[ Iteration 33 ] Training loss: 0.13388
DEBUG:root:[ Iteration 36 ] Training loss: 0.1317
DEBUG:root:[ Iteration 39 ] Training loss: 0.129046
DEBUG:root:[ Iteration 40 ] Test loss: 0.17358
DEBUG:root:[ Iteration 42 ] Training loss: 0.126086
DEBUG:root:[ Iteration 45 ] Training loss: 0.12335
DEBUG:root:[ Iteration 48 ] Training loss: 0.120199
DEBUG:root:[ Iteration 51 ] Training loss: 0.11726
DEBUG:root:[ Iteration 54 ] Training loss: 0.113729
DEBUG:root:[ Iteration 57 ] Training loss: 0.11024
DEBUG:root:[ Iteration 60 ] Training loss: 0.106712
DEBUG:root:[ Iteration 60 ] Test loss: 0.170378
DEBUG:root:[ Iteration 63 ] Training loss: 0.102936
DEBUG:root:[ Iteration 66 ] Training loss: 0.0989267
DEBUG:root:[ Iteration 69 ] Training loss: 0.0949276
DEBUG:root:[ Iteration 72 ] Training loss: 0.0908091
DEBUG:root:[ Iteration 75 ] Training loss: 0.0866444
DEBUG:root:[ Iteration 78 ] Training loss: 0.0824178
DEBUG:root:[ Iteration 80 ] Test loss: 0.16885
DEBUG:root:[ Iteration 81 ] Training loss: 0.0781474
DEBUG:root:[ Iteration 84 ] Training loss: 0.0739075
DEBUG:root:[ Iteration 87 ] Training loss: 0.0696104
DEBUG:root:[ Iteration 90 ] Training loss: 0.0653892
DEBUG:root:[ Iteration 93 ] Training loss: 0.0612808
DEBUG:root:[ Iteration 96 ] Training loss: 0.057292
DEBUG:root:[ Iteration 99 ] Training loss: 0.0534528
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h21m35s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.188933
DEBUG:root:[ Iteration 0 ] Test loss: 0.183848
DEBUG:root:[ Iteration 3 ] Training loss: 0.189728
DEBUG:root:[ Iteration 6 ] Training loss: 0.18785
DEBUG:root:[ Iteration 9 ] Training loss: 0.186584
DEBUG:root:[ Iteration 12 ] Training loss: 0.19203
DEBUG:root:[ Iteration 15 ] Training loss: 0.181682
DEBUG:root:[ Iteration 18 ] Training loss: 0.183813
DEBUG:root:[ Iteration 20 ] Test loss: 0.177001
DEBUG:root:[ Iteration 21 ] Training loss: 0.184607
DEBUG:root:[ Iteration 24 ] Training loss: 0.174685
DEBUG:root:[ Iteration 27 ] Training loss: 0.174251
DEBUG:root:[ Iteration 30 ] Training loss: 0.170316
DEBUG:root:[ Iteration 33 ] Training loss: 0.171406
DEBUG:root:[ Iteration 36 ] Training loss: 0.172443
DEBUG:root:[ Iteration 39 ] Training loss: 0.168584
DEBUG:root:[ Iteration 40 ] Test loss: 0.169737
DEBUG:root:[ Iteration 42 ] Training loss: 0.166815
DEBUG:root:[ Iteration 45 ] Training loss: 0.162034
DEBUG:root:[ Iteration 48 ] Training loss: 0.165578
DEBUG:root:[ Iteration 51 ] Training loss: 0.163964
DEBUG:root:[ Iteration 54 ] Training loss: 0.163663
DEBUG:root:[ Iteration 57 ] Training loss: 0.161312
DEBUG:root:[ Iteration 60 ] Training loss: 0.158999
DEBUG:root:[ Iteration 60 ] Test loss: 0.164987
DEBUG:root:[ Iteration 63 ] Training loss: 0.164309
DEBUG:root:[ Iteration 66 ] Training loss: 0.163891
DEBUG:root:[ Iteration 69 ] Training loss: 0.157289
DEBUG:root:[ Iteration 72 ] Training loss: 0.164287
DEBUG:root:[ Iteration 75 ] Training loss: 0.16344
DEBUG:root:[ Iteration 78 ] Training loss: 0.160429
DEBUG:root:[ Iteration 80 ] Test loss: 0.162197
DEBUG:root:[ Iteration 81 ] Training loss: 0.163549
DEBUG:root:[ Iteration 84 ] Training loss: 0.155249
DEBUG:root:[ Iteration 87 ] Training loss: 0.151522
DEBUG:root:[ Iteration 90 ] Training loss: 0.164602
DEBUG:root:[ Iteration 93 ] Training loss: 0.159389
DEBUG:root:[ Iteration 96 ] Training loss: 0.168021
DEBUG:root:[ Iteration 99 ] Training loss: 0.151414
DEBUG:root:[ Iteration 100 ] Test loss: 0.160492
DEBUG:root:[ Iteration 102 ] Training loss: 0.158185
DEBUG:root:[ Iteration 105 ] Training loss: 0.155721
DEBUG:root:[ Iteration 108 ] Training loss: 0.154237
DEBUG:root:[ Iteration 111 ] Training loss: 0.164057
DEBUG:root:[ Iteration 114 ] Training loss: 0.160498
DEBUG:root:[ Iteration 117 ] Training loss: 0.157345
DEBUG:root:[ Iteration 120 ] Training loss: 0.1556
DEBUG:root:[ Iteration 120 ] Test loss: 0.159636
DEBUG:root:[ Iteration 123 ] Training loss: 0.155745
DEBUG:root:[ Iteration 126 ] Training loss: 0.144587
DEBUG:root:[ Iteration 129 ] Training loss: 0.156979
DEBUG:root:[ Iteration 132 ] Training loss: 0.160633
DEBUG:root:[ Iteration 135 ] Training loss: 0.163593
DEBUG:root:[ Iteration 138 ] Training loss: 0.161197
DEBUG:root:[ Iteration 140 ] Test loss: 0.159371
DEBUG:root:[ Iteration 141 ] Training loss: 0.142709
DEBUG:root:[ Iteration 144 ] Training loss: 0.153677
DEBUG:root:[ Iteration 147 ] Training loss: 0.157097
DEBUG:root:[ Iteration 150 ] Training loss: 0.139041
DEBUG:root:[ Iteration 153 ] Training loss: 0.148091
DEBUG:root:[ Iteration 156 ] Training loss: 0.151402
DEBUG:root:[ Iteration 159 ] Training loss: 0.144082
DEBUG:root:[ Iteration 160 ] Test loss: 0.159337
DEBUG:root:[ Iteration 162 ] Training loss: 0.149422
DEBUG:root:[ Iteration 165 ] Training loss: 0.150381
DEBUG:root:[ Iteration 168 ] Training loss: 0.145864
DEBUG:root:[ Iteration 171 ] Training loss: 0.147851
DEBUG:root:[ Iteration 174 ] Training loss: 0.152565
DEBUG:root:[ Iteration 177 ] Training loss: 0.151803
DEBUG:root:[ Iteration 180 ] Training loss: 0.150258
DEBUG:root:[ Iteration 180 ] Test loss: 0.159495
DEBUG:root:[ Iteration 183 ] Training loss: 0.156274
DEBUG:root:[ Iteration 186 ] Training loss: 0.13814
DEBUG:root:[ Iteration 189 ] Training loss: 0.137859
DEBUG:root:[ Iteration 192 ] Training loss: 0.151711
DEBUG:root:[ Iteration 195 ] Training loss: 0.149553
DEBUG:root:[ Iteration 198 ] Training loss: 0.150414
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h24m02s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.182971
DEBUG:root:[ Iteration 0 ] Test loss: 0.174861
DEBUG:root:[ Iteration 3 ] Training loss: 0.175062
DEBUG:root:[ Iteration 6 ] Training loss: 0.179685
DEBUG:root:[ Iteration 9 ] Training loss: 0.180599
DEBUG:root:[ Iteration 12 ] Training loss: 0.17348
DEBUG:root:[ Iteration 15 ] Training loss: 0.177123
DEBUG:root:[ Iteration 18 ] Training loss: 0.179218
DEBUG:root:[ Iteration 20 ] Test loss: 0.174759
DEBUG:root:[ Iteration 21 ] Training loss: 0.17181
DEBUG:root:[ Iteration 24 ] Training loss: 0.179764
DEBUG:root:[ Iteration 27 ] Training loss: 0.18061
DEBUG:root:[ Iteration 30 ] Training loss: 0.173365
DEBUG:root:[ Iteration 33 ] Training loss: 0.177708
DEBUG:root:[ Iteration 36 ] Training loss: 0.177085
DEBUG:root:[ Iteration 39 ] Training loss: 0.181577
DEBUG:root:[ Iteration 40 ] Test loss: 0.174654
DEBUG:root:[ Iteration 42 ] Training loss: 0.180019
DEBUG:root:[ Iteration 45 ] Training loss: 0.180061
DEBUG:root:[ Iteration 48 ] Training loss: 0.177679
DEBUG:root:[ Iteration 51 ] Training loss: 0.175541
DEBUG:root:[ Iteration 54 ] Training loss: 0.178727
DEBUG:root:[ Iteration 57 ] Training loss: 0.174317
DEBUG:root:[ Iteration 60 ] Training loss: 0.177031
DEBUG:root:[ Iteration 60 ] Test loss: 0.174548
DEBUG:root:[ Iteration 63 ] Training loss: 0.180226
DEBUG:root:[ Iteration 66 ] Training loss: 0.177941
DEBUG:root:[ Iteration 69 ] Training loss: 0.177629
DEBUG:root:[ Iteration 72 ] Training loss: 0.175723
DEBUG:root:[ Iteration 75 ] Training loss: 0.175163
DEBUG:root:[ Iteration 78 ] Training loss: 0.177069
DEBUG:root:[ Iteration 80 ] Test loss: 0.174443
DEBUG:root:[ Iteration 81 ] Training loss: 0.174822
DEBUG:root:[ Iteration 84 ] Training loss: 0.17646
DEBUG:root:[ Iteration 87 ] Training loss: 0.173905
DEBUG:root:[ Iteration 90 ] Training loss: 0.175773
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h28m03s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.171635
DEBUG:root:[ Iteration 0 ] Test loss: 0.174727
DEBUG:root:[ Iteration 3 ] Training loss: 0.171613
DEBUG:root:[ Iteration 6 ] Training loss: 0.171584
DEBUG:root:[ Iteration 9 ] Training loss: 0.171554
DEBUG:root:[ Iteration 12 ] Training loss: 0.171524
DEBUG:root:[ Iteration 15 ] Training loss: 0.171495
DEBUG:root:[ Iteration 18 ] Training loss: 0.171465
DEBUG:root:[ Iteration 20 ] Test loss: 0.174548
DEBUG:root:[ Iteration 21 ] Training loss: 0.171435
DEBUG:root:[ Iteration 24 ] Training loss: 0.171405
DEBUG:root:[ Iteration 27 ] Training loss: 0.171375
DEBUG:root:[ Iteration 30 ] Training loss: 0.171346
DEBUG:root:[ Iteration 33 ] Training loss: 0.171316
DEBUG:root:[ Iteration 36 ] Training loss: 0.171287
DEBUG:root:[ Iteration 39 ] Training loss: 0.171257
DEBUG:root:[ Iteration 40 ] Test loss: 0.174361
DEBUG:root:[ Iteration 42 ] Training loss: 0.171228
DEBUG:root:[ Iteration 45 ] Training loss: 0.171198
DEBUG:root:[ Iteration 48 ] Training loss: 0.171169
DEBUG:root:[ Iteration 51 ] Training loss: 0.17114
DEBUG:root:[ Iteration 54 ] Training loss: 0.171111
DEBUG:root:[ Iteration 57 ] Training loss: 0.171081
DEBUG:root:[ Iteration 60 ] Training loss: 0.171052
DEBUG:root:[ Iteration 60 ] Test loss: 0.174178
DEBUG:root:[ Iteration 63 ] Training loss: 0.171023
DEBUG:root:[ Iteration 66 ] Training loss: 0.170994
DEBUG:root:[ Iteration 69 ] Training loss: 0.170966
DEBUG:root:[ Iteration 72 ] Training loss: 0.170937
DEBUG:root:[ Iteration 75 ] Training loss: 0.170908
DEBUG:root:[ Iteration 78 ] Training loss: 0.170879
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h28m30s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.168384
DEBUG:root:[ Iteration 0 ] Test loss: 0.17407
DEBUG:root:[ Iteration 3 ] Training loss: 0.168252
DEBUG:root:[ Iteration 6 ] Training loss: 0.168073
DEBUG:root:[ Iteration 9 ] Training loss: 0.16789
DEBUG:root:[ Iteration 12 ] Training loss: 0.167707
DEBUG:root:[ Iteration 15 ] Training loss: 0.167526
DEBUG:root:[ Iteration 18 ] Training loss: 0.167347
DEBUG:root:[ Iteration 20 ] Test loss: 0.17311
DEBUG:root:[ Iteration 21 ] Training loss: 0.167169
DEBUG:root:[ Iteration 24 ] Training loss: 0.166992
DEBUG:root:[ Iteration 27 ] Training loss: 0.166817
DEBUG:root:[ Iteration 30 ] Training loss: 0.166643
DEBUG:root:[ Iteration 33 ] Training loss: 0.16647
DEBUG:root:[ Iteration 36 ] Training loss: 0.166299
DEBUG:root:[ Iteration 39 ] Training loss: 0.16613
DEBUG:root:[ Iteration 40 ] Test loss: 0.172157
DEBUG:root:[ Iteration 42 ] Training loss: 0.165961
DEBUG:root:[ Iteration 45 ] Training loss: 0.165794
DEBUG:root:[ Iteration 48 ] Training loss: 0.165627
DEBUG:root:[ Iteration 51 ] Training loss: 0.165462
DEBUG:root:[ Iteration 54 ] Training loss: 0.165299
DEBUG:root:[ Iteration 57 ] Training loss: 0.165136
DEBUG:root:[ Iteration 60 ] Training loss: 0.164974
DEBUG:root:[ Iteration 60 ] Test loss: 0.171255
DEBUG:root:[ Iteration 63 ] Training loss: 0.164813
DEBUG:root:[ Iteration 66 ] Training loss: 0.164653
DEBUG:root:[ Iteration 69 ] Training loss: 0.164494
DEBUG:root:[ Iteration 72 ] Training loss: 0.164336
DEBUG:root:[ Iteration 75 ] Training loss: 0.164179
DEBUG:root:[ Iteration 78 ] Training loss: 0.164022
DEBUG:root:[ Iteration 80 ] Test loss: 0.170396
DEBUG:root:[ Iteration 81 ] Training loss: 0.163867
DEBUG:root:[ Iteration 84 ] Training loss: 0.163712
DEBUG:root:[ Iteration 87 ] Training loss: 0.163558
DEBUG:root:[ Iteration 90 ] Training loss: 0.163404
DEBUG:root:[ Iteration 93 ] Training loss: 0.163251
DEBUG:root:[ Iteration 96 ] Training loss: 0.163098
DEBUG:root:[ Iteration 99 ] Training loss: 0.162946
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h29m37s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.177447
DEBUG:root:[ Iteration 0 ] Test loss: 0.175414
DEBUG:root:[ Iteration 3 ] Training loss: 0.177039
DEBUG:root:[ Iteration 6 ] Training loss: 0.176167
DEBUG:root:[ Iteration 9 ] Training loss: 0.174915
DEBUG:root:[ Iteration 12 ] Training loss: 0.173237
DEBUG:root:[ Iteration 15 ] Training loss: 0.170934
DEBUG:root:[ Iteration 18 ] Training loss: 0.167514
DEBUG:root:[ Iteration 20 ] Test loss: 0.16782
DEBUG:root:[ Iteration 21 ] Training loss: 0.161985
DEBUG:root:[ Iteration 24 ] Training loss: 0.152997
DEBUG:root:[ Iteration 27 ] Training loss: 0.141399
DEBUG:root:[ Iteration 30 ] Training loss: 0.135879
DEBUG:root:[ Iteration 33 ] Training loss: 0.139377
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h32m24s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.179828
DEBUG:root:[ Iteration 0 ] Test loss: 0.173749
DEBUG:root:[ Iteration 3 ] Training loss: 0.179812
DEBUG:root:[ Iteration 6 ] Training loss: 0.179776
DEBUG:root:[ Iteration 9 ] Training loss: 0.179726
DEBUG:root:[ Iteration 12 ] Training loss: 0.179668
DEBUG:root:[ Iteration 15 ] Training loss: 0.179604
DEBUG:root:[ Iteration 18 ] Training loss: 0.179537
DEBUG:root:[ Iteration 20 ] Test loss: 0.172843
DEBUG:root:[ Iteration 21 ] Training loss: 0.179469
DEBUG:root:[ Iteration 24 ] Training loss: 0.179401
DEBUG:root:[ Iteration 27 ] Training loss: 0.179333
DEBUG:root:[ Iteration 30 ] Training loss: 0.179267
DEBUG:root:[ Iteration 33 ] Training loss: 0.179203
DEBUG:root:[ Iteration 36 ] Training loss: 0.179141
DEBUG:root:[ Iteration 39 ] Training loss: 0.179081
DEBUG:root:[ Iteration 40 ] Test loss: 0.171593
DEBUG:root:[ Iteration 42 ] Training loss: 0.179023
DEBUG:root:[ Iteration 45 ] Training loss: 0.178968
DEBUG:root:[ Iteration 48 ] Training loss: 0.178916
DEBUG:root:[ Iteration 51 ] Training loss: 0.178865
DEBUG:root:[ Iteration 54 ] Training loss: 0.178817
DEBUG:root:[ Iteration 57 ] Training loss: 0.178771
DEBUG:root:[ Iteration 60 ] Training loss: 0.178728
DEBUG:root:[ Iteration 60 ] Test loss: 0.170515
DEBUG:root:[ Iteration 63 ] Training loss: 0.178686
DEBUG:root:[ Iteration 66 ] Training loss: 0.178646
DEBUG:root:[ Iteration 69 ] Training loss: 0.178608
DEBUG:root:[ Iteration 72 ] Training loss: 0.178572
DEBUG:root:[ Iteration 75 ] Training loss: 0.178538
DEBUG:root:[ Iteration 78 ] Training loss: 0.178505
DEBUG:root:[ Iteration 80 ] Test loss: 0.169635
DEBUG:root:[ Iteration 81 ] Training loss: 0.178474
DEBUG:root:[ Iteration 84 ] Training loss: 0.178444
DEBUG:root:[ Iteration 87 ] Training loss: 0.178416
DEBUG:root:[ Iteration 90 ] Training loss: 0.178389
DEBUG:root:[ Iteration 93 ] Training loss: 0.178363
DEBUG:root:[ Iteration 96 ] Training loss: 0.178339
DEBUG:root:[ Iteration 99 ] Training loss: 0.178316
DEBUG:root:[ Iteration 100 ] Test loss: 0.168917
DEBUG:root:[ Iteration 102 ] Training loss: 0.178294
DEBUG:root:[ Iteration 105 ] Training loss: 0.178272
DEBUG:root:[ Iteration 108 ] Training loss: 0.178252
DEBUG:root:[ Iteration 111 ] Training loss: 0.178233
DEBUG:root:[ Iteration 114 ] Training loss: 0.178215
DEBUG:root:[ Iteration 117 ] Training loss: 0.178198
DEBUG:root:[ Iteration 120 ] Training loss: 0.178181
DEBUG:root:[ Iteration 120 ] Test loss: 0.168332
DEBUG:root:[ Iteration 123 ] Training loss: 0.178165
DEBUG:root:[ Iteration 126 ] Training loss: 0.178151
DEBUG:root:[ Iteration 129 ] Training loss: 0.178136
DEBUG:root:[ Iteration 132 ] Training loss: 0.178123
DEBUG:root:[ Iteration 135 ] Training loss: 0.17811
DEBUG:root:[ Iteration 138 ] Training loss: 0.178097
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h36m18s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.183775
DEBUG:root:[ Iteration 0 ] Test loss: 0.173884
DEBUG:root:[ Iteration 3 ] Training loss: 0.183362
DEBUG:root:[ Iteration 6 ] Training loss: 0.182937
DEBUG:root:[ Iteration 9 ] Training loss: 0.182514
DEBUG:root:[ Iteration 12 ] Training loss: 0.182093
DEBUG:root:[ Iteration 15 ] Training loss: 0.181674
DEBUG:root:[ Iteration 18 ] Training loss: 0.181257
DEBUG:root:[ Iteration 20 ] Test loss: 0.174666
DEBUG:root:[ Iteration 21 ] Training loss: 0.180842
DEBUG:root:[ Iteration 24 ] Training loss: 0.18043
DEBUG:root:[ Iteration 27 ] Training loss: 0.180019
DEBUG:root:[ Iteration 30 ] Training loss: 0.179611
DEBUG:root:[ Iteration 33 ] Training loss: 0.179204
DEBUG:root:[ Iteration 36 ] Training loss: 0.1788
DEBUG:root:[ Iteration 39 ] Training loss: 0.178397
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h38m19s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.175754
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h38m49s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.200106
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h41m37s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.557407
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h42m56s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.266401
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h44m03s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.189743
DEBUG:root:[ Iteration 0 ] Test loss: 0.188355
DEBUG:root:[ Iteration 3 ] Training loss: 0.179728
DEBUG:root:[ Iteration 6 ] Training loss: 0.172093
DEBUG:root:[ Iteration 9 ] Training loss: 0.16589
DEBUG:root:[ Iteration 12 ] Training loss: 0.16054
DEBUG:root:[ Iteration 15 ] Training loss: 0.155747
DEBUG:root:[ Iteration 18 ] Training loss: 0.151464
DEBUG:root:[ Iteration 20 ] Test loss: 0.2095
DEBUG:root:[ Iteration 21 ] Training loss: 0.147599
DEBUG:root:[ Iteration 24 ] Training loss: 0.144198
DEBUG:root:[ Iteration 27 ] Training loss: 0.141329
DEBUG:root:[ Iteration 30 ] Training loss: 0.138786
DEBUG:root:[ Iteration 33 ] Training loss: 0.136602
DEBUG:root:[ Iteration 36 ] Training loss: 0.134716
DEBUG:root:[ Iteration 39 ] Training loss: 0.133098
DEBUG:root:[ Iteration 40 ] Test loss: 0.236134
DEBUG:root:[ Iteration 42 ] Training loss: 0.131696
DEBUG:root:[ Iteration 45 ] Training loss: 0.130515
DEBUG:root:[ Iteration 48 ] Training loss: 0.129483
DEBUG:root:[ Iteration 51 ] Training loss: 0.128577
DEBUG:root:[ Iteration 54 ] Training loss: 0.127778
DEBUG:root:[ Iteration 57 ] Training loss: 0.12706
DEBUG:root:[ Iteration 60 ] Training loss: 0.126325
DEBUG:root:[ Iteration 60 ] Test loss: 0.251347
DEBUG:root:[ Iteration 63 ] Training loss: 0.125486
DEBUG:root:[ Iteration 66 ] Training loss: 0.124671
DEBUG:root:[ Iteration 69 ] Training loss: 0.124065
DEBUG:root:[ Iteration 72 ] Training loss: 0.123513
DEBUG:root:[ Iteration 75 ] Training loss: 0.123059
DEBUG:root:[ Iteration 78 ] Training loss: 0.122609
DEBUG:root:[ Iteration 80 ] Test loss: 0.260893
DEBUG:root:[ Iteration 81 ] Training loss: 0.122158
DEBUG:root:[ Iteration 84 ] Training loss: 0.121732
DEBUG:root:[ Iteration 87 ] Training loss: 0.121287
DEBUG:root:[ Iteration 90 ] Training loss: 0.120843
DEBUG:root:[ Iteration 93 ] Training loss: 0.120373
DEBUG:root:[ Iteration 96 ] Training loss: 0.119911
DEBUG:root:[ Iteration 99 ] Training loss: 0.119439
DEBUG:root:[ Iteration 100 ] Test loss: 0.267551
DEBUG:root:[ Iteration 102 ] Training loss: 0.118953
DEBUG:root:[ Iteration 105 ] Training loss: 0.118463
DEBUG:root:[ Iteration 108 ] Training loss: 0.117965
DEBUG:root:[ Iteration 111 ] Training loss: 0.117466
DEBUG:root:[ Iteration 114 ] Training loss: 0.116932
DEBUG:root:[ Iteration 117 ] Training loss: 0.116391
DEBUG:root:[ Iteration 120 ] Training loss: 0.115844
DEBUG:root:[ Iteration 120 ] Test loss: 0.272217
DEBUG:root:[ Iteration 123 ] Training loss: 0.115281
DEBUG:root:[ Iteration 126 ] Training loss: 0.1147
DEBUG:root:[ Iteration 129 ] Training loss: 0.114096
DEBUG:root:[ Iteration 132 ] Training loss: 0.113487
DEBUG:root:[ Iteration 135 ] Training loss: 0.112868
DEBUG:root:[ Iteration 138 ] Training loss: 0.112214
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h45m27s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.18998
DEBUG:root:[ Iteration 0 ] Test loss: 0.18861
DEBUG:root:[ Iteration 3 ] Training loss: 0.180704
DEBUG:root:[ Iteration 6 ] Training loss: 0.178644
DEBUG:root:[ Iteration 9 ] Training loss: 0.178686
DEBUG:root:[ Iteration 12 ] Training loss: 0.176136
DEBUG:root:[ Iteration 15 ] Training loss: 0.173854
DEBUG:root:[ Iteration 18 ] Training loss: 0.177637
DEBUG:root:[ Iteration 20 ] Test loss: 0.175632
DEBUG:root:[ Iteration 21 ] Training loss: 0.175101
DEBUG:root:[ Iteration 24 ] Training loss: 0.173204
DEBUG:root:[ Iteration 27 ] Training loss: 0.172706
DEBUG:root:[ Iteration 30 ] Training loss: 0.176133
DEBUG:root:[ Iteration 33 ] Training loss: 0.175326
DEBUG:root:[ Iteration 36 ] Training loss: 0.169879
DEBUG:root:[ Iteration 39 ] Training loss: 0.174887
DEBUG:root:[ Iteration 40 ] Test loss: 0.173195
DEBUG:root:[ Iteration 42 ] Training loss: 0.173737
DEBUG:root:[ Iteration 45 ] Training loss: 0.170875
DEBUG:root:[ Iteration 48 ] Training loss: 0.172533
DEBUG:root:[ Iteration 51 ] Training loss: 0.170213
DEBUG:root:[ Iteration 54 ] Training loss: 0.170799
DEBUG:root:[ Iteration 57 ] Training loss: 0.177115
DEBUG:root:[ Iteration 60 ] Training loss: 0.164246
DEBUG:root:[ Iteration 60 ] Test loss: 0.172228
DEBUG:root:[ Iteration 63 ] Training loss: 0.176428
DEBUG:root:[ Iteration 66 ] Training loss: 0.1753
DEBUG:root:[ Iteration 69 ] Training loss: 0.168545
DEBUG:root:[ Iteration 72 ] Training loss: 0.170092
DEBUG:root:[ Iteration 75 ] Training loss: 0.165573
DEBUG:root:[ Iteration 78 ] Training loss: 0.174132
DEBUG:root:[ Iteration 80 ] Test loss: 0.171302
DEBUG:root:[ Iteration 81 ] Training loss: 0.169767
DEBUG:root:[ Iteration 84 ] Training loss: 0.169025
DEBUG:root:[ Iteration 87 ] Training loss: 0.171219
DEBUG:root:[ Iteration 90 ] Training loss: 0.168345
DEBUG:root:[ Iteration 93 ] Training loss: 0.172003
DEBUG:root:[ Iteration 96 ] Training loss: 0.164018
DEBUG:root:[ Iteration 99 ] Training loss: 0.17251
DEBUG:root:[ Iteration 100 ] Test loss: 0.170394
DEBUG:root:[ Iteration 102 ] Training loss: 0.170893
DEBUG:root:[ Iteration 105 ] Training loss: 0.170589
DEBUG:root:[ Iteration 108 ] Training loss: 0.168622
DEBUG:root:[ Iteration 111 ] Training loss: 0.16378
DEBUG:root:[ Iteration 114 ] Training loss: 0.172446
DEBUG:root:[ Iteration 117 ] Training loss: 0.166617
DEBUG:root:[ Iteration 120 ] Training loss: 0.163143
DEBUG:root:[ Iteration 120 ] Test loss: 0.169477
DEBUG:root:[ Iteration 123 ] Training loss: 0.172897
DEBUG:root:[ Iteration 126 ] Training loss: 0.170348
DEBUG:root:[ Iteration 129 ] Training loss: 0.165646
DEBUG:root:[ Iteration 132 ] Training loss: 0.164003
DEBUG:root:[ Iteration 135 ] Training loss: 0.174128
DEBUG:root:[ Iteration 138 ] Training loss: 0.165048
DEBUG:root:[ Iteration 140 ] Test loss: 0.168526
DEBUG:root:[ Iteration 141 ] Training loss: 0.169251
DEBUG:root:[ Iteration 144 ] Training loss: 0.171967
DEBUG:root:[ Iteration 147 ] Training loss: 0.160545
DEBUG:root:[ Iteration 150 ] Training loss: 0.163597
DEBUG:root:[ Iteration 153 ] Training loss: 0.163677
DEBUG:root:[ Iteration 156 ] Training loss: 0.16906
DEBUG:root:[ Iteration 159 ] Training loss: 0.161482
DEBUG:root:[ Iteration 160 ] Test loss: 0.16747
DEBUG:root:[ Iteration 162 ] Training loss: 0.171815
DEBUG:root:[ Iteration 165 ] Training loss: 0.160828
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-14-2016_19h52m41s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.543662
DEBUG:root:[ Iteration 0 ] Test loss: 0.566447
DEBUG:root:[ Iteration 3 ] Training loss: 0.201591
DEBUG:root:[ Iteration 6 ] Training loss: 0.16694
DEBUG:root:[ Iteration 9 ] Training loss: 0.157172
DEBUG:root:[ Iteration 12 ] Training loss: 0.154956
DEBUG:root:[ Iteration 15 ] Training loss: 0.154302
DEBUG:root:[ Iteration 18 ] Training loss: 0.158666
DEBUG:root:[ Iteration 20 ] Test loss: 0.154368
DEBUG:root:[ Iteration 21 ] Training loss: 0.148697
DEBUG:root:[ Iteration 24 ] Training loss: 0.14612
DEBUG:root:[ Iteration 27 ] Training loss: 0.141993
DEBUG:root:[ Iteration 30 ] Training loss: 0.148857
DEBUG:root:[ Iteration 33 ] Training loss: 0.147198
DEBUG:root:[ Iteration 36 ] Training loss: 0.143977
DEBUG:root:[ Iteration 39 ] Training loss: 0.149767
DEBUG:root:[ Iteration 40 ] Test loss: 0.145655
DEBUG:root:[ Iteration 42 ] Training loss: 0.139296
DEBUG:root:[ Iteration 45 ] Training loss: 0.139273
DEBUG:root:[ Iteration 48 ] Training loss: 0.135423
DEBUG:root:[ Iteration 51 ] Training loss: 0.13053
DEBUG:root:[ Iteration 54 ] Training loss: 0.133196
DEBUG:root:[ Iteration 57 ] Training loss: 0.141797
DEBUG:root:[ Iteration 60 ] Training loss: 0.132189
DEBUG:root:[ Iteration 60 ] Test loss: 0.140526
DEBUG:root:[ Iteration 63 ] Training loss: 0.13615
DEBUG:root:[ Iteration 66 ] Training loss: 0.147198
DEBUG:root:[ Iteration 69 ] Training loss: 0.137802
DEBUG:root:[ Iteration 72 ] Training loss: 0.13943
DEBUG:root:[ Iteration 75 ] Training loss: 0.146376
DEBUG:root:[ Iteration 78 ] Training loss: 0.121616
DEBUG:root:[ Iteration 80 ] Test loss: 0.13745
DEBUG:root:[ Iteration 81 ] Training loss: 0.128532
DEBUG:root:[ Iteration 84 ] Training loss: 0.142504
DEBUG:root:[ Iteration 87 ] Training loss: 0.142561
DEBUG:root:[ Iteration 90 ] Training loss: 0.13416
DEBUG:root:[ Iteration 93 ] Training loss: 0.129005
DEBUG:root:[ Iteration 96 ] Training loss: 0.1267
DEBUG:root:[ Iteration 99 ] Training loss: 0.130197
DEBUG:root:[ Iteration 100 ] Test loss: 0.135507
DEBUG:root:[ Iteration 102 ] Training loss: 0.144774
DEBUG:root:[ Iteration 105 ] Training loss: 0.131918
DEBUG:root:[ Iteration 108 ] Training loss: 0.139696
DEBUG:root:[ Iteration 111 ] Training loss: 0.118006
DEBUG:root:[ Iteration 114 ] Training loss: 0.12175
DEBUG:root:[ Iteration 117 ] Training loss: 0.121576
DEBUG:root:[ Iteration 120 ] Training loss: 0.14415
DEBUG:root:[ Iteration 120 ] Test loss: 0.134206
DEBUG:root:[ Iteration 123 ] Training loss: 0.134563
DEBUG:root:[ Iteration 126 ] Training loss: 0.12194
DEBUG:root:[ Iteration 129 ] Training loss: 0.122032
DEBUG:root:[ Iteration 132 ] Training loss: 0.130306
DEBUG:root:[ Iteration 135 ] Training loss: 0.132184
DEBUG:root:[ Iteration 138 ] Training loss: 0.130601
DEBUG:root:[ Iteration 140 ] Test loss: 0.133284
DEBUG:root:[ Iteration 141 ] Training loss: 0.113022
DEBUG:root:[ Iteration 144 ] Training loss: 0.130246
DEBUG:root:[ Iteration 147 ] Training loss: 0.121282
DEBUG:root:[ Iteration 150 ] Training loss: 0.123306
DEBUG:root:[ Iteration 153 ] Training loss: 0.137286
DEBUG:root:[ Iteration 156 ] Training loss: 0.119858
DEBUG:root:[ Iteration 159 ] Training loss: 0.129459
DEBUG:root:[ Iteration 160 ] Test loss: 0.132658
DEBUG:root:[ Iteration 162 ] Training loss: 0.128409
DEBUG:root:[ Iteration 165 ] Training loss: 0.135586
DEBUG:root:[ Iteration 168 ] Training loss: 0.107508
DEBUG:root:[ Iteration 171 ] Training loss: 0.116868
DEBUG:root:[ Iteration 174 ] Training loss: 0.121304
DEBUG:root:[ Iteration 177 ] Training loss: 0.119805
DEBUG:root:[ Iteration 180 ] Training loss: 0.132372
DEBUG:root:[ Iteration 180 ] Test loss: 0.132114
DEBUG:root:[ Iteration 183 ] Training loss: 0.13667
DEBUG:root:[ Iteration 186 ] Training loss: 0.118312
DEBUG:root:[ Iteration 189 ] Training loss: 0.122916
DEBUG:root:[ Iteration 192 ] Training loss: 0.132281
DEBUG:root:[ Iteration 195 ] Training loss: 0.126608
DEBUG:root:[ Iteration 198 ] Training loss: 0.11893
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-15-2016_12h48m51s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.134029
DEBUG:root:[ Iteration 0 ] Test loss: 0.131742
DEBUG:root:[ Iteration 3 ] Training loss: 0.122359
DEBUG:root:[ Iteration 6 ] Training loss: 0.124041
DEBUG:root:[ Iteration 9 ] Training loss: 0.125284
DEBUG:root:[ Iteration 12 ] Training loss: 0.130677
DEBUG:root:[ Iteration 15 ] Training loss: 0.127507
DEBUG:root:[ Iteration 18 ] Training loss: 0.13131
DEBUG:root:[ Iteration 20 ] Test loss: 0.131284
DEBUG:root:[ Iteration 21 ] Training loss: 0.12447
DEBUG:root:[ Iteration 24 ] Training loss: 0.123738
DEBUG:root:[ Iteration 27 ] Training loss: 0.124976
DEBUG:root:[ Iteration 30 ] Training loss: 0.130955
DEBUG:root:[ Iteration 33 ] Training loss: 0.131952
DEBUG:root:[ Iteration 36 ] Training loss: 0.131195
DEBUG:root:[ Iteration 39 ] Training loss: 0.12235
DEBUG:root:[ Iteration 40 ] Test loss: 0.131011
DEBUG:root:[ Iteration 42 ] Training loss: 0.133362
DEBUG:root:[ Iteration 45 ] Training loss: 0.127361
DEBUG:root:[ Iteration 48 ] Training loss: 0.121394
DEBUG:root:[ Iteration 51 ] Training loss: 0.110515
DEBUG:root:[ Iteration 54 ] Training loss: 0.133534
DEBUG:root:[ Iteration 57 ] Training loss: 0.124112
DEBUG:root:[ Iteration 60 ] Training loss: 0.131603
DEBUG:root:[ Iteration 60 ] Test loss: 0.130626
DEBUG:root:[ Iteration 63 ] Training loss: 0.114665
DEBUG:root:[ Iteration 66 ] Training loss: 0.124101
DEBUG:root:[ Iteration 69 ] Training loss: 0.118172
DEBUG:root:[ Iteration 72 ] Training loss: 0.115442
DEBUG:root:[ Iteration 75 ] Training loss: 0.141035
DEBUG:root:[ Iteration 78 ] Training loss: 0.122226
DEBUG:root:[ Iteration 80 ] Test loss: 0.130295
DEBUG:root:[ Iteration 81 ] Training loss: 0.11738
DEBUG:root:[ Iteration 84 ] Training loss: 0.114805
DEBUG:root:[ Iteration 87 ] Training loss: 0.117079
DEBUG:root:[ Iteration 90 ] Training loss: 0.129824
DEBUG:root:[ Iteration 93 ] Training loss: 0.116034
DEBUG:root:[ Iteration 96 ] Training loss: 0.142086
DEBUG:root:[ Iteration 99 ] Training loss: 0.122348
DEBUG:root:[ Iteration 100 ] Test loss: 0.130024
DEBUG:root:[ Iteration 102 ] Training loss: 0.133794
DEBUG:root:[ Iteration 105 ] Training loss: 0.122147
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.680741
DEBUG:root:[ Iteration 0 ] Test loss: 0.698288
DEBUG:root:[ Iteration 0 ] Training loss: 0.542222
DEBUG:root:[ Iteration 0 ] Test loss: 0.477242
DEBUG:root:[ Iteration 3 ] Training loss: 0.378234
DEBUG:root:[ Iteration 6 ] Training loss: 0.32523
DEBUG:root:[ Iteration 9 ] Training loss: 0.361871
DEBUG:root:[ Iteration 12 ] Training loss: 0.23526
DEBUG:root:[ Iteration 15 ] Training loss: 0.253741
DEBUG:root:[ Iteration 18 ] Training loss: 0.242699
DEBUG:root:[ Iteration 20 ] Test loss: 0.259008
DEBUG:root:[ Iteration 21 ] Training loss: 0.226739
DEBUG:root:[ Iteration 24 ] Training loss: 0.237972
DEBUG:root:[ Iteration 27 ] Training loss: 0.194077
DEBUG:root:[ Iteration 30 ] Training loss: 0.245766
DEBUG:root:[ Iteration 33 ] Training loss: 0.203908
DEBUG:root:[ Iteration 36 ] Training loss: 0.168665
DEBUG:root:[ Iteration 39 ] Training loss: 0.15879
DEBUG:root:[ Iteration 40 ] Test loss: 0.174787
DEBUG:root:[ Iteration 42 ] Training loss: 0.200719
DEBUG:root:[ Iteration 45 ] Training loss: 0.170061
DEBUG:root:[ Iteration 48 ] Training loss: 0.182317
DEBUG:root:[ Iteration 51 ] Training loss: 0.186176
DEBUG:root:[ Iteration 54 ] Training loss: 0.149352
DEBUG:root:[ Iteration 57 ] Training loss: 0.168221
DEBUG:root:[ Iteration 60 ] Training loss: 0.168657
DEBUG:root:[ Iteration 60 ] Test loss: 0.149366
DEBUG:root:[ Iteration 63 ] Training loss: 0.143689
DEBUG:root:[ Iteration 66 ] Training loss: 0.141336
DEBUG:root:[ Iteration 69 ] Training loss: 0.128344
DEBUG:root:[ Iteration 72 ] Training loss: 0.166366
DEBUG:root:[ Iteration 75 ] Training loss: 0.146576
DEBUG:root:[ Iteration 78 ] Training loss: 0.140626
DEBUG:root:[ Iteration 80 ] Test loss: 0.137041
DEBUG:root:[ Iteration 81 ] Training loss: 0.19446
DEBUG:root:[ Iteration 84 ] Training loss: 0.140973
DEBUG:root:[ Iteration 87 ] Training loss: 0.144235
DEBUG:root:[ Iteration 90 ] Training loss: 0.108227
DEBUG:root:[ Iteration 93 ] Training loss: 0.119521
DEBUG:root:[ Iteration 96 ] Training loss: 0.135227
DEBUG:root:[ Iteration 99 ] Training loss: 0.149005
DEBUG:root:[ Iteration 100 ] Test loss: 0.132857
DEBUG:root:[ Iteration 102 ] Training loss: 0.138258
DEBUG:root:[ Iteration 105 ] Training loss: 0.116177
DEBUG:root:[ Iteration 108 ] Training loss: 0.143794
DEBUG:root:[ Iteration 111 ] Training loss: 0.129642
DEBUG:root:[ Iteration 114 ] Training loss: 0.116737
DEBUG:root:[ Iteration 117 ] Training loss: 0.162632
DEBUG:root:[ Iteration 120 ] Training loss: 0.114155
DEBUG:root:[ Iteration 120 ] Test loss: 0.127118
DEBUG:root:[ Iteration 123 ] Training loss: 0.132674
DEBUG:root:[ Iteration 126 ] Training loss: 0.129771
DEBUG:root:[ Iteration 129 ] Training loss: 0.120995
DEBUG:root:[ Iteration 132 ] Training loss: 0.114147
DEBUG:root:[ Iteration 135 ] Training loss: 0.149544
DEBUG:root:[ Iteration 138 ] Training loss: 0.143253
DEBUG:root:[ Iteration 140 ] Test loss: 0.120686
DEBUG:root:[ Iteration 141 ] Training loss: 0.118262
DEBUG:root:[ Iteration 144 ] Training loss: 0.121839
DEBUG:root:[ Iteration 147 ] Training loss: 0.120908
DEBUG:root:[ Iteration 150 ] Training loss: 0.115537
DEBUG:root:[ Iteration 153 ] Training loss: 0.12518
DEBUG:root:[ Iteration 156 ] Training loss: 0.117498
DEBUG:root:[ Iteration 159 ] Training loss: 0.122495
DEBUG:root:[ Iteration 160 ] Test loss: 0.116777
DEBUG:root:[ Iteration 162 ] Training loss: 0.118593
DEBUG:root:[ Iteration 165 ] Training loss: 0.102919
DEBUG:root:[ Iteration 168 ] Training loss: 0.127421
DEBUG:root:[ Iteration 171 ] Training loss: 0.102137
DEBUG:root:[ Iteration 174 ] Training loss: 0.148283
DEBUG:root:[ Iteration 177 ] Training loss: 0.138579
DEBUG:root:[ Iteration 180 ] Training loss: 0.139621
DEBUG:root:[ Iteration 180 ] Test loss: 0.114831
DEBUG:root:[ Iteration 183 ] Training loss: 0.129803
DEBUG:root:[ Iteration 186 ] Training loss: 0.136717
DEBUG:root:[ Iteration 189 ] Training loss: 0.112552
DEBUG:root:[ Iteration 192 ] Training loss: 0.101781
DEBUG:root:[ Iteration 195 ] Training loss: 0.136025
DEBUG:root:[ Iteration 198 ] Training loss: 0.113399
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net6/net6_02-15-2016_13h29m29s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.736196
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.128512
DEBUG:root:[ Iteration 0 ] Test loss: 0.113351
DEBUG:root:[ Iteration 3 ] Training loss: 0.102719
DEBUG:root:[ Iteration 6 ] Training loss: 0.12465
DEBUG:root:[ Iteration 9 ] Training loss: 0.122578
DEBUG:root:[ Iteration 12 ] Training loss: 0.115419
DEBUG:root:[ Iteration 15 ] Training loss: 0.102003
DEBUG:root:[ Iteration 18 ] Training loss: 0.118328
DEBUG:root:[ Iteration 20 ] Test loss: 0.112278
DEBUG:root:[ Iteration 21 ] Training loss: 0.110736
DEBUG:root:[ Iteration 24 ] Training loss: 0.0951936
DEBUG:root:[ Iteration 27 ] Training loss: 0.1158
DEBUG:root:[ Iteration 30 ] Training loss: 0.105534
DEBUG:root:[ Iteration 33 ] Training loss: 0.110213
DEBUG:root:[ Iteration 36 ] Training loss: 0.0958546
DEBUG:root:[ Iteration 39 ] Training loss: 0.14163
DEBUG:root:[ Iteration 40 ] Test loss: 0.113104
DEBUG:root:[ Iteration 42 ] Training loss: 0.120737
DEBUG:root:[ Iteration 45 ] Training loss: 0.125917
DEBUG:root:[ Iteration 48 ] Training loss: 0.135109
DEBUG:root:[ Iteration 51 ] Training loss: 0.114595
DEBUG:root:[ Iteration 54 ] Training loss: 0.105075
DEBUG:root:[ Iteration 57 ] Training loss: 0.109014
DEBUG:root:[ Iteration 60 ] Training loss: 0.133503
DEBUG:root:[ Iteration 60 ] Test loss: 0.109558
DEBUG:root:[ Iteration 63 ] Training loss: 0.0960028
DEBUG:root:[ Iteration 66 ] Training loss: 0.116799
DEBUG:root:[ Iteration 69 ] Training loss: 0.0924438
DEBUG:root:[ Iteration 72 ] Training loss: 0.116216
DEBUG:root:[ Iteration 75 ] Training loss: 0.113413
DEBUG:root:[ Iteration 78 ] Training loss: 0.132551
DEBUG:root:[ Iteration 80 ] Test loss: 0.109271
DEBUG:root:[ Iteration 81 ] Training loss: 0.132717
DEBUG:root:[ Iteration 84 ] Training loss: 0.140909
DEBUG:root:[ Iteration 87 ] Training loss: 0.088364
DEBUG:root:[ Iteration 90 ] Training loss: 0.104079
DEBUG:root:[ Iteration 93 ] Training loss: 0.102339
DEBUG:root:[ Iteration 96 ] Training loss: 0.12518
DEBUG:root:[ Iteration 99 ] Training loss: 0.108485
DEBUG:root:[ Iteration 100 ] Test loss: 0.106893
DEBUG:root:[ Iteration 102 ] Training loss: 0.10598
DEBUG:root:[ Iteration 105 ] Training loss: 0.100287
DEBUG:root:[ Iteration 108 ] Training loss: 0.0981877
DEBUG:root:[ Iteration 111 ] Training loss: 0.10179
DEBUG:root:[ Iteration 114 ] Training loss: 0.105573
DEBUG:root:[ Iteration 117 ] Training loss: 0.0940692
DEBUG:root:[ Iteration 120 ] Training loss: 0.127544
DEBUG:root:[ Iteration 120 ] Test loss: 0.108476
DEBUG:root:[ Iteration 123 ] Training loss: 0.102371
DEBUG:root:[ Iteration 126 ] Training loss: 0.102103
DEBUG:root:[ Iteration 129 ] Training loss: 0.0977843
DEBUG:root:[ Iteration 132 ] Training loss: 0.0867964
DEBUG:root:[ Iteration 135 ] Training loss: 0.107994
DEBUG:root:[ Iteration 138 ] Training loss: 0.131411
DEBUG:root:[ Iteration 140 ] Test loss: 0.108203
DEBUG:root:[ Iteration 141 ] Training loss: 0.142631
DEBUG:root:[ Iteration 144 ] Training loss: 0.121555
DEBUG:root:[ Iteration 147 ] Training loss: 0.125996
DEBUG:root:[ Iteration 150 ] Training loss: 0.095924
DEBUG:root:[ Iteration 153 ] Training loss: 0.0992566
DEBUG:root:[ Iteration 156 ] Training loss: 0.102172
DEBUG:root:[ Iteration 159 ] Training loss: 0.0970656
DEBUG:root:[ Iteration 160 ] Test loss: 0.106058
DEBUG:root:[ Iteration 162 ] Training loss: 0.095325
DEBUG:root:[ Iteration 165 ] Training loss: 0.0957922
DEBUG:root:[ Iteration 168 ] Training loss: 0.0878445
DEBUG:root:[ Iteration 171 ] Training loss: 0.101606
DEBUG:root:[ Iteration 174 ] Training loss: 0.121797
DEBUG:root:[ Iteration 177 ] Training loss: 0.111145
DEBUG:root:[ Iteration 180 ] Training loss: 0.114908
DEBUG:root:[ Iteration 180 ] Test loss: 0.105151
DEBUG:root:[ Iteration 183 ] Training loss: 0.10743
DEBUG:root:[ Iteration 186 ] Training loss: 0.111187
DEBUG:root:[ Iteration 189 ] Training loss: 0.0953474
DEBUG:root:[ Iteration 192 ] Training loss: 0.10429
DEBUG:root:[ Iteration 195 ] Training loss: 0.0964178
DEBUG:root:[ Iteration 198 ] Training loss: 0.100739
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.123312
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.133029
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net6/net6_02-15-2016_13h44m16s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.119189
DEBUG:root:[ Iteration 0 ] Test loss: 0.11335
DEBUG:root:[ Iteration 3 ] Training loss: 0.110114
DEBUG:root:[ Iteration 6 ] Training loss: 0.10752
DEBUG:root:[ Iteration 9 ] Training loss: 0.108812
DEBUG:root:[ Iteration 12 ] Training loss: 0.133335
DEBUG:root:[ Iteration 15 ] Training loss: 0.112957
DEBUG:root:[ Iteration 18 ] Training loss: 0.129161
DEBUG:root:[ Iteration 20 ] Test loss: 0.112202
DEBUG:root:[ Iteration 21 ] Training loss: 0.113814
DEBUG:root:[ Iteration 24 ] Training loss: 0.113295
DEBUG:root:[ Iteration 27 ] Training loss: 0.136231
DEBUG:root:[ Iteration 30 ] Training loss: 0.117016
DEBUG:root:[ Iteration 33 ] Training loss: 0.109096
DEBUG:root:[ Iteration 36 ] Training loss: 0.0935028
DEBUG:root:[ Iteration 39 ] Training loss: 0.123792
DEBUG:root:[ Iteration 40 ] Test loss: 0.110565
DEBUG:root:[ Iteration 42 ] Training loss: 0.111226
DEBUG:root:[ Iteration 45 ] Training loss: 0.078434
DEBUG:root:[ Iteration 48 ] Training loss: 0.105718
DEBUG:root:[ Iteration 51 ] Training loss: 0.113818
DEBUG:root:[ Iteration 54 ] Training loss: 0.105794
DEBUG:root:[ Iteration 57 ] Training loss: 0.116589
DEBUG:root:[ Iteration 60 ] Training loss: 0.114638
DEBUG:root:[ Iteration 60 ] Test loss: 0.109811
DEBUG:root:[ Iteration 63 ] Training loss: 0.101608
DEBUG:root:[ Iteration 66 ] Training loss: 0.105813
DEBUG:root:[ Iteration 69 ] Training loss: 0.104291
DEBUG:root:[ Iteration 72 ] Training loss: 0.101696
DEBUG:root:[ Iteration 75 ] Training loss: 0.117739
DEBUG:root:[ Iteration 78 ] Training loss: 0.121253
DEBUG:root:[ Iteration 80 ] Test loss: 0.107976
DEBUG:root:[ Iteration 81 ] Training loss: 0.11793
DEBUG:root:[ Iteration 84 ] Training loss: 0.106399
DEBUG:root:[ Iteration 87 ] Training loss: 0.103286
DEBUG:root:[ Iteration 90 ] Training loss: 0.108926
DEBUG:root:[ Iteration 93 ] Training loss: 0.117188
DEBUG:root:[ Iteration 96 ] Training loss: 0.10679
DEBUG:root:[ Iteration 99 ] Training loss: 0.109458
DEBUG:root:[ Iteration 100 ] Test loss: 0.107238
DEBUG:root:[ Iteration 102 ] Training loss: 0.13517
DEBUG:root:[ Iteration 105 ] Training loss: 0.115945
DEBUG:root:[ Iteration 108 ] Training loss: 0.107733
DEBUG:root:[ Iteration 111 ] Training loss: 0.0903432
DEBUG:root:[ Iteration 114 ] Training loss: 0.103768
DEBUG:root:[ Iteration 117 ] Training loss: 0.126736
DEBUG:root:[ Iteration 120 ] Training loss: 0.0966899
DEBUG:root:[ Iteration 120 ] Test loss: 0.107369
DEBUG:root:[ Iteration 123 ] Training loss: 0.0942526
DEBUG:root:[ Iteration 126 ] Training loss: 0.0945421
DEBUG:root:[ Iteration 129 ] Training loss: 0.105493
DEBUG:root:[ Iteration 132 ] Training loss: 0.106836
DEBUG:root:[ Iteration 135 ] Training loss: 0.104689
DEBUG:root:[ Iteration 138 ] Training loss: 0.0908785
DEBUG:root:[ Iteration 140 ] Test loss: 0.104872
DEBUG:root:[ Iteration 141 ] Training loss: 0.115012
DEBUG:root:[ Iteration 144 ] Training loss: 0.121201
DEBUG:root:[ Iteration 147 ] Training loss: 0.104571
DEBUG:root:[ Iteration 150 ] Training loss: 0.101475
DEBUG:root:[ Iteration 153 ] Training loss: 0.115572
DEBUG:root:[ Iteration 156 ] Training loss: 0.103851
DEBUG:root:[ Iteration 159 ] Training loss: 0.100552
DEBUG:root:[ Iteration 160 ] Test loss: 0.104267
DEBUG:root:[ Iteration 162 ] Training loss: 0.110361
DEBUG:root:[ Iteration 165 ] Training loss: 0.103709
DEBUG:root:[ Iteration 168 ] Training loss: 0.0969238
DEBUG:root:[ Iteration 171 ] Training loss: 0.111408
DEBUG:root:[ Iteration 174 ] Training loss: 0.100297
DEBUG:root:[ Iteration 177 ] Training loss: 0.120532
DEBUG:root:[ Iteration 180 ] Training loss: 0.100439
DEBUG:root:[ Iteration 180 ] Test loss: 0.103237
DEBUG:root:[ Iteration 183 ] Training loss: 0.0873775
DEBUG:root:[ Iteration 186 ] Training loss: 0.0960252
DEBUG:root:[ Iteration 189 ] Training loss: 0.0998988
DEBUG:root:[ Iteration 192 ] Training loss: 0.0987946
DEBUG:root:[ Iteration 195 ] Training loss: 0.0907203
DEBUG:root:[ Iteration 198 ] Training loss: 0.10667
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net6/net6_02-15-2016_13h48m35s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.10129
DEBUG:root:[ Iteration 0 ] Test loss: 0.103436
DEBUG:root:[ Iteration 3 ] Training loss: 0.103642
DEBUG:root:[ Iteration 6 ] Training loss: 0.107876
DEBUG:root:[ Iteration 9 ] Training loss: 0.0968528
DEBUG:root:[ Iteration 12 ] Training loss: 0.102248
DEBUG:root:[ Iteration 15 ] Training loss: 0.0953402
DEBUG:root:[ Iteration 18 ] Training loss: 0.10794
DEBUG:root:[ Iteration 20 ] Test loss: 0.103737
DEBUG:root:[ Iteration 21 ] Training loss: 0.10275
DEBUG:root:[ Iteration 24 ] Training loss: 0.0962745
DEBUG:root:[ Iteration 27 ] Training loss: 0.0705856
DEBUG:root:[ Iteration 30 ] Training loss: 0.0979792
DEBUG:root:[ Iteration 33 ] Training loss: 0.114157
DEBUG:root:[ Iteration 36 ] Training loss: 0.0986293
DEBUG:root:[ Iteration 39 ] Training loss: 0.0963812
DEBUG:root:[ Iteration 40 ] Test loss: 0.100782
DEBUG:root:[ Iteration 42 ] Training loss: 0.104023
DEBUG:root:[ Iteration 45 ] Training loss: 0.0822531
DEBUG:root:[ Iteration 48 ] Training loss: 0.0922795
DEBUG:root:[ Iteration 51 ] Training loss: 0.101556
DEBUG:root:[ Iteration 54 ] Training loss: 0.0913708
DEBUG:root:[ Iteration 57 ] Training loss: 0.0915227
DEBUG:root:[ Iteration 60 ] Training loss: 0.104911
DEBUG:root:[ Iteration 60 ] Test loss: 0.0997215
DEBUG:root:[ Iteration 63 ] Training loss: 0.110762
DEBUG:root:[ Iteration 66 ] Training loss: 0.0879966
DEBUG:root:[ Iteration 69 ] Training loss: 0.0981693
DEBUG:root:[ Iteration 72 ] Training loss: 0.102336
DEBUG:root:[ Iteration 75 ] Training loss: 0.121293
DEBUG:root:[ Iteration 78 ] Training loss: 0.109288
DEBUG:root:[ Iteration 80 ] Test loss: 0.0986863
DEBUG:root:[ Iteration 81 ] Training loss: 0.0824973
DEBUG:root:[ Iteration 84 ] Training loss: 0.0964464
DEBUG:root:[ Iteration 87 ] Training loss: 0.0767409
DEBUG:root:[ Iteration 90 ] Training loss: 0.0973205
DEBUG:root:[ Iteration 93 ] Training loss: 0.132461
DEBUG:root:[ Iteration 96 ] Training loss: 0.0794681
DEBUG:root:[ Iteration 99 ] Training loss: 0.0941559
DEBUG:root:[ Iteration 100 ] Test loss: 0.0977624
DEBUG:root:[ Iteration 102 ] Training loss: 0.105686
DEBUG:root:[ Iteration 105 ] Training loss: 0.123835
DEBUG:root:[ Iteration 108 ] Training loss: 0.0828095
DEBUG:root:[ Iteration 111 ] Training loss: 0.0920884
DEBUG:root:[ Iteration 114 ] Training loss: 0.0862641
DEBUG:root:[ Iteration 117 ] Training loss: 0.0987314
DEBUG:root:[ Iteration 120 ] Training loss: 0.103442
DEBUG:root:[ Iteration 120 ] Test loss: 0.098037
DEBUG:root:[ Iteration 123 ] Training loss: 0.0950995
DEBUG:root:[ Iteration 126 ] Training loss: 0.0817248
DEBUG:root:[ Iteration 129 ] Training loss: 0.0939955
DEBUG:root:[ Iteration 132 ] Training loss: 0.093302
DEBUG:root:[ Iteration 135 ] Training loss: 0.0981713
DEBUG:root:[ Iteration 138 ] Training loss: 0.0970903
DEBUG:root:[ Iteration 140 ] Test loss: 0.0961633
DEBUG:root:[ Iteration 141 ] Training loss: 0.102649
DEBUG:root:[ Iteration 144 ] Training loss: 0.0942431
DEBUG:root:[ Iteration 147 ] Training loss: 0.0860566
DEBUG:root:[ Iteration 150 ] Training loss: 0.102258
DEBUG:root:[ Iteration 153 ] Training loss: 0.0681115
DEBUG:root:[ Iteration 156 ] Training loss: 0.0941001
DEBUG:root:[ Iteration 159 ] Training loss: 0.100297
DEBUG:root:[ Iteration 160 ] Test loss: 0.0956383
DEBUG:root:[ Iteration 162 ] Training loss: 0.101699
DEBUG:root:[ Iteration 165 ] Training loss: 0.092614
DEBUG:root:[ Iteration 168 ] Training loss: 0.110809
DEBUG:root:[ Iteration 171 ] Training loss: 0.105897
DEBUG:root:[ Iteration 174 ] Training loss: 0.108216
DEBUG:root:[ Iteration 177 ] Training loss: 0.0821529
DEBUG:root:[ Iteration 180 ] Training loss: 0.092768
DEBUG:root:[ Iteration 180 ] Test loss: 0.0951607
DEBUG:root:[ Iteration 183 ] Training loss: 0.10519
DEBUG:root:[ Iteration 186 ] Training loss: 0.0774215
DEBUG:root:[ Iteration 189 ] Training loss: 0.0921951
DEBUG:root:[ Iteration 192 ] Training loss: 0.0899538
DEBUG:root:[ Iteration 195 ] Training loss: 0.0893446
DEBUG:root:[ Iteration 198 ] Training loss: 0.0837681
DEBUG:root:[ Iteration 200 ] Test loss: 0.0938902
DEBUG:root:[ Iteration 201 ] Training loss: 0.104305
DEBUG:root:[ Iteration 204 ] Training loss: 0.106954
DEBUG:root:[ Iteration 207 ] Training loss: 0.0838279
DEBUG:root:[ Iteration 210 ] Training loss: 0.110953
DEBUG:root:[ Iteration 213 ] Training loss: 0.0842635
DEBUG:root:[ Iteration 216 ] Training loss: 0.0883103
DEBUG:root:[ Iteration 219 ] Training loss: 0.0919074
DEBUG:root:[ Iteration 220 ] Test loss: 0.0932788
DEBUG:root:[ Iteration 222 ] Training loss: 0.0913478
DEBUG:root:[ Iteration 225 ] Training loss: 0.102491
DEBUG:root:[ Iteration 228 ] Training loss: 0.0842305
DEBUG:root:[ Iteration 231 ] Training loss: 0.0926299
DEBUG:root:[ Iteration 234 ] Training loss: 0.098329
DEBUG:root:[ Iteration 237 ] Training loss: 0.0837995
DEBUG:root:[ Iteration 240 ] Training loss: 0.0825771
DEBUG:root:[ Iteration 240 ] Test loss: 0.0933612
DEBUG:root:[ Iteration 243 ] Training loss: 0.0770338
DEBUG:root:[ Iteration 246 ] Training loss: 0.0967049
DEBUG:root:[ Iteration 249 ] Training loss: 0.0763203
DEBUG:root:[ Iteration 252 ] Training loss: 0.100426
DEBUG:root:[ Iteration 255 ] Training loss: 0.0878457
DEBUG:root:[ Iteration 258 ] Training loss: 0.085398
DEBUG:root:[ Iteration 260 ] Test loss: 0.0917435
DEBUG:root:[ Iteration 261 ] Training loss: 0.0963184
DEBUG:root:[ Iteration 264 ] Training loss: 0.0853424
DEBUG:root:[ Iteration 267 ] Training loss: 0.0873075
DEBUG:root:[ Iteration 270 ] Training loss: 0.105692
DEBUG:root:[ Iteration 273 ] Training loss: 0.0934893
DEBUG:root:[ Iteration 276 ] Training loss: 0.101669
DEBUG:root:[ Iteration 279 ] Training loss: 0.0957656
DEBUG:root:[ Iteration 280 ] Test loss: 0.0914243
DEBUG:root:[ Iteration 282 ] Training loss: 0.0874146
DEBUG:root:[ Iteration 285 ] Training loss: 0.0852114
DEBUG:root:[ Iteration 288 ] Training loss: 0.0902067
DEBUG:root:[ Iteration 291 ] Training loss: 0.0742364
DEBUG:root:[ Iteration 294 ] Training loss: 0.0978371
DEBUG:root:[ Iteration 297 ] Training loss: 0.0953097
DEBUG:root:[ Iteration 300 ] Training loss: 0.0721929
DEBUG:root:[ Iteration 300 ] Test loss: 0.0905916
DEBUG:root:[ Iteration 303 ] Training loss: 0.0875486
DEBUG:root:[ Iteration 306 ] Training loss: 0.093289
DEBUG:root:[ Iteration 309 ] Training loss: 0.0759501
DEBUG:root:[ Iteration 312 ] Training loss: 0.0911291
DEBUG:root:[ Iteration 315 ] Training loss: 0.0799277
DEBUG:root:[ Iteration 318 ] Training loss: 0.0846449
DEBUG:root:[ Iteration 320 ] Test loss: 0.0896681
DEBUG:root:[ Iteration 321 ] Training loss: 0.105043
DEBUG:root:[ Iteration 324 ] Training loss: 0.0845488
DEBUG:root:[ Iteration 327 ] Training loss: 0.096545
DEBUG:root:[ Iteration 330 ] Training loss: 0.0828573
DEBUG:root:[ Iteration 333 ] Training loss: 0.0967525
DEBUG:root:[ Iteration 336 ] Training loss: 0.0682163
DEBUG:root:[ Iteration 339 ] Training loss: 0.0844021
DEBUG:root:[ Iteration 340 ] Test loss: 0.0890553
DEBUG:root:[ Iteration 342 ] Training loss: 0.0748248
DEBUG:root:[ Iteration 345 ] Training loss: 0.0971247
DEBUG:root:[ Iteration 348 ] Training loss: 0.0829332
DEBUG:root:[ Iteration 351 ] Training loss: 0.0961045
DEBUG:root:[ Iteration 354 ] Training loss: 0.0805125
DEBUG:root:[ Iteration 357 ] Training loss: 0.0888349
DEBUG:root:[ Iteration 360 ] Training loss: 0.0855489
DEBUG:root:[ Iteration 360 ] Test loss: 0.088167
DEBUG:root:[ Iteration 363 ] Training loss: 0.0821129
DEBUG:root:[ Iteration 366 ] Training loss: 0.0876065
DEBUG:root:[ Iteration 369 ] Training loss: 0.0946883
DEBUG:root:[ Iteration 372 ] Training loss: 0.0861949
DEBUG:root:[ Iteration 375 ] Training loss: 0.0747334
DEBUG:root:[ Iteration 378 ] Training loss: 0.0908182
DEBUG:root:[ Iteration 380 ] Test loss: 0.0902299
DEBUG:root:[ Iteration 381 ] Training loss: 0.0856411
DEBUG:root:[ Iteration 384 ] Training loss: 0.0961682
DEBUG:root:[ Iteration 387 ] Training loss: 0.0784799
DEBUG:root:[ Iteration 390 ] Training loss: 0.0882843
DEBUG:root:[ Iteration 393 ] Training loss: 0.0817166
DEBUG:root:[ Iteration 396 ] Training loss: 0.094608
DEBUG:root:[ Iteration 399 ] Training loss: 0.0846519
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net6/net6_02-15-2016_13h57m43s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.550097
DEBUG:root:[ Iteration 0 ] Test loss: 0.554209
DEBUG:root:[ Iteration 0 ] Training loss: 0.554746
DEBUG:root:[ Iteration 0 ] Test loss: 0.511749
DEBUG:root:[ Iteration 3 ] Training loss: 0.424506
DEBUG:root:[ Iteration 6 ] Training loss: 0.387756
DEBUG:root:[ Iteration 9 ] Training loss: 0.323816
DEBUG:root:[ Iteration 12 ] Training loss: 0.329896
DEBUG:root:[ Iteration 15 ] Training loss: 0.31825
DEBUG:root:[ Iteration 18 ] Training loss: 0.273847
DEBUG:root:[ Iteration 20 ] Test loss: 0.292394
DEBUG:root:[ Iteration 21 ] Training loss: 0.296242
DEBUG:root:[ Iteration 24 ] Training loss: 0.291828
DEBUG:root:[ Iteration 27 ] Training loss: 0.270209
DEBUG:root:[ Iteration 30 ] Training loss: 0.238
DEBUG:root:[ Iteration 33 ] Training loss: 0.251161
DEBUG:root:[ Iteration 36 ] Training loss: 0.221567
DEBUG:root:[ Iteration 39 ] Training loss: 0.255125
DEBUG:root:[ Iteration 40 ] Test loss: 0.234138
DEBUG:root:[ Iteration 42 ] Training loss: 0.254024
DEBUG:root:[ Iteration 45 ] Training loss: 0.220591
DEBUG:root:[ Iteration 48 ] Training loss: 0.230891
DEBUG:root:[ Iteration 51 ] Training loss: 0.189414
DEBUG:root:[ Iteration 54 ] Training loss: 0.242858
DEBUG:root:[ Iteration 57 ] Training loss: 0.175212
DEBUG:root:[ Iteration 60 ] Training loss: 0.197568
DEBUG:root:[ Iteration 60 ] Test loss: 0.186863
DEBUG:root:[ Iteration 63 ] Training loss: 0.193498
DEBUG:root:[ Iteration 66 ] Training loss: 0.16961
DEBUG:root:[ Iteration 69 ] Training loss: 0.167491
DEBUG:root:[ Iteration 72 ] Training loss: 0.158946
DEBUG:root:[ Iteration 75 ] Training loss: 0.151529
DEBUG:root:[ Iteration 78 ] Training loss: 0.155857
DEBUG:root:[ Iteration 80 ] Test loss: 0.153415
DEBUG:root:[ Iteration 81 ] Training loss: 0.145133
DEBUG:root:[ Iteration 84 ] Training loss: 0.181868
DEBUG:root:[ Iteration 87 ] Training loss: 0.15249
DEBUG:root:[ Iteration 90 ] Training loss: 0.158486
DEBUG:root:[ Iteration 93 ] Training loss: 0.155873
DEBUG:root:[ Iteration 96 ] Training loss: 0.131188
DEBUG:root:[ Iteration 99 ] Training loss: 0.137412
DEBUG:root:[ Iteration 100 ] Test loss: 0.139431
DEBUG:root:[ Iteration 102 ] Training loss: 0.162786
DEBUG:root:[ Iteration 105 ] Training loss: 0.147165
DEBUG:root:[ Iteration 108 ] Training loss: 0.131567
DEBUG:root:[ Iteration 111 ] Training loss: 0.155772
DEBUG:root:[ Iteration 114 ] Training loss: 0.131626
DEBUG:root:[ Iteration 117 ] Training loss: 0.122157
DEBUG:root:[ Iteration 120 ] Training loss: 0.127891
DEBUG:root:[ Iteration 120 ] Test loss: 0.131365
DEBUG:root:[ Iteration 123 ] Training loss: 0.131743
DEBUG:root:[ Iteration 126 ] Training loss: 0.126641
DEBUG:root:[ Iteration 129 ] Training loss: 0.140945
DEBUG:root:[ Iteration 132 ] Training loss: 0.115023
DEBUG:root:[ Iteration 135 ] Training loss: 0.12856
DEBUG:root:[ Iteration 138 ] Training loss: 0.145268
DEBUG:root:[ Iteration 140 ] Test loss: 0.125732
DEBUG:root:[ Iteration 141 ] Training loss: 0.113449
DEBUG:root:[ Iteration 144 ] Training loss: 0.108863
DEBUG:root:[ Iteration 147 ] Training loss: 0.135433
DEBUG:root:[ Iteration 150 ] Training loss: 0.168044
DEBUG:root:[ Iteration 153 ] Training loss: 0.114587
DEBUG:root:[ Iteration 156 ] Training loss: 0.133125
DEBUG:root:[ Iteration 159 ] Training loss: 0.123201
DEBUG:root:[ Iteration 160 ] Test loss: 0.121394
DEBUG:root:[ Iteration 162 ] Training loss: 0.118945
DEBUG:root:[ Iteration 165 ] Training loss: 0.12782
DEBUG:root:[ Iteration 168 ] Training loss: 0.122252
DEBUG:root:[ Iteration 171 ] Training loss: 0.116479
DEBUG:root:[ Iteration 174 ] Training loss: 0.125393
DEBUG:root:[ Iteration 177 ] Training loss: 0.112016
DEBUG:root:[ Iteration 180 ] Training loss: 0.10617
DEBUG:root:[ Iteration 180 ] Test loss: 0.118048
DEBUG:root:[ Iteration 183 ] Training loss: 0.118524
DEBUG:root:[ Iteration 186 ] Training loss: 0.137606
DEBUG:root:[ Iteration 189 ] Training loss: 0.114333
DEBUG:root:[ Iteration 192 ] Training loss: 0.110767
DEBUG:root:[ Iteration 195 ] Training loss: 0.126068
DEBUG:root:[ Iteration 198 ] Training loss: 0.116438
DEBUG:root:[ Iteration 200 ] Test loss: 0.115562
DEBUG:root:[ Iteration 201 ] Training loss: 0.122343
DEBUG:root:[ Iteration 204 ] Training loss: 0.119509
DEBUG:root:[ Iteration 207 ] Training loss: 0.120092
DEBUG:root:[ Iteration 210 ] Training loss: 0.107711
DEBUG:root:[ Iteration 213 ] Training loss: 0.10826
DEBUG:root:[ Iteration 216 ] Training loss: 0.104613
DEBUG:root:[ Iteration 219 ] Training loss: 0.114076
DEBUG:root:[ Iteration 220 ] Test loss: 0.113629
DEBUG:root:[ Iteration 222 ] Training loss: 0.109015
DEBUG:root:[ Iteration 225 ] Training loss: 0.126791
DEBUG:root:[ Iteration 228 ] Training loss: 0.122608
DEBUG:root:[ Iteration 231 ] Training loss: 0.125567
DEBUG:root:[ Iteration 234 ] Training loss: 0.121067
DEBUG:root:[ Iteration 237 ] Training loss: 0.129687
DEBUG:root:[ Iteration 240 ] Training loss: 0.0909492
DEBUG:root:[ Iteration 240 ] Test loss: 0.112129
DEBUG:root:[ Iteration 243 ] Training loss: 0.0985657
DEBUG:root:[ Iteration 246 ] Training loss: 0.103045
DEBUG:root:[ Iteration 249 ] Training loss: 0.107786
DEBUG:root:[ Iteration 252 ] Training loss: 0.0896735
DEBUG:root:[ Iteration 255 ] Training loss: 0.104231
DEBUG:root:[ Iteration 258 ] Training loss: 0.13321
DEBUG:root:[ Iteration 260 ] Test loss: 0.110356
DEBUG:root:[ Iteration 261 ] Training loss: 0.110005
DEBUG:root:[ Iteration 264 ] Training loss: 0.101451
DEBUG:root:[ Iteration 267 ] Training loss: 0.132732
DEBUG:root:[ Iteration 270 ] Training loss: 0.098138
DEBUG:root:[ Iteration 273 ] Training loss: 0.1144
DEBUG:root:[ Iteration 276 ] Training loss: 0.107048
DEBUG:root:[ Iteration 279 ] Training loss: 0.117694
DEBUG:root:[ Iteration 280 ] Test loss: 0.108877
DEBUG:root:[ Iteration 282 ] Training loss: 0.113074
DEBUG:root:[ Iteration 285 ] Training loss: 0.118922
DEBUG:root:[ Iteration 288 ] Training loss: 0.10526
DEBUG:root:[ Iteration 291 ] Training loss: 0.100892
DEBUG:root:[ Iteration 294 ] Training loss: 0.0999168
DEBUG:root:[ Iteration 297 ] Training loss: 0.0976288
DEBUG:root:[ Iteration 300 ] Training loss: 0.109556
DEBUG:root:[ Iteration 300 ] Test loss: 0.107026
DEBUG:root:[ Iteration 303 ] Training loss: 0.113534
DEBUG:root:[ Iteration 306 ] Training loss: 0.120611
DEBUG:root:[ Iteration 309 ] Training loss: 0.106501
DEBUG:root:[ Iteration 312 ] Training loss: 0.0891278
DEBUG:root:[ Iteration 315 ] Training loss: 0.105335
DEBUG:root:[ Iteration 318 ] Training loss: 0.112364
DEBUG:root:[ Iteration 320 ] Test loss: 0.105672
DEBUG:root:[ Iteration 321 ] Training loss: 0.119368
DEBUG:root:[ Iteration 324 ] Training loss: 0.113955
DEBUG:root:[ Iteration 327 ] Training loss: 0.120967
DEBUG:root:[ Iteration 330 ] Training loss: 0.0907712
DEBUG:root:[ Iteration 333 ] Training loss: 0.133913
DEBUG:root:[ Iteration 336 ] Training loss: 0.109496
DEBUG:root:[ Iteration 339 ] Training loss: 0.126257
DEBUG:root:[ Iteration 340 ] Test loss: 0.104657
DEBUG:root:[ Iteration 342 ] Training loss: 0.100279
DEBUG:root:[ Iteration 345 ] Training loss: 0.120444
DEBUG:root:[ Iteration 348 ] Training loss: 0.101392
DEBUG:root:[ Iteration 351 ] Training loss: 0.108522
DEBUG:root:[ Iteration 354 ] Training loss: 0.0924464
DEBUG:root:[ Iteration 357 ] Training loss: 0.107393
DEBUG:root:[ Iteration 360 ] Training loss: 0.0851092
DEBUG:root:[ Iteration 360 ] Test loss: 0.103328
DEBUG:root:[ Iteration 363 ] Training loss: 0.111779
DEBUG:root:[ Iteration 366 ] Training loss: 0.115206
DEBUG:root:[ Iteration 369 ] Training loss: 0.106572
DEBUG:root:[ Iteration 372 ] Training loss: 0.104629
DEBUG:root:[ Iteration 375 ] Training loss: 0.0918817
DEBUG:root:[ Iteration 378 ] Training loss: 0.107151
DEBUG:root:[ Iteration 380 ] Test loss: 0.102173
DEBUG:root:[ Iteration 381 ] Training loss: 0.111764
DEBUG:root:[ Iteration 384 ] Training loss: 0.107121
DEBUG:root:[ Iteration 387 ] Training loss: 0.103272
DEBUG:root:[ Iteration 390 ] Training loss: 0.113833
DEBUG:root:[ Iteration 393 ] Training loss: 0.102884
DEBUG:root:[ Iteration 396 ] Training loss: 0.106313
DEBUG:root:[ Iteration 399 ] Training loss: 0.110862
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.782467
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.493393
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.392942
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.368055
DEBUG:root:[ Iteration 0 ] Test loss: 0.374361
DEBUG:root:[ Iteration 3 ] Training loss: 0.299851
DEBUG:root:[ Iteration 6 ] Training loss: 0.283034
DEBUG:root:[ Iteration 9 ] Training loss: 0.2368
DEBUG:root:[ Iteration 12 ] Training loss: 0.203583
DEBUG:root:[ Iteration 15 ] Training loss: 0.214776
DEBUG:root:[ Iteration 18 ] Training loss: 0.241186
DEBUG:root:[ Iteration 20 ] Test loss: 0.197347
DEBUG:root:[ Iteration 21 ] Training loss: 0.211921
DEBUG:root:[ Iteration 24 ] Training loss: 0.185994
DEBUG:root:[ Iteration 27 ] Training loss: 0.176041
DEBUG:root:[ Iteration 30 ] Training loss: 0.167019
DEBUG:root:[ Iteration 33 ] Training loss: 0.171738
DEBUG:root:[ Iteration 36 ] Training loss: 0.182356
DEBUG:root:[ Iteration 39 ] Training loss: 0.161762
DEBUG:root:[ Iteration 40 ] Test loss: 0.165909
DEBUG:root:[ Iteration 42 ] Training loss: 0.149759
DEBUG:root:[ Iteration 45 ] Training loss: 0.173379
DEBUG:root:[ Iteration 48 ] Training loss: 0.170151
DEBUG:root:[ Iteration 51 ] Training loss: 0.131553
DEBUG:root:[ Iteration 54 ] Training loss: 0.153842
DEBUG:root:[ Iteration 57 ] Training loss: 0.183421
DEBUG:root:[ Iteration 60 ] Training loss: 0.158391
DEBUG:root:[ Iteration 60 ] Test loss: 0.149622
DEBUG:root:[ Iteration 63 ] Training loss: 0.144953
DEBUG:root:[ Iteration 66 ] Training loss: 0.178592
DEBUG:root:[ Iteration 69 ] Training loss: 0.13595
DEBUG:root:[ Iteration 72 ] Training loss: 0.170829
DEBUG:root:[ Iteration 75 ] Training loss: 0.122804
DEBUG:root:[ Iteration 78 ] Training loss: 0.132796
DEBUG:root:[ Iteration 80 ] Test loss: 0.138669
DEBUG:root:[ Iteration 81 ] Training loss: 0.134224
DEBUG:root:[ Iteration 84 ] Training loss: 0.124933
DEBUG:root:[ Iteration 87 ] Training loss: 0.142349
DEBUG:root:[ Iteration 90 ] Training loss: 0.142061
DEBUG:root:[ Iteration 93 ] Training loss: 0.147586
DEBUG:root:[ Iteration 96 ] Training loss: 0.160352
DEBUG:root:[ Iteration 99 ] Training loss: 0.109807
DEBUG:root:[ Iteration 100 ] Test loss: 0.132532
DEBUG:root:[ Iteration 102 ] Training loss: 0.135066
DEBUG:root:[ Iteration 105 ] Training loss: 0.124143
DEBUG:root:[ Iteration 108 ] Training loss: 0.145954
DEBUG:root:[ Iteration 111 ] Training loss: 0.138219
DEBUG:root:[ Iteration 114 ] Training loss: 0.134378
DEBUG:root:[ Iteration 117 ] Training loss: 0.130145
DEBUG:root:[ Iteration 120 ] Training loss: 0.133931
DEBUG:root:[ Iteration 120 ] Test loss: 0.127933
DEBUG:root:[ Iteration 123 ] Training loss: 0.126589
DEBUG:root:[ Iteration 126 ] Training loss: 0.129318
DEBUG:root:[ Iteration 129 ] Training loss: 0.143607
DEBUG:root:[ Iteration 132 ] Training loss: 0.137866
DEBUG:root:[ Iteration 135 ] Training loss: 0.118384
DEBUG:root:[ Iteration 138 ] Training loss: 0.116068
DEBUG:root:[ Iteration 140 ] Test loss: 0.124795
DEBUG:root:[ Iteration 141 ] Training loss: 0.116611
DEBUG:root:[ Iteration 144 ] Training loss: 0.140037
DEBUG:root:[ Iteration 147 ] Training loss: 0.126125
DEBUG:root:[ Iteration 150 ] Training loss: 0.139743
DEBUG:root:[ Iteration 153 ] Training loss: 0.127323
DEBUG:root:[ Iteration 156 ] Training loss: 0.136807
DEBUG:root:[ Iteration 159 ] Training loss: 0.126928
DEBUG:root:[ Iteration 160 ] Test loss: 0.122008
DEBUG:root:[ Iteration 162 ] Training loss: 0.130153
DEBUG:root:[ Iteration 165 ] Training loss: 0.128111
DEBUG:root:[ Iteration 168 ] Training loss: 0.111445
DEBUG:root:[ Iteration 171 ] Training loss: 0.114143
DEBUG:root:[ Iteration 174 ] Training loss: 0.118711
DEBUG:root:[ Iteration 177 ] Training loss: 0.1083
DEBUG:root:[ Iteration 180 ] Training loss: 0.134683
DEBUG:root:[ Iteration 180 ] Test loss: 0.119698
DEBUG:root:[ Iteration 183 ] Training loss: 0.117128
DEBUG:root:[ Iteration 186 ] Training loss: 0.110475
DEBUG:root:[ Iteration 189 ] Training loss: 0.129371
DEBUG:root:[ Iteration 192 ] Training loss: 0.132173
DEBUG:root:[ Iteration 195 ] Training loss: 0.119931
DEBUG:root:[ Iteration 198 ] Training loss: 0.127324
DEBUG:root:[ Iteration 200 ] Test loss: 0.117501
DEBUG:root:[ Iteration 201 ] Training loss: 0.127791
DEBUG:root:[ Iteration 204 ] Training loss: 0.127906
DEBUG:root:[ Iteration 207 ] Training loss: 0.126511
DEBUG:root:[ Iteration 210 ] Training loss: 0.108262
DEBUG:root:[ Iteration 213 ] Training loss: 0.112165
DEBUG:root:[ Iteration 216 ] Training loss: 0.135863
DEBUG:root:[ Iteration 219 ] Training loss: 0.12604
DEBUG:root:[ Iteration 220 ] Test loss: 0.115844
DEBUG:root:[ Iteration 222 ] Training loss: 0.115136
DEBUG:root:[ Iteration 225 ] Training loss: 0.125564
DEBUG:root:[ Iteration 228 ] Training loss: 0.11048
DEBUG:root:[ Iteration 231 ] Training loss: 0.113594
DEBUG:root:[ Iteration 234 ] Training loss: 0.114725
DEBUG:root:[ Iteration 237 ] Training loss: 0.124205
DEBUG:root:[ Iteration 240 ] Training loss: 0.118653
DEBUG:root:[ Iteration 240 ] Test loss: 0.114293
DEBUG:root:[ Iteration 243 ] Training loss: 0.142068
DEBUG:root:[ Iteration 246 ] Training loss: 0.126469
DEBUG:root:[ Iteration 249 ] Training loss: 0.112115
DEBUG:root:[ Iteration 252 ] Training loss: 0.106958
DEBUG:root:[ Iteration 255 ] Training loss: 0.103003
DEBUG:root:[ Iteration 258 ] Training loss: 0.129351
DEBUG:root:[ Iteration 260 ] Test loss: 0.112861
DEBUG:root:[ Iteration 261 ] Training loss: 0.110045
DEBUG:root:[ Iteration 264 ] Training loss: 0.107647
DEBUG:root:[ Iteration 267 ] Training loss: 0.10072
DEBUG:root:[ Iteration 270 ] Training loss: 0.102026
DEBUG:root:[ Iteration 273 ] Training loss: 0.10993
DEBUG:root:[ Iteration 276 ] Training loss: 0.132456
DEBUG:root:[ Iteration 279 ] Training loss: 0.13295
DEBUG:root:[ Iteration 280 ] Test loss: 0.111612
DEBUG:root:[ Iteration 282 ] Training loss: 0.10762
DEBUG:root:[ Iteration 285 ] Training loss: 0.112614
DEBUG:root:[ Iteration 288 ] Training loss: 0.109306
DEBUG:root:[ Iteration 291 ] Training loss: 0.103718
DEBUG:root:[ Iteration 294 ] Training loss: 0.126713
DEBUG:root:[ Iteration 297 ] Training loss: 0.112731
DEBUG:root:[ Iteration 300 ] Training loss: 0.0903235
DEBUG:root:[ Iteration 300 ] Test loss: 0.110584
DEBUG:root:[ Iteration 303 ] Training loss: 0.0998811
DEBUG:root:[ Iteration 306 ] Training loss: 0.11586
DEBUG:root:[ Iteration 309 ] Training loss: 0.107625
DEBUG:root:[ Iteration 312 ] Training loss: 0.115157
DEBUG:root:[ Iteration 315 ] Training loss: 0.107903
DEBUG:root:[ Iteration 318 ] Training loss: 0.131771
DEBUG:root:[ Iteration 320 ] Test loss: 0.109613
DEBUG:root:[ Iteration 321 ] Training loss: 0.106273
DEBUG:root:[ Iteration 324 ] Training loss: 0.114277
DEBUG:root:[ Iteration 327 ] Training loss: 0.111927
DEBUG:root:[ Iteration 330 ] Training loss: 0.109446
DEBUG:root:[ Iteration 333 ] Training loss: 0.114279
DEBUG:root:[ Iteration 336 ] Training loss: 0.11157
DEBUG:root:[ Iteration 339 ] Training loss: 0.121416
DEBUG:root:[ Iteration 340 ] Test loss: 0.108476
DEBUG:root:[ Iteration 342 ] Training loss: 0.0924697
DEBUG:root:[ Iteration 345 ] Training loss: 0.0913877
DEBUG:root:[ Iteration 348 ] Training loss: 0.121698
DEBUG:root:[ Iteration 351 ] Training loss: 0.109612
DEBUG:root:[ Iteration 354 ] Training loss: 0.10403
DEBUG:root:[ Iteration 357 ] Training loss: 0.109658
DEBUG:root:[ Iteration 360 ] Training loss: 0.0907404
DEBUG:root:[ Iteration 360 ] Test loss: 0.107491
DEBUG:root:[ Iteration 363 ] Training loss: 0.0888771
DEBUG:root:[ Iteration 366 ] Training loss: 0.0997231
DEBUG:root:[ Iteration 369 ] Training loss: 0.113681
DEBUG:root:[ Iteration 372 ] Training loss: 0.109374
DEBUG:root:[ Iteration 375 ] Training loss: 0.116733
DEBUG:root:[ Iteration 378 ] Training loss: 0.104361
DEBUG:root:[ Iteration 380 ] Test loss: 0.106537
DEBUG:root:[ Iteration 381 ] Training loss: 0.11874
DEBUG:root:[ Iteration 384 ] Training loss: 0.107271
DEBUG:root:[ Iteration 387 ] Training loss: 0.106201
DEBUG:root:[ Iteration 390 ] Training loss: 0.114342
DEBUG:root:[ Iteration 393 ] Training loss: 0.103867
DEBUG:root:[ Iteration 396 ] Training loss: 0.0983829
DEBUG:root:[ Iteration 399 ] Training loss: 0.0996799
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-16-2016_19h41m11s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.177089
DEBUG:root:[ Iteration 0 ] Test loss: 0.177722
DEBUG:root:[ Iteration 3 ] Training loss: 0.175317
DEBUG:root:[ Iteration 6 ] Training loss: 0.174883
DEBUG:root:[ Iteration 9 ] Training loss: 0.181925
DEBUG:root:[ Iteration 12 ] Training loss: 0.174428
DEBUG:root:[ Iteration 15 ] Training loss: 0.174867
DEBUG:root:[ Iteration 18 ] Training loss: 0.175937
DEBUG:root:[ Iteration 20 ] Test loss: 0.17439
DEBUG:root:[ Iteration 21 ] Training loss: 0.166627
DEBUG:root:[ Iteration 24 ] Training loss: 0.175392
DEBUG:root:[ Iteration 27 ] Training loss: 0.170032
DEBUG:root:[ Iteration 30 ] Training loss: 0.170954
DEBUG:root:[ Iteration 33 ] Training loss: 0.165885
DEBUG:root:[ Iteration 36 ] Training loss: 0.146915
DEBUG:root:[ Iteration 39 ] Training loss: 0.168332
DEBUG:root:[ Iteration 40 ] Test loss: 0.164625
DEBUG:root:[ Iteration 42 ] Training loss: 0.163391
DEBUG:root:[ Iteration 45 ] Training loss: 0.176344
DEBUG:root:[ Iteration 48 ] Training loss: 0.142571
DEBUG:root:[ Iteration 51 ] Training loss: 0.153311
DEBUG:root:[ Iteration 54 ] Training loss: 0.150813
DEBUG:root:[ Iteration 57 ] Training loss: 0.171324
DEBUG:root:[ Iteration 60 ] Training loss: 0.151787
DEBUG:root:[ Iteration 60 ] Test loss: 0.157951
DEBUG:root:[ Iteration 63 ] Training loss: 0.170033
DEBUG:root:[ Iteration 66 ] Training loss: 0.160392
DEBUG:root:[ Iteration 69 ] Training loss: 0.157213
DEBUG:root:[ Iteration 72 ] Training loss: 0.148758
DEBUG:root:[ Iteration 75 ] Training loss: 0.138972
DEBUG:root:[ Iteration 78 ] Training loss: 0.122812
DEBUG:root:[ Iteration 80 ] Test loss: 0.134486
DEBUG:root:[ Iteration 81 ] Training loss: 0.138144
DEBUG:root:[ Iteration 84 ] Training loss: 0.122468
DEBUG:root:[ Iteration 87 ] Training loss: 0.116853
DEBUG:root:[ Iteration 90 ] Training loss: 0.110009
DEBUG:root:[ Iteration 93 ] Training loss: 0.120531
DEBUG:root:[ Iteration 96 ] Training loss: 0.114055
DEBUG:root:[ Iteration 99 ] Training loss: 0.091299
DEBUG:root:[ Iteration 100 ] Test loss: 0.104054
DEBUG:root:[ Iteration 102 ] Training loss: 0.125037
DEBUG:root:[ Iteration 105 ] Training loss: 0.102427
DEBUG:root:[ Iteration 108 ] Training loss: 0.0958901
DEBUG:root:[ Iteration 111 ] Training loss: 0.0971976
DEBUG:root:[ Iteration 114 ] Training loss: 0.0740192
DEBUG:root:[ Iteration 117 ] Training loss: 0.0809431
DEBUG:root:[ Iteration 120 ] Training loss: 0.0844483
DEBUG:root:[ Iteration 120 ] Test loss: 0.0856999
DEBUG:root:[ Iteration 123 ] Training loss: 0.112226
DEBUG:root:[ Iteration 126 ] Training loss: 0.0761397
DEBUG:root:[ Iteration 129 ] Training loss: 0.0981799
DEBUG:root:[ Iteration 132 ] Training loss: 0.0994272
DEBUG:root:[ Iteration 135 ] Training loss: 0.128563
DEBUG:root:[ Iteration 138 ] Training loss: 0.125849
DEBUG:root:[ Iteration 140 ] Test loss: 0.0691073
DEBUG:root:[ Iteration 141 ] Training loss: 0.114548
DEBUG:root:[ Iteration 144 ] Training loss: 0.0761157
DEBUG:root:[ Iteration 147 ] Training loss: 0.0613074
DEBUG:root:[ Iteration 150 ] Training loss: 0.0588922
DEBUG:root:[ Iteration 153 ] Training loss: 0.0441195
DEBUG:root:[ Iteration 156 ] Training loss: 0.0602422
DEBUG:root:[ Iteration 159 ] Training loss: 0.0463554
DEBUG:root:[ Iteration 160 ] Test loss: 0.0454509
DEBUG:root:[ Iteration 162 ] Training loss: 0.035719
DEBUG:root:[ Iteration 0 ] Training loss: 0.179253
DEBUG:root:[ Iteration 0 ] Test loss: 0.177674
DEBUG:root:[ Iteration 3 ] Training loss: 0.173906
DEBUG:root:[ Iteration 6 ] Training loss: 0.168486
DEBUG:root:[ Iteration 9 ] Training loss: 0.171525
DEBUG:root:[ Iteration 12 ] Training loss: 0.17174
DEBUG:root:[ Iteration 15 ] Training loss: 0.151099
DEBUG:root:[ Iteration 18 ] Training loss: 0.180729
DEBUG:root:[ Iteration 20 ] Test loss: 0.165054
DEBUG:root:[ Iteration 21 ] Training loss: 0.179265
DEBUG:root:[ Iteration 24 ] Training loss: 0.162472
DEBUG:root:[ Iteration 27 ] Training loss: 0.139873
DEBUG:root:[ Iteration 30 ] Training loss: 0.174868
DEBUG:root:[ Iteration 33 ] Training loss: 0.161328
DEBUG:root:[ Iteration 36 ] Training loss: 0.155765
DEBUG:root:[ Iteration 39 ] Training loss: 0.162852
DEBUG:root:[ Iteration 40 ] Test loss: 0.158429
DEBUG:root:[ Iteration 42 ] Training loss: 0.148446
DEBUG:root:[ Iteration 45 ] Training loss: 0.143057
DEBUG:root:[ Iteration 48 ] Training loss: 0.14914
DEBUG:root:[ Iteration 51 ] Training loss: 0.141827
DEBUG:root:[ Iteration 54 ] Training loss: 0.147648
DEBUG:root:[ Iteration 57 ] Training loss: 0.158685
DEBUG:root:[ Iteration 60 ] Training loss: 0.134273
DEBUG:root:[ Iteration 60 ] Test loss: 0.142922
DEBUG:root:[ Iteration 63 ] Training loss: 0.142203
DEBUG:root:[ Iteration 66 ] Training loss: 0.112381
DEBUG:root:[ Iteration 69 ] Training loss: 0.139856
DEBUG:root:[ Iteration 72 ] Training loss: 0.118007
DEBUG:root:[ Iteration 75 ] Training loss: 0.108631
DEBUG:root:[ Iteration 78 ] Training loss: 0.0927251
DEBUG:root:[ Iteration 80 ] Test loss: 0.109375
DEBUG:root:[ Iteration 81 ] Training loss: 0.0991114
DEBUG:root:[ Iteration 84 ] Training loss: 0.14365
DEBUG:root:[ Iteration 87 ] Training loss: 0.0913849
DEBUG:root:[ Iteration 90 ] Training loss: 0.0825824
DEBUG:root:[ Iteration 93 ] Training loss: 0.0825819
DEBUG:root:[ Iteration 96 ] Training loss: 0.148291
DEBUG:root:[ Iteration 99 ] Training loss: 0.0930897
DEBUG:root:[ Iteration 100 ] Test loss: 0.135983
DEBUG:root:[ Iteration 102 ] Training loss: 0.131685
DEBUG:root:[ Iteration 105 ] Training loss: 0.125981
DEBUG:root:[ Iteration 108 ] Training loss: 0.15523
DEBUG:root:[ Iteration 111 ] Training loss: 0.0952541
DEBUG:root:[ Iteration 114 ] Training loss: 0.106201
DEBUG:root:[ Iteration 117 ] Training loss: 0.0863263
DEBUG:root:[ Iteration 120 ] Training loss: 0.0898074
DEBUG:root:[ Iteration 120 ] Test loss: 0.0901525
DEBUG:root:[ Iteration 123 ] Training loss: 0.094326
DEBUG:root:[ Iteration 126 ] Training loss: 0.0719132
DEBUG:root:[ Iteration 129 ] Training loss: 0.0858944
DEBUG:root:[ Iteration 132 ] Training loss: 0.0620586
DEBUG:root:[ Iteration 135 ] Training loss: 0.0713717
DEBUG:root:[ Iteration 138 ] Training loss: 0.0529551
DEBUG:root:[ Iteration 140 ] Test loss: 0.0531836
DEBUG:root:[ Iteration 141 ] Training loss: 0.0537351
DEBUG:root:[ Iteration 144 ] Training loss: 0.0499397
DEBUG:root:[ Iteration 147 ] Training loss: 0.0518604
DEBUG:root:[ Iteration 150 ] Training loss: 0.044962
DEBUG:root:[ Iteration 153 ] Training loss: 0.0245395
DEBUG:root:[ Iteration 156 ] Training loss: 0.0302424
DEBUG:root:[ Iteration 159 ] Training loss: 0.0387722
DEBUG:root:[ Iteration 160 ] Test loss: 0.0425856
DEBUG:root:[ Iteration 162 ] Training loss: 0.0524353
DEBUG:root:[ Iteration 165 ] Training loss: 0.0243682
DEBUG:root:[ Iteration 168 ] Training loss: 0.038011
DEBUG:root:[ Iteration 171 ] Training loss: 0.0232485
DEBUG:root:[ Iteration 174 ] Training loss: 0.0416101
DEBUG:root:[ Iteration 177 ] Training loss: 0.0369877
DEBUG:root:[ Iteration 180 ] Training loss: 0.0308753
DEBUG:root:[ Iteration 180 ] Test loss: 0.032647
DEBUG:root:[ Iteration 183 ] Training loss: 0.019612
DEBUG:root:[ Iteration 186 ] Training loss: 0.0196081
DEBUG:root:[ Iteration 189 ] Training loss: 0.016866
DEBUG:root:[ Iteration 192 ] Training loss: 0.0178624
DEBUG:root:[ Iteration 195 ] Training loss: 0.0171349
DEBUG:root:[ Iteration 198 ] Training loss: 0.0212073
DEBUG:root:[ Iteration 200 ] Test loss: 0.0180364
DEBUG:root:[ Iteration 201 ] Training loss: 0.010624
DEBUG:root:[ Iteration 204 ] Training loss: 0.0137434
DEBUG:root:[ Iteration 207 ] Training loss: 0.0160218
DEBUG:root:[ Iteration 210 ] Training loss: 0.0273923
DEBUG:root:[ Iteration 213 ] Training loss: 0.0391198
DEBUG:root:[ Iteration 216 ] Training loss: 0.0144638
DEBUG:root:[ Iteration 219 ] Training loss: 0.0122979
DEBUG:root:[ Iteration 220 ] Test loss: 0.0252092
DEBUG:root:[ Iteration 222 ] Training loss: 0.022505
DEBUG:root:[ Iteration 225 ] Training loss: 0.0116073
DEBUG:root:[ Iteration 228 ] Training loss: 0.00713368
DEBUG:root:[ Iteration 231 ] Training loss: 0.0124542
DEBUG:root:[ Iteration 234 ] Training loss: 0.0161116
DEBUG:root:[ Iteration 237 ] Training loss: 0.0141556
DEBUG:root:[ Iteration 240 ] Training loss: 0.0164502
DEBUG:root:[ Iteration 240 ] Test loss: 0.0123608
DEBUG:root:[ Iteration 243 ] Training loss: 0.00834366
DEBUG:root:[ Iteration 246 ] Training loss: 0.00927003
DEBUG:root:[ Iteration 249 ] Training loss: 0.00664601
DEBUG:root:[ Iteration 252 ] Training loss: 0.0194808
DEBUG:root:[ Iteration 255 ] Training loss: 0.0229886
DEBUG:root:[ Iteration 258 ] Training loss: 0.0151018
DEBUG:root:[ Iteration 260 ] Test loss: 0.0124806
DEBUG:root:[ Iteration 261 ] Training loss: 0.0219714
DEBUG:root:[ Iteration 264 ] Training loss: 0.0103194
DEBUG:root:[ Iteration 267 ] Training loss: 0.00517238
DEBUG:root:[ Iteration 270 ] Training loss: 0.00711638
DEBUG:root:[ Iteration 273 ] Training loss: 0.0109172
DEBUG:root:[ Iteration 276 ] Training loss: 0.00595067
DEBUG:root:[ Iteration 279 ] Training loss: 0.0156021
DEBUG:root:[ Iteration 280 ] Test loss: 0.00969733
DEBUG:root:[ Iteration 282 ] Training loss: 0.0104904
DEBUG:root:[ Iteration 285 ] Training loss: 0.00460699
DEBUG:root:[ Iteration 288 ] Training loss: 0.0127759
DEBUG:root:[ Iteration 291 ] Training loss: 0.00716885
DEBUG:root:[ Iteration 294 ] Training loss: 0.00561453
DEBUG:root:[ Iteration 297 ] Training loss: 0.00911945
DEBUG:root:[ Iteration 300 ] Training loss: 0.0142047
DEBUG:root:[ Iteration 300 ] Test loss: 0.0139874
DEBUG:root:[ Iteration 303 ] Training loss: 0.0171992
DEBUG:root:[ Iteration 306 ] Training loss: 0.00917417
DEBUG:root:[ Iteration 309 ] Training loss: 0.0099433
DEBUG:root:[ Iteration 312 ] Training loss: 0.0211388
DEBUG:root:[ Iteration 315 ] Training loss: 0.00881802
DEBUG:root:[ Iteration 318 ] Training loss: 0.0068146
DEBUG:root:[ Iteration 320 ] Test loss: 0.00708752
DEBUG:root:[ Iteration 321 ] Training loss: 0.00611461
DEBUG:root:[ Iteration 324 ] Training loss: 0.00489514
DEBUG:root:[ Iteration 327 ] Training loss: 0.00628385
DEBUG:root:[ Iteration 330 ] Training loss: 0.002662
DEBUG:root:[ Iteration 333 ] Training loss: 0.0133023
DEBUG:root:[ Iteration 336 ] Training loss: 0.00853235
DEBUG:root:[ Iteration 339 ] Training loss: 0.0116266
DEBUG:root:[ Iteration 340 ] Test loss: 0.00600915
DEBUG:root:[ Iteration 342 ] Training loss: 0.00670713
DEBUG:root:[ Iteration 345 ] Training loss: 0.00908557
DEBUG:root:[ Iteration 348 ] Training loss: 0.00279492
DEBUG:root:[ Iteration 351 ] Training loss: 0.00493705
DEBUG:root:[ Iteration 354 ] Training loss: 0.00748738
DEBUG:root:[ Iteration 357 ] Training loss: 0.00649809
DEBUG:root:[ Iteration 360 ] Training loss: 0.00680387
DEBUG:root:[ Iteration 360 ] Test loss: 0.00761667
DEBUG:root:[ Iteration 363 ] Training loss: 0.00330974
DEBUG:root:[ Iteration 366 ] Training loss: 0.00518513
DEBUG:root:[ Iteration 369 ] Training loss: 0.0028376
DEBUG:root:[ Iteration 372 ] Training loss: 0.0044185
DEBUG:root:[ Iteration 375 ] Training loss: 0.00466131
DEBUG:root:[ Iteration 378 ] Training loss: 0.00679854
DEBUG:root:[ Iteration 380 ] Test loss: 0.00496548
DEBUG:root:[ Iteration 381 ] Training loss: 0.00602006
DEBUG:root:[ Iteration 384 ] Training loss: 0.00408747
DEBUG:root:[ Iteration 387 ] Training loss: 0.00885134
DEBUG:root:[ Iteration 390 ] Training loss: 0.00346721
DEBUG:root:[ Iteration 393 ] Training loss: 0.00710706
DEBUG:root:[ Iteration 396 ] Training loss: 0.00865164
DEBUG:root:[ Iteration 399 ] Training loss: 0.00510483
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-17-2016_22h57m55s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.215895
DEBUG:root:[ Iteration 0 ] Test loss: 0.213649
DEBUG:root:[ Iteration 3 ] Training loss: 0.223761
DEBUG:root:[ Iteration 6 ] Training loss: 0.204439
DEBUG:root:[ Iteration 9 ] Training loss: 0.208799
DEBUG:root:[ Iteration 12 ] Training loss: 0.200424
DEBUG:root:[ Iteration 15 ] Training loss: 0.187916
DEBUG:root:[ Iteration 18 ] Training loss: 0.139247
DEBUG:root:[ Iteration 20 ] Test loss: 0.11299
DEBUG:root:[ Iteration 21 ] Training loss: 0.0987103
DEBUG:root:[ Iteration 24 ] Training loss: 0.128874
DEBUG:root:[ Iteration 27 ] Training loss: 0.0973827
DEBUG:root:[ Iteration 30 ] Training loss: 0.0999535
DEBUG:root:[ Iteration 33 ] Training loss: 0.109133
DEBUG:root:[ Iteration 36 ] Training loss: 0.0749438
DEBUG:root:[ Iteration 39 ] Training loss: 0.0899713
DEBUG:root:[ Iteration 40 ] Test loss: 0.0806742
DEBUG:root:[ Iteration 42 ] Training loss: 0.0796085
DEBUG:root:[ Iteration 45 ] Training loss: 0.0611037
DEBUG:root:[ Iteration 48 ] Training loss: 0.0650142
DEBUG:root:[ Iteration 51 ] Training loss: 0.0521923
DEBUG:root:[ Iteration 54 ] Training loss: 0.0694878
DEBUG:root:[ Iteration 57 ] Training loss: 0.0507335
DEBUG:root:[ Iteration 60 ] Training loss: 0.0769297
DEBUG:root:[ Iteration 60 ] Test loss: 0.0606672
DEBUG:root:[ Iteration 63 ] Training loss: 0.0360718
DEBUG:root:[ Iteration 66 ] Training loss: 0.0477007
DEBUG:root:[ Iteration 69 ] Training loss: 0.0444414
DEBUG:root:[ Iteration 72 ] Training loss: 0.0397844
DEBUG:root:[ Iteration 75 ] Training loss: 0.0224528
DEBUG:root:[ Iteration 78 ] Training loss: 0.0289214
DEBUG:root:[ Iteration 80 ] Test loss: 0.0340413
DEBUG:root:[ Iteration 81 ] Training loss: 0.0617645
DEBUG:root:[ Iteration 84 ] Training loss: 0.0466045
DEBUG:root:[ Iteration 87 ] Training loss: 0.049593
DEBUG:root:[ Iteration 90 ] Training loss: 0.0249906
DEBUG:root:[ Iteration 93 ] Training loss: 0.0543634
DEBUG:root:[ Iteration 96 ] Training loss: 0.0396497
DEBUG:root:[ Iteration 99 ] Training loss: 0.0530419
DEBUG:root:[ Iteration 100 ] Test loss: 0.0329444
DEBUG:root:[ Iteration 102 ] Training loss: 0.039374
DEBUG:root:[ Iteration 105 ] Training loss: 0.0484268
DEBUG:root:[ Iteration 108 ] Training loss: 0.0304141
DEBUG:root:[ Iteration 111 ] Training loss: 0.0269509
DEBUG:root:[ Iteration 114 ] Training loss: 0.0226325
DEBUG:root:[ Iteration 117 ] Training loss: 0.0240017
DEBUG:root:[ Iteration 120 ] Training loss: 0.0268878
DEBUG:root:[ Iteration 120 ] Test loss: 0.0333793
DEBUG:root:[ Iteration 123 ] Training loss: 0.024642
DEBUG:root:[ Iteration 126 ] Training loss: 0.0293282
DEBUG:root:[ Iteration 129 ] Training loss: 0.0265243
DEBUG:root:[ Iteration 132 ] Training loss: 0.0265874
DEBUG:root:[ Iteration 135 ] Training loss: 0.0345731
DEBUG:root:[ Iteration 138 ] Training loss: 0.0225838
DEBUG:root:[ Iteration 140 ] Test loss: 0.0247356
DEBUG:root:[ Iteration 141 ] Training loss: 0.0292855
DEBUG:root:[ Iteration 144 ] Training loss: 0.0241309
DEBUG:root:[ Iteration 147 ] Training loss: 0.0152042
DEBUG:root:[ Iteration 150 ] Training loss: 0.0200231
DEBUG:root:[ Iteration 153 ] Training loss: 0.0196147
DEBUG:root:[ Iteration 156 ] Training loss: 0.0087884
DEBUG:root:[ Iteration 159 ] Training loss: 0.00949416
DEBUG:root:[ Iteration 160 ] Test loss: 0.00908623
DEBUG:root:[ Iteration 162 ] Training loss: 0.0052498
DEBUG:root:[ Iteration 165 ] Training loss: 0.00498916
DEBUG:root:[ Iteration 168 ] Training loss: 0.00477114
DEBUG:root:[ Iteration 171 ] Training loss: 0.00415666
DEBUG:root:[ Iteration 174 ] Training loss: 0.00590432
DEBUG:root:[ Iteration 177 ] Training loss: 0.00639946
DEBUG:root:[ Iteration 180 ] Training loss: 0.00655497
DEBUG:root:[ Iteration 180 ] Test loss: 0.00410481
DEBUG:root:[ Iteration 183 ] Training loss: 0.00332089
DEBUG:root:[ Iteration 186 ] Training loss: 0.00223103
DEBUG:root:[ Iteration 189 ] Training loss: 0.00268562
DEBUG:root:[ Iteration 192 ] Training loss: 0.00223175
DEBUG:root:[ Iteration 195 ] Training loss: 0.00645038
DEBUG:root:[ Iteration 198 ] Training loss: 0.00454739
DEBUG:root:[ Iteration 200 ] Test loss: 0.00343364
DEBUG:root:[ Iteration 201 ] Training loss: 0.00364102
DEBUG:root:[ Iteration 204 ] Training loss: 0.00639228
DEBUG:root:[ Iteration 207 ] Training loss: 0.00420373
DEBUG:root:[ Iteration 210 ] Training loss: 0.00444635
DEBUG:root:[ Iteration 213 ] Training loss: 0.00288407
DEBUG:root:[ Iteration 216 ] Training loss: 0.00251424
DEBUG:root:[ Iteration 219 ] Training loss: 0.00232858
DEBUG:root:[ Iteration 220 ] Test loss: 0.00306929
DEBUG:root:[ Iteration 222 ] Training loss: 0.00308212
DEBUG:root:[ Iteration 225 ] Training loss: 0.00192705
DEBUG:root:[ Iteration 228 ] Training loss: 0.00201433
DEBUG:root:[ Iteration 231 ] Training loss: 0.00200628
DEBUG:root:[ Iteration 234 ] Training loss: 0.00452636
DEBUG:root:[ Iteration 237 ] Training loss: 0.00301651
DEBUG:root:[ Iteration 240 ] Training loss: 0.00254505
DEBUG:root:[ Iteration 240 ] Test loss: 0.00301199
DEBUG:root:[ Iteration 243 ] Training loss: 0.00107019
DEBUG:root:[ Iteration 246 ] Training loss: 0.00190684
DEBUG:root:[ Iteration 249 ] Training loss: 0.00417954
DEBUG:root:[ Iteration 252 ] Training loss: 0.00126059
DEBUG:root:[ Iteration 255 ] Training loss: 0.00410017
DEBUG:root:[ Iteration 258 ] Training loss: 0.00318121
DEBUG:root:[ Iteration 260 ] Test loss: 0.00237943
DEBUG:root:[ Iteration 261 ] Training loss: 0.00213779
DEBUG:root:[ Iteration 264 ] Training loss: 0.00311899
DEBUG:root:[ Iteration 267 ] Training loss: 0.00223332
DEBUG:root:[ Iteration 270 ] Training loss: 0.00141457
DEBUG:root:[ Iteration 273 ] Training loss: 0.0016801
DEBUG:root:[ Iteration 276 ] Training loss: 0.00131498
DEBUG:root:[ Iteration 279 ] Training loss: 0.00276701
DEBUG:root:[ Iteration 280 ] Test loss: 0.00245636
DEBUG:root:[ Iteration 282 ] Training loss: 0.00174094
DEBUG:root:[ Iteration 285 ] Training loss: 0.000971835
DEBUG:root:[ Iteration 288 ] Training loss: 0.00202595
DEBUG:root:[ Iteration 291 ] Training loss: 0.00477893
DEBUG:root:[ Iteration 294 ] Training loss: 0.00241031
DEBUG:root:[ Iteration 297 ] Training loss: 0.00223351
DEBUG:root:[ Iteration 300 ] Training loss: 0.0030371
DEBUG:root:[ Iteration 300 ] Test loss: 0.00294849
DEBUG:root:[ Iteration 303 ] Training loss: 0.00113726
DEBUG:root:[ Iteration 306 ] Training loss: 0.0021658
DEBUG:root:[ Iteration 309 ] Training loss: 0.00185313
DEBUG:root:[ Iteration 312 ] Training loss: 0.0026568
DEBUG:root:[ Iteration 315 ] Training loss: 0.00148676
DEBUG:root:[ Iteration 318 ] Training loss: 0.00205532
DEBUG:root:[ Iteration 320 ] Test loss: 0.00229673
DEBUG:root:[ Iteration 321 ] Training loss: 0.000989535
DEBUG:root:[ Iteration 324 ] Training loss: 0.00317549
DEBUG:root:[ Iteration 327 ] Training loss: 0.00209943
DEBUG:root:[ Iteration 330 ] Training loss: 0.00246523
DEBUG:root:[ Iteration 333 ] Training loss: 0.00216725
DEBUG:root:[ Iteration 336 ] Training loss: 0.000873241
DEBUG:root:[ Iteration 339 ] Training loss: 0.00245459
DEBUG:root:[ Iteration 340 ] Test loss: 0.00248806
DEBUG:root:[ Iteration 342 ] Training loss: 0.00177517
DEBUG:root:[ Iteration 345 ] Training loss: 0.00157648
DEBUG:root:[ Iteration 348 ] Training loss: 0.00158626
DEBUG:root:[ Iteration 351 ] Training loss: 0.00118962
DEBUG:root:[ Iteration 354 ] Training loss: 0.00251952
DEBUG:root:[ Iteration 357 ] Training loss: 0.00185319
DEBUG:root:[ Iteration 360 ] Training loss: 0.00527505
DEBUG:root:[ Iteration 360 ] Test loss: 0.0036479
DEBUG:root:[ Iteration 363 ] Training loss: 0.00278503
DEBUG:root:[ Iteration 366 ] Training loss: 0.00458425
DEBUG:root:[ Iteration 369 ] Training loss: 0.00168011
DEBUG:root:[ Iteration 372 ] Training loss: 0.00367241
DEBUG:root:[ Iteration 375 ] Training loss: 0.00256628
DEBUG:root:[ Iteration 378 ] Training loss: 0.00317036
DEBUG:root:[ Iteration 380 ] Test loss: 0.00224388
DEBUG:root:[ Iteration 381 ] Training loss: 0.00174689
DEBUG:root:[ Iteration 384 ] Training loss: 0.000943309
DEBUG:root:[ Iteration 387 ] Training loss: 0.00273505
DEBUG:root:[ Iteration 390 ] Training loss: 0.00196643
DEBUG:root:[ Iteration 393 ] Training loss: 0.00122726
DEBUG:root:[ Iteration 396 ] Training loss: 0.00292557
DEBUG:root:[ Iteration 399 ] Training loss: 0.00102935
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-19-2016_17h14m04s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-19-2016_17h14m58s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0576365
DEBUG:root:[ Iteration 0 ] Test loss: 0.0472741
DEBUG:root:[ Iteration 3 ] Training loss: 0.0364056
DEBUG:root:[ Iteration 6 ] Training loss: 0.0429522
DEBUG:root:[ Iteration 9 ] Training loss: 0.0348002
DEBUG:root:[ Iteration 12 ] Training loss: 0.0384946
DEBUG:root:[ Iteration 15 ] Training loss: 0.0311575
DEBUG:root:[ Iteration 18 ] Training loss: 0.0394328
DEBUG:root:[ Iteration 20 ] Test loss: 0.0259902
DEBUG:root:[ Iteration 21 ] Training loss: 0.0294466
DEBUG:root:[ Iteration 24 ] Training loss: 0.0313237
DEBUG:root:[ Iteration 27 ] Training loss: 0.0356545
DEBUG:root:[ Iteration 30 ] Training loss: 0.0202175
DEBUG:root:[ Iteration 33 ] Training loss: 0.0302544
DEBUG:root:[ Iteration 36 ] Training loss: 0.0269293
DEBUG:root:[ Iteration 39 ] Training loss: 0.0157561
DEBUG:root:[ Iteration 40 ] Test loss: 0.0214102
DEBUG:root:[ Iteration 42 ] Training loss: 0.0215714
DEBUG:root:[ Iteration 45 ] Training loss: 0.0208625
DEBUG:root:[ Iteration 48 ] Training loss: 0.0238228
DEBUG:root:[ Iteration 51 ] Training loss: 0.0179663
DEBUG:root:[ Iteration 54 ] Training loss: 0.0156944
DEBUG:root:[ Iteration 57 ] Training loss: 0.0105545
DEBUG:root:[ Iteration 60 ] Training loss: 0.0129288
DEBUG:root:[ Iteration 60 ] Test loss: 0.0134741
DEBUG:root:[ Iteration 63 ] Training loss: 0.0152124
DEBUG:root:[ Iteration 66 ] Training loss: 0.0220556
DEBUG:root:[ Iteration 69 ] Training loss: 0.012788
DEBUG:root:[ Iteration 72 ] Training loss: 0.007716
DEBUG:root:[ Iteration 75 ] Training loss: 0.00777118
DEBUG:root:[ Iteration 78 ] Training loss: 0.0182865
DEBUG:root:[ Iteration 80 ] Test loss: 0.0133059
DEBUG:root:[ Iteration 81 ] Training loss: 0.0169941
DEBUG:root:[ Iteration 84 ] Training loss: 0.0168169
DEBUG:root:[ Iteration 87 ] Training loss: 0.0114406
DEBUG:root:[ Iteration 90 ] Training loss: 0.013995
DEBUG:root:[ Iteration 93 ] Training loss: 0.0108958
DEBUG:root:[ Iteration 96 ] Training loss: 0.0105465
DEBUG:root:[ Iteration 99 ] Training loss: 0.0146311
DEBUG:root:[ Iteration 100 ] Test loss: 0.00876461
DEBUG:root:[ Iteration 102 ] Training loss: 0.0109267
DEBUG:root:[ Iteration 105 ] Training loss: 0.0066018
DEBUG:root:[ Iteration 108 ] Training loss: 0.00651888
DEBUG:root:[ Iteration 111 ] Training loss: 0.0106437
DEBUG:root:[ Iteration 114 ] Training loss: 0.0094993
DEBUG:root:[ Iteration 117 ] Training loss: 0.00726592
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-23-2016_14h01m15s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0415127
DEBUG:root:[ Iteration 0 ] Test loss: 0.0472741
DEBUG:root:[ Iteration 3 ] Training loss: 0.0424677
DEBUG:root:[ Iteration 6 ] Training loss: 0.0459825
DEBUG:root:[ Iteration 9 ] Training loss: 0.0448419
DEBUG:root:[ Iteration 12 ] Training loss: 0.0373922
DEBUG:root:[ Iteration 15 ] Training loss: 0.0480012
DEBUG:root:[ Iteration 18 ] Training loss: 0.0243616
DEBUG:root:[ Iteration 20 ] Test loss: 0.0249452
DEBUG:root:[ Iteration 21 ] Training loss: 0.0276288
DEBUG:root:[ Iteration 24 ] Training loss: 0.0275296
DEBUG:root:[ Iteration 27 ] Training loss: 0.0327358
DEBUG:root:[ Iteration 30 ] Training loss: 0.0360626
DEBUG:root:[ Iteration 33 ] Training loss: 0.0216061
DEBUG:root:[ Iteration 36 ] Training loss: 0.01539
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.0823778
DEBUG:root:[ Iteration 0 ] Test loss: 0.0752351
DEBUG:root:[ Iteration 0 ] Training loss: 0.0748821
DEBUG:root:[ Iteration 0 ] Test loss: 0.0752351
DEBUG:root:[ Iteration 3 ] Training loss: 0.0653602
DEBUG:root:[ Iteration 6 ] Training loss: 0.0510621
DEBUG:root:[ Iteration 9 ] Training loss: 0.0465514
DEBUG:root:[ Iteration 12 ] Training loss: 0.0500631
DEBUG:root:[ Iteration 15 ] Training loss: 0.0478239
DEBUG:root:[ Iteration 18 ] Training loss: 0.0461302
DEBUG:root:[ Iteration 20 ] Test loss: 0.0592032
DEBUG:root:[ Iteration 21 ] Training loss: 0.0644894
DEBUG:root:[ Iteration 24 ] Training loss: 0.0616452
DEBUG:root:[ Iteration 27 ] Training loss: 0.0510025
DEBUG:root:[ Iteration 30 ] Training loss: 0.0457269
DEBUG:root:[ Iteration 33 ] Training loss: 0.0521721
DEBUG:root:[ Iteration 36 ] Training loss: 0.0541882
DEBUG:root:[ Iteration 39 ] Training loss: 0.0370161
DEBUG:root:[ Iteration 40 ] Test loss: 0.0488394
DEBUG:root:[ Iteration 42 ] Training loss: 0.0472937
DEBUG:root:[ Iteration 45 ] Training loss: 0.0445338
DEBUG:root:[ Iteration 48 ] Training loss: 0.0462064
DEBUG:root:[ Iteration 51 ] Training loss: 0.0497937
DEBUG:root:[ Iteration 54 ] Training loss: 0.0288592
DEBUG:root:[ Iteration 57 ] Training loss: 0.0326089
DEBUG:root:[ Iteration 60 ] Training loss: 0.0489368
DEBUG:root:[ Iteration 60 ] Test loss: 0.0392289
DEBUG:root:[ Iteration 63 ] Training loss: 0.0384207
DEBUG:root:[ Iteration 66 ] Training loss: 0.0501063
DEBUG:root:[ Iteration 69 ] Training loss: 0.0331612
DEBUG:root:[ Iteration 72 ] Training loss: 0.0468264
DEBUG:root:[ Iteration 75 ] Training loss: 0.0321133
DEBUG:root:[ Iteration 78 ] Training loss: 0.0398911
DEBUG:root:[ Iteration 80 ] Test loss: 0.03469
DEBUG:root:[ Iteration 81 ] Training loss: 0.0406555
DEBUG:root:[ Iteration 84 ] Training loss: 0.0288939
DEBUG:root:[ Iteration 87 ] Training loss: 0.035526
DEBUG:root:[ Iteration 90 ] Training loss: 0.0282673
DEBUG:root:[ Iteration 93 ] Training loss: 0.0289945
DEBUG:root:[ Iteration 96 ] Training loss: 0.0292415
DEBUG:root:[ Iteration 99 ] Training loss: 0.021814
DEBUG:root:[ Iteration 100 ] Test loss: 0.0316782
DEBUG:root:[ Iteration 102 ] Training loss: 0.0236215
DEBUG:root:[ Iteration 105 ] Training loss: 0.02823
DEBUG:root:[ Iteration 108 ] Training loss: 0.0215207
DEBUG:root:[ Iteration 111 ] Training loss: 0.0227473
DEBUG:root:[ Iteration 114 ] Training loss: 0.0306396
DEBUG:root:[ Iteration 117 ] Training loss: 0.0220301
DEBUG:root:[ Iteration 120 ] Training loss: 0.0208017
DEBUG:root:[ Iteration 120 ] Test loss: 0.0274536
DEBUG:root:[ Iteration 123 ] Training loss: 0.0315345
DEBUG:root:[ Iteration 126 ] Training loss: 0.0169195
DEBUG:root:[ Iteration 129 ] Training loss: 0.0259542
DEBUG:root:[ Iteration 132 ] Training loss: 0.0204052
DEBUG:root:[ Iteration 135 ] Training loss: 0.0216927
DEBUG:root:[ Iteration 138 ] Training loss: 0.0158997
DEBUG:root:[ Iteration 140 ] Test loss: 0.0252886
DEBUG:root:[ Iteration 141 ] Training loss: 0.0199065
DEBUG:root:[ Iteration 144 ] Training loss: 0.0211029
DEBUG:root:[ Iteration 147 ] Training loss: 0.018428
DEBUG:root:[ Iteration 150 ] Training loss: 0.0227751
DEBUG:root:[ Iteration 153 ] Training loss: 0.0306478
DEBUG:root:[ Iteration 156 ] Training loss: 0.0207089
DEBUG:root:[ Iteration 159 ] Training loss: 0.023526
DEBUG:root:[ Iteration 160 ] Test loss: 0.0354018
DEBUG:root:[ Iteration 162 ] Training loss: 0.0258943
DEBUG:root:[ Iteration 165 ] Training loss: 0.0223185
DEBUG:root:[ Iteration 168 ] Training loss: 0.0298461
DEBUG:root:[ Iteration 171 ] Training loss: 0.0262554
DEBUG:root:[ Iteration 174 ] Training loss: 0.0155176
DEBUG:root:[ Iteration 177 ] Training loss: 0.0176548
DEBUG:root:[ Iteration 180 ] Training loss: 0.0172961
DEBUG:root:[ Iteration 180 ] Test loss: 0.0218416
DEBUG:root:[ Iteration 183 ] Training loss: 0.0241199
DEBUG:root:[ Iteration 186 ] Training loss: 0.0228162
DEBUG:root:[ Iteration 189 ] Training loss: 0.0207572
DEBUG:root:[ Iteration 192 ] Training loss: 0.0184321
DEBUG:root:[ Iteration 195 ] Training loss: 0.0203825
DEBUG:root:[ Iteration 198 ] Training loss: 0.0212549
DEBUG:root:[ Iteration 200 ] Test loss: 0.0265561
DEBUG:root:[ Iteration 201 ] Training loss: 0.0164174
DEBUG:root:[ Iteration 204 ] Training loss: 0.011224
DEBUG:root:[ Iteration 207 ] Training loss: 0.0315895
DEBUG:root:[ Iteration 210 ] Training loss: 0.0246178
DEBUG:root:[ Iteration 213 ] Training loss: 0.0166434
DEBUG:root:[ Iteration 216 ] Training loss: 0.0186199
DEBUG:root:[ Iteration 219 ] Training loss: 0.0215084
DEBUG:root:[ Iteration 220 ] Test loss: 0.0209994
DEBUG:root:[ Iteration 222 ] Training loss: 0.0178549
DEBUG:root:[ Iteration 225 ] Training loss: 0.0173759
DEBUG:root:[ Iteration 228 ] Training loss: 0.0202035
DEBUG:root:[ Iteration 231 ] Training loss: 0.0151323
DEBUG:root:[ Iteration 234 ] Training loss: 0.0225858
DEBUG:root:[ Iteration 237 ] Training loss: 0.0192452
DEBUG:root:[ Iteration 240 ] Training loss: 0.0285488
DEBUG:root:[ Iteration 240 ] Test loss: 0.0197658
DEBUG:root:[ Iteration 243 ] Training loss: 0.0158902
DEBUG:root:[ Iteration 246 ] Training loss: 0.0165791
DEBUG:root:[ Iteration 249 ] Training loss: 0.0246317
DEBUG:root:[ Iteration 252 ] Training loss: 0.0129975
DEBUG:root:[ Iteration 255 ] Training loss: 0.0152503
DEBUG:root:[ Iteration 258 ] Training loss: 0.016121
DEBUG:root:[ Iteration 260 ] Test loss: 0.0182097
DEBUG:root:[ Iteration 261 ] Training loss: 0.011961
DEBUG:root:[ Iteration 264 ] Training loss: 0.011933
DEBUG:root:[ Iteration 267 ] Training loss: 0.0187717
DEBUG:root:[ Iteration 270 ] Training loss: 0.0166211
DEBUG:root:[ Iteration 273 ] Training loss: 0.0135242
DEBUG:root:[ Iteration 276 ] Training loss: 0.0128901
DEBUG:root:[ Iteration 279 ] Training loss: 0.0234409
DEBUG:root:[ Iteration 280 ] Test loss: 0.0182888
DEBUG:root:[ Iteration 282 ] Training loss: 0.0171342
DEBUG:root:[ Iteration 285 ] Training loss: 0.0276981
DEBUG:root:[ Iteration 288 ] Training loss: 0.0117832
DEBUG:root:[ Iteration 291 ] Training loss: 0.0133405
DEBUG:root:[ Iteration 294 ] Training loss: 0.00953062
DEBUG:root:[ Iteration 297 ] Training loss: 0.0129875
DEBUG:root:[ Iteration 300 ] Training loss: 0.0108809
DEBUG:root:[ Iteration 300 ] Test loss: 0.0163959
DEBUG:root:[ Iteration 303 ] Training loss: 0.01314
DEBUG:root:[ Iteration 306 ] Training loss: 0.0159343
DEBUG:root:[ Iteration 309 ] Training loss: 0.0209213
DEBUG:root:[ Iteration 312 ] Training loss: 0.0145901
DEBUG:root:[ Iteration 315 ] Training loss: 0.00841139
DEBUG:root:[ Iteration 318 ] Training loss: 0.0144617
DEBUG:root:[ Iteration 320 ] Test loss: 0.0163166
DEBUG:root:[ Iteration 321 ] Training loss: 0.0113616
DEBUG:root:[ Iteration 324 ] Training loss: 0.00791945
DEBUG:root:[ Iteration 327 ] Training loss: 0.011022
DEBUG:root:[ Iteration 330 ] Training loss: 0.0121487
DEBUG:root:[ Iteration 333 ] Training loss: 0.0176294
DEBUG:root:[ Iteration 336 ] Training loss: 0.0202101
DEBUG:root:[ Iteration 339 ] Training loss: 0.0155738
DEBUG:root:[ Iteration 340 ] Test loss: 0.0180627
DEBUG:root:[ Iteration 342 ] Training loss: 0.0159036
DEBUG:root:[ Iteration 345 ] Training loss: 0.0164605
DEBUG:root:[ Iteration 348 ] Training loss: 0.0142617
DEBUG:root:[ Iteration 351 ] Training loss: 0.0127349
DEBUG:root:[ Iteration 354 ] Training loss: 0.0138081
DEBUG:root:[ Iteration 357 ] Training loss: 0.0106124
DEBUG:root:[ Iteration 360 ] Training loss: 0.0187511
DEBUG:root:[ Iteration 360 ] Test loss: 0.019879
DEBUG:root:[ Iteration 363 ] Training loss: 0.0142712
DEBUG:root:[ Iteration 366 ] Training loss: 0.00605294
DEBUG:root:[ Iteration 369 ] Training loss: 0.0171657
DEBUG:root:[ Iteration 372 ] Training loss: 0.0133562
DEBUG:root:[ Iteration 375 ] Training loss: 0.0133369
DEBUG:root:[ Iteration 378 ] Training loss: 0.0149624
DEBUG:root:[ Iteration 380 ] Test loss: 0.0161527
DEBUG:root:[ Iteration 381 ] Training loss: 0.0172203
DEBUG:root:[ Iteration 384 ] Training loss: 0.0124234
DEBUG:root:[ Iteration 387 ] Training loss: 0.017269
DEBUG:root:[ Iteration 390 ] Training loss: 0.0286486
DEBUG:root:[ Iteration 393 ] Training loss: 0.0226384
DEBUG:root:[ Iteration 396 ] Training loss: 0.0272
DEBUG:root:[ Iteration 399 ] Training loss: 0.00787747
DEBUG:root:[ Iteration 400 ] Test loss: 0.0169283
DEBUG:root:[ Iteration 402 ] Training loss: 0.0157787
DEBUG:root:[ Iteration 405 ] Training loss: 0.0124462
DEBUG:root:[ Iteration 408 ] Training loss: 0.0106071
DEBUG:root:[ Iteration 411 ] Training loss: 0.0112202
DEBUG:root:[ Iteration 414 ] Training loss: 0.0106601
DEBUG:root:[ Iteration 417 ] Training loss: 0.00968719
DEBUG:root:[ Iteration 420 ] Training loss: 0.0142834
DEBUG:root:[ Iteration 420 ] Test loss: 0.0173014
DEBUG:root:[ Iteration 423 ] Training loss: 0.0160371
DEBUG:root:[ Iteration 426 ] Training loss: 0.00933747
DEBUG:root:[ Iteration 429 ] Training loss: 0.00853514
DEBUG:root:[ Iteration 432 ] Training loss: 0.0139618
DEBUG:root:[ Iteration 435 ] Training loss: 0.0196621
DEBUG:root:[ Iteration 438 ] Training loss: 0.0161758
DEBUG:root:[ Iteration 440 ] Test loss: 0.0153732
DEBUG:root:[ Iteration 441 ] Training loss: 0.0104472
DEBUG:root:[ Iteration 444 ] Training loss: 0.0158343
DEBUG:root:[ Iteration 447 ] Training loss: 0.0145038
DEBUG:root:[ Iteration 450 ] Training loss: 0.00997002
DEBUG:root:[ Iteration 453 ] Training loss: 0.00887621
DEBUG:root:[ Iteration 456 ] Training loss: 0.0181862
DEBUG:root:[ Iteration 459 ] Training loss: 0.00735311
DEBUG:root:[ Iteration 460 ] Test loss: 0.0153715
DEBUG:root:[ Iteration 462 ] Training loss: 0.0127389
DEBUG:root:[ Iteration 465 ] Training loss: 0.0112868
DEBUG:root:[ Iteration 468 ] Training loss: 0.0139718
DEBUG:root:[ Iteration 471 ] Training loss: 0.00925267
DEBUG:root:[ Iteration 474 ] Training loss: 0.0141067
DEBUG:root:[ Iteration 477 ] Training loss: 0.0120285
DEBUG:root:[ Iteration 480 ] Training loss: 0.0173633
DEBUG:root:[ Iteration 480 ] Test loss: 0.0151932
DEBUG:root:[ Iteration 483 ] Training loss: 0.0169961
DEBUG:root:[ Iteration 486 ] Training loss: 0.015204
DEBUG:root:[ Iteration 489 ] Training loss: 0.0119447
DEBUG:root:[ Iteration 492 ] Training loss: 0.0111342
DEBUG:root:[ Iteration 495 ] Training loss: 0.0111069
DEBUG:root:[ Iteration 498 ] Training loss: 0.00849621
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-24-2016_17h39m10s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.174274
DEBUG:root:[ Iteration 0 ] Test loss: 0.170562
DEBUG:root:[ Iteration 3 ] Training loss: 0.171618
DEBUG:root:[ Iteration 6 ] Training loss: 0.151781
DEBUG:root:[ Iteration 9 ] Training loss: 0.12241
DEBUG:root:[ Iteration 12 ] Training loss: 0.0946663
DEBUG:root:[ Iteration 15 ] Training loss: 0.0947232
DEBUG:root:[ Iteration 18 ] Training loss: 0.0923898
DEBUG:root:[ Iteration 20 ] Test loss: 0.0887604
DEBUG:root:[ Iteration 21 ] Training loss: 0.0865417
DEBUG:root:[ Iteration 24 ] Training loss: 0.0719821
DEBUG:root:[ Iteration 27 ] Training loss: 0.0934366
DEBUG:root:[ Iteration 30 ] Training loss: 0.076572
DEBUG:root:[ Iteration 33 ] Training loss: 0.0769517
DEBUG:root:[ Iteration 36 ] Training loss: 0.0769996
DEBUG:root:[ Iteration 39 ] Training loss: 0.0698944
DEBUG:root:[ Iteration 40 ] Test loss: 0.0696266
DEBUG:root:[ Iteration 42 ] Training loss: 0.0528811
DEBUG:root:[ Iteration 45 ] Training loss: 0.0601119
DEBUG:root:[ Iteration 48 ] Training loss: 0.0573042
DEBUG:root:[ Iteration 51 ] Training loss: 0.0397072
DEBUG:root:[ Iteration 54 ] Training loss: 0.0494439
DEBUG:root:[ Iteration 57 ] Training loss: 0.0477119
DEBUG:root:[ Iteration 60 ] Training loss: 0.0686447
DEBUG:root:[ Iteration 60 ] Test loss: 0.05839
DEBUG:root:[ Iteration 63 ] Training loss: 0.0373858
DEBUG:root:[ Iteration 66 ] Training loss: 0.0487076
DEBUG:root:[ Iteration 69 ] Training loss: 0.0550836
DEBUG:root:[ Iteration 72 ] Training loss: 0.0570544
DEBUG:root:[ Iteration 75 ] Training loss: 0.0485731
DEBUG:root:[ Iteration 78 ] Training loss: 0.0874394
DEBUG:root:[ Iteration 80 ] Test loss: 0.0688994
DEBUG:root:[ Iteration 81 ] Training loss: 0.0336366
DEBUG:root:[ Iteration 84 ] Training loss: 0.079582
DEBUG:root:[ Iteration 87 ] Training loss: 0.0899438
DEBUG:root:[ Iteration 90 ] Training loss: 0.0522394
DEBUG:root:[ Iteration 93 ] Training loss: 0.0402525
DEBUG:root:[ Iteration 96 ] Training loss: 0.0473457
DEBUG:root:[ Iteration 99 ] Training loss: 0.0363972
DEBUG:root:[ Iteration 100 ] Test loss: 0.0502894
DEBUG:root:[ Iteration 102 ] Training loss: 0.0323029
DEBUG:root:[ Iteration 105 ] Training loss: 0.0379156
DEBUG:root:[ Iteration 108 ] Training loss: 0.0383557
DEBUG:root:[ Iteration 111 ] Training loss: 0.0402224
DEBUG:root:[ Iteration 114 ] Training loss: 0.0305697
DEBUG:root:[ Iteration 117 ] Training loss: 0.0334616
DEBUG:root:[ Iteration 120 ] Training loss: 0.0276085
DEBUG:root:[ Iteration 120 ] Test loss: 0.0361526
DEBUG:root:[ Iteration 123 ] Training loss: 0.0326286
DEBUG:root:[ Iteration 126 ] Training loss: 0.0304666
DEBUG:root:[ Iteration 129 ] Training loss: 0.027405
DEBUG:root:[ Iteration 132 ] Training loss: 0.0366234
DEBUG:root:[ Iteration 135 ] Training loss: 0.0321515
DEBUG:root:[ Iteration 138 ] Training loss: 0.0323346
DEBUG:root:[ Iteration 140 ] Test loss: 0.0440407
DEBUG:root:[ Iteration 141 ] Training loss: 0.0369037
DEBUG:root:[ Iteration 144 ] Training loss: 0.0224599
DEBUG:root:[ Iteration 147 ] Training loss: 0.0300723
DEBUG:root:[ Iteration 150 ] Training loss: 0.030072
DEBUG:root:[ Iteration 153 ] Training loss: 0.0339091
DEBUG:root:[ Iteration 156 ] Training loss: 0.0329639
DEBUG:root:[ Iteration 159 ] Training loss: 0.0330386
DEBUG:root:[ Iteration 160 ] Test loss: 0.0332057
DEBUG:root:[ Iteration 162 ] Training loss: 0.0404916
DEBUG:root:[ Iteration 165 ] Training loss: 0.0384731
DEBUG:root:[ Iteration 168 ] Training loss: 0.039598
DEBUG:root:[ Iteration 171 ] Training loss: 0.0349528
DEBUG:root:[ Iteration 174 ] Training loss: 0.0242955
DEBUG:root:[ Iteration 177 ] Training loss: 0.0236499
DEBUG:root:[ Iteration 180 ] Training loss: 0.022413
DEBUG:root:[ Iteration 180 ] Test loss: 0.0327254
DEBUG:root:[ Iteration 183 ] Training loss: 0.0253885
DEBUG:root:[ Iteration 186 ] Training loss: 0.0332294
DEBUG:root:[ Iteration 189 ] Training loss: 0.019741
DEBUG:root:[ Iteration 192 ] Training loss: 0.0284097
DEBUG:root:[ Iteration 195 ] Training loss: 0.0216966
DEBUG:root:[ Iteration 198 ] Training loss: 0.0269713
DEBUG:root:[ Iteration 200 ] Test loss: 0.0347747
DEBUG:root:[ Iteration 201 ] Training loss: 0.0276304
DEBUG:root:[ Iteration 204 ] Training loss: 0.0258903
DEBUG:root:[ Iteration 207 ] Training loss: 0.030435
DEBUG:root:[ Iteration 210 ] Training loss: 0.0333804
DEBUG:root:[ Iteration 213 ] Training loss: 0.0279625
DEBUG:root:[ Iteration 216 ] Training loss: 0.0182767
DEBUG:root:[ Iteration 219 ] Training loss: 0.0225121
DEBUG:root:[ Iteration 220 ] Test loss: 0.0278513
DEBUG:root:[ Iteration 222 ] Training loss: 0.0236473
DEBUG:root:[ Iteration 225 ] Training loss: 0.023871
DEBUG:root:[ Iteration 228 ] Training loss: 0.0189577
DEBUG:root:[ Iteration 231 ] Training loss: 0.0276193
DEBUG:root:[ Iteration 234 ] Training loss: 0.0268544
DEBUG:root:[ Iteration 237 ] Training loss: 0.0297366
DEBUG:root:[ Iteration 240 ] Training loss: 0.0373025
DEBUG:root:[ Iteration 240 ] Test loss: 0.0350545
DEBUG:root:[ Iteration 243 ] Training loss: 0.0259223
DEBUG:root:[ Iteration 246 ] Training loss: 0.0364256
DEBUG:root:[ Iteration 249 ] Training loss: 0.0323737
DEBUG:root:[ Iteration 252 ] Training loss: 0.0284524
DEBUG:root:[ Iteration 255 ] Training loss: 0.0248917
DEBUG:root:[ Iteration 258 ] Training loss: 0.0203873
DEBUG:root:[ Iteration 260 ] Test loss: 0.0272412
DEBUG:root:[ Iteration 261 ] Training loss: 0.0208126
DEBUG:root:[ Iteration 264 ] Training loss: 0.0232433
DEBUG:root:[ Iteration 267 ] Training loss: 0.0216221
DEBUG:root:[ Iteration 270 ] Training loss: 0.0214318
DEBUG:root:[ Iteration 273 ] Training loss: 0.0282761
DEBUG:root:[ Iteration 276 ] Training loss: 0.0219717
DEBUG:root:[ Iteration 279 ] Training loss: 0.0290837
DEBUG:root:[ Iteration 280 ] Test loss: 0.0308255
DEBUG:root:[ Iteration 282 ] Training loss: 0.0239513
DEBUG:root:[ Iteration 285 ] Training loss: 0.0233331
DEBUG:root:[ Iteration 288 ] Training loss: 0.0238593
DEBUG:root:[ Iteration 291 ] Training loss: 0.0362824
DEBUG:root:[ Iteration 294 ] Training loss: 0.0203176
DEBUG:root:[ Iteration 297 ] Training loss: 0.0273846
DEBUG:root:[ Iteration 300 ] Training loss: 0.0202413
DEBUG:root:[ Iteration 300 ] Test loss: 0.0279436
DEBUG:root:[ Iteration 303 ] Training loss: 0.0248475
DEBUG:root:[ Iteration 306 ] Training loss: 0.0234268
DEBUG:root:[ Iteration 309 ] Training loss: 0.0103285
DEBUG:root:[ Iteration 312 ] Training loss: 0.0177641
DEBUG:root:[ Iteration 315 ] Training loss: 0.0140462
DEBUG:root:[ Iteration 318 ] Training loss: 0.0216503
DEBUG:root:[ Iteration 320 ] Test loss: 0.025688
DEBUG:root:[ Iteration 321 ] Training loss: 0.01424
DEBUG:root:[ Iteration 324 ] Training loss: 0.0228619
DEBUG:root:[ Iteration 327 ] Training loss: 0.0130078
DEBUG:root:[ Iteration 330 ] Training loss: 0.0167647
DEBUG:root:[ Iteration 333 ] Training loss: 0.0253466
DEBUG:root:[ Iteration 336 ] Training loss: 0.0180852
DEBUG:root:[ Iteration 339 ] Training loss: 0.0259322
DEBUG:root:[ Iteration 340 ] Test loss: 0.0289369
DEBUG:root:[ Iteration 342 ] Training loss: 0.0210136
DEBUG:root:[ Iteration 345 ] Training loss: 0.0201185
DEBUG:root:[ Iteration 348 ] Training loss: 0.0183612
DEBUG:root:[ Iteration 351 ] Training loss: 0.0215912
DEBUG:root:[ Iteration 354 ] Training loss: 0.0227264
DEBUG:root:[ Iteration 357 ] Training loss: 0.0189289
DEBUG:root:[ Iteration 360 ] Training loss: 0.0129209
DEBUG:root:[ Iteration 360 ] Test loss: 0.0281464
DEBUG:root:[ Iteration 363 ] Training loss: 0.0331992
DEBUG:root:[ Iteration 366 ] Training loss: 0.0249074
DEBUG:root:[ Iteration 369 ] Training loss: 0.0187955
DEBUG:root:[ Iteration 372 ] Training loss: 0.0196223
DEBUG:root:[ Iteration 375 ] Training loss: 0.0151572
DEBUG:root:[ Iteration 378 ] Training loss: 0.0116816
DEBUG:root:[ Iteration 380 ] Test loss: 0.0246411
DEBUG:root:[ Iteration 381 ] Training loss: 0.0317854
DEBUG:root:[ Iteration 384 ] Training loss: 0.0161772
DEBUG:root:[ Iteration 387 ] Training loss: 0.0167715
DEBUG:root:[ Iteration 390 ] Training loss: 0.0182406
DEBUG:root:[ Iteration 393 ] Training loss: 0.0195769
DEBUG:root:[ Iteration 396 ] Training loss: 0.0161256
DEBUG:root:[ Iteration 399 ] Training loss: 0.0142544
DEBUG:root:[ Iteration 400 ] Test loss: 0.0266123
DEBUG:root:[ Iteration 402 ] Training loss: 0.0241357
DEBUG:root:[ Iteration 405 ] Training loss: 0.0184931
DEBUG:root:[ Iteration 408 ] Training loss: 0.0181468
DEBUG:root:[ Iteration 411 ] Training loss: 0.0185008
DEBUG:root:[ Iteration 414 ] Training loss: 0.0175761
DEBUG:root:[ Iteration 417 ] Training loss: 0.0219457
DEBUG:root:[ Iteration 420 ] Training loss: 0.0170678
DEBUG:root:[ Iteration 420 ] Test loss: 0.0277218
DEBUG:root:[ Iteration 423 ] Training loss: 0.018971
DEBUG:root:[ Iteration 426 ] Training loss: 0.0187215
DEBUG:root:[ Iteration 429 ] Training loss: 0.0281542
DEBUG:root:[ Iteration 432 ] Training loss: 0.01464
DEBUG:root:[ Iteration 435 ] Training loss: 0.0193714
DEBUG:root:[ Iteration 438 ] Training loss: 0.0194604
DEBUG:root:[ Iteration 440 ] Test loss: 0.0236071
DEBUG:root:[ Iteration 441 ] Training loss: 0.0260746
DEBUG:root:[ Iteration 444 ] Training loss: 0.0163033
DEBUG:root:[ Iteration 447 ] Training loss: 0.0338373
DEBUG:root:[ Iteration 450 ] Training loss: 0.0150051
DEBUG:root:[ Iteration 453 ] Training loss: 0.0301117
DEBUG:root:[ Iteration 456 ] Training loss: 0.0186633
DEBUG:root:[ Iteration 459 ] Training loss: 0.0151948
DEBUG:root:[ Iteration 460 ] Test loss: 0.0235724
DEBUG:root:[ Iteration 462 ] Training loss: 0.0211693
DEBUG:root:[ Iteration 465 ] Training loss: 0.0170432
DEBUG:root:[ Iteration 468 ] Training loss: 0.0100854
DEBUG:root:[ Iteration 471 ] Training loss: 0.0149242
DEBUG:root:[ Iteration 474 ] Training loss: 0.022103
DEBUG:root:[ Iteration 477 ] Training loss: 0.0166315
DEBUG:root:[ Iteration 480 ] Training loss: 0.0184769
DEBUG:root:[ Iteration 480 ] Test loss: 0.0261946
DEBUG:root:[ Iteration 483 ] Training loss: 0.0198776
DEBUG:root:[ Iteration 486 ] Training loss: 0.0235039
DEBUG:root:[ Iteration 489 ] Training loss: 0.0260632
DEBUG:root:[ Iteration 492 ] Training loss: 0.023324
DEBUG:root:[ Iteration 495 ] Training loss: 0.0276869
DEBUG:root:[ Iteration 498 ] Training loss: 0.0168265
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-24-2016_18h50m20s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.119814
DEBUG:root:[ Iteration 0 ] Test loss: 0.118357
DEBUG:root:[ Iteration 3 ] Training loss: 0.0947763
DEBUG:root:[ Iteration 6 ] Training loss: 0.113399
DEBUG:root:[ Iteration 9 ] Training loss: 0.0765843
DEBUG:root:[ Iteration 12 ] Training loss: 0.108963
DEBUG:root:[ Iteration 15 ] Training loss: 0.0688915
DEBUG:root:[ Iteration 18 ] Training loss: 0.0655422
DEBUG:root:[ Iteration 20 ] Test loss: 0.071195
DEBUG:root:[ Iteration 21 ] Training loss: 0.087474
DEBUG:root:[ Iteration 24 ] Training loss: 0.0520066
DEBUG:root:[ Iteration 27 ] Training loss: 0.0722857
DEBUG:root:[ Iteration 30 ] Training loss: 0.0733398
DEBUG:root:[ Iteration 33 ] Training loss: 0.0692737
DEBUG:root:[ Iteration 36 ] Training loss: 0.0714153
DEBUG:root:[ Iteration 39 ] Training loss: 0.0684087
DEBUG:root:[ Iteration 40 ] Test loss: 0.0629337
DEBUG:root:[ Iteration 42 ] Training loss: 0.058686
DEBUG:root:[ Iteration 45 ] Training loss: 0.0632608
DEBUG:root:[ Iteration 48 ] Training loss: 0.0760002
DEBUG:root:[ Iteration 51 ] Training loss: 0.0505602
DEBUG:root:[ Iteration 54 ] Training loss: 0.0565315
DEBUG:root:[ Iteration 57 ] Training loss: 0.0413642
DEBUG:root:[ Iteration 60 ] Training loss: 0.0469931
DEBUG:root:[ Iteration 60 ] Test loss: 0.0532305
DEBUG:root:[ Iteration 63 ] Training loss: 0.0478742
DEBUG:root:[ Iteration 66 ] Training loss: 0.0514407
DEBUG:root:[ Iteration 69 ] Training loss: 0.0371774
DEBUG:root:[ Iteration 72 ] Training loss: 0.0542698
DEBUG:root:[ Iteration 75 ] Training loss: 0.035137
DEBUG:root:[ Iteration 78 ] Training loss: 0.0338141
DEBUG:root:[ Iteration 80 ] Test loss: 0.0441359
DEBUG:root:[ Iteration 81 ] Training loss: 0.0396234
DEBUG:root:[ Iteration 84 ] Training loss: 0.0485853
DEBUG:root:[ Iteration 87 ] Training loss: 0.029431
DEBUG:root:[ Iteration 90 ] Training loss: 0.033153
DEBUG:root:[ Iteration 93 ] Training loss: 0.0406436
DEBUG:root:[ Iteration 96 ] Training loss: 0.0346743
DEBUG:root:[ Iteration 99 ] Training loss: 0.0264163
DEBUG:root:[ Iteration 100 ] Test loss: 0.0360178
DEBUG:root:[ Iteration 102 ] Training loss: 0.0243513
DEBUG:root:[ Iteration 105 ] Training loss: 0.0420137
DEBUG:root:[ Iteration 108 ] Training loss: 0.0282819
DEBUG:root:[ Iteration 111 ] Training loss: 0.0244092
DEBUG:root:[ Iteration 114 ] Training loss: 0.0398222
DEBUG:root:[ Iteration 117 ] Training loss: 0.0356269
DEBUG:root:[ Iteration 120 ] Training loss: 0.0204919
DEBUG:root:[ Iteration 120 ] Test loss: 0.0322985
DEBUG:root:[ Iteration 123 ] Training loss: 0.0277434
DEBUG:root:[ Iteration 126 ] Training loss: 0.026336
DEBUG:root:[ Iteration 129 ] Training loss: 0.0374576
DEBUG:root:[ Iteration 132 ] Training loss: 0.0351512
DEBUG:root:[ Iteration 135 ] Training loss: 0.0313155
DEBUG:root:[ Iteration 138 ] Training loss: 0.0389186
DEBUG:root:[ Iteration 140 ] Test loss: 0.0426598
DEBUG:root:[ Iteration 141 ] Training loss: 0.03541
DEBUG:root:[ Iteration 144 ] Training loss: 0.0270449
DEBUG:root:[ Iteration 147 ] Training loss: 0.016968
DEBUG:root:[ Iteration 150 ] Training loss: 0.0286736
DEBUG:root:[ Iteration 153 ] Training loss: 0.0316624
DEBUG:root:[ Iteration 156 ] Training loss: 0.0298301
DEBUG:root:[ Iteration 159 ] Training loss: 0.0269027
DEBUG:root:[ Iteration 160 ] Test loss: 0.0296838
DEBUG:root:[ Iteration 162 ] Training loss: 0.0308841
DEBUG:root:[ Iteration 165 ] Training loss: 0.0320021
DEBUG:root:[ Iteration 168 ] Training loss: 0.0337779
DEBUG:root:[ Iteration 171 ] Training loss: 0.0277596
DEBUG:root:[ Iteration 174 ] Training loss: 0.0201762
DEBUG:root:[ Iteration 177 ] Training loss: 0.0219525
DEBUG:root:[ Iteration 180 ] Training loss: 0.0187352
DEBUG:root:[ Iteration 180 ] Test loss: 0.0261686
DEBUG:root:[ Iteration 183 ] Training loss: 0.0208478
DEBUG:root:[ Iteration 186 ] Training loss: 0.0209424
DEBUG:root:[ Iteration 189 ] Training loss: 0.0284423
DEBUG:root:[ Iteration 192 ] Training loss: 0.0198035
DEBUG:root:[ Iteration 195 ] Training loss: 0.024058
DEBUG:root:[ Iteration 198 ] Training loss: 0.0177209
DEBUG:root:[ Iteration 200 ] Test loss: 0.0267042
DEBUG:root:[ Iteration 201 ] Training loss: 0.0219611
DEBUG:root:[ Iteration 204 ] Training loss: 0.0308881
DEBUG:root:[ Iteration 207 ] Training loss: 0.0139645
DEBUG:root:[ Iteration 210 ] Training loss: 0.0244761
DEBUG:root:[ Iteration 213 ] Training loss: 0.0187205
DEBUG:root:[ Iteration 216 ] Training loss: 0.0221726
DEBUG:root:[ Iteration 219 ] Training loss: 0.0244345
DEBUG:root:[ Iteration 220 ] Test loss: 0.0274548
DEBUG:root:[ Iteration 222 ] Training loss: 0.0225517
DEBUG:root:[ Iteration 225 ] Training loss: 0.013269
DEBUG:root:[ Iteration 228 ] Training loss: 0.0238381
DEBUG:root:[ Iteration 231 ] Training loss: 0.014852
DEBUG:root:[ Iteration 234 ] Training loss: 0.0138438
DEBUG:root:[ Iteration 237 ] Training loss: 0.0182389
DEBUG:root:[ Iteration 240 ] Training loss: 0.0251359
DEBUG:root:[ Iteration 240 ] Test loss: 0.0271638
DEBUG:root:[ Iteration 243 ] Training loss: 0.0183428
DEBUG:root:[ Iteration 246 ] Training loss: 0.0230611
DEBUG:root:[ Iteration 249 ] Training loss: 0.0149009
DEBUG:root:[ Iteration 252 ] Training loss: 0.0238181
DEBUG:root:[ Iteration 255 ] Training loss: 0.0188396
DEBUG:root:[ Iteration 258 ] Training loss: 0.0148005
DEBUG:root:[ Iteration 260 ] Test loss: 0.0268198
DEBUG:root:[ Iteration 261 ] Training loss: 0.019778
DEBUG:root:[ Iteration 264 ] Training loss: 0.0240855
DEBUG:root:[ Iteration 267 ] Training loss: 0.0172844
DEBUG:root:[ Iteration 270 ] Training loss: 0.0163827
DEBUG:root:[ Iteration 273 ] Training loss: 0.021146
DEBUG:root:[ Iteration 276 ] Training loss: 0.0202477
DEBUG:root:[ Iteration 279 ] Training loss: 0.0185723
DEBUG:root:[ Iteration 280 ] Test loss: 0.0245947
DEBUG:root:[ Iteration 282 ] Training loss: 0.0186209
DEBUG:root:[ Iteration 285 ] Training loss: 0.0202571
DEBUG:root:[ Iteration 288 ] Training loss: 0.0126512
DEBUG:root:[ Iteration 291 ] Training loss: 0.0166703
DEBUG:root:[ Iteration 294 ] Training loss: 0.0161561
DEBUG:root:[ Iteration 297 ] Training loss: 0.0130471
DEBUG:root:[ Iteration 300 ] Training loss: 0.0184178
DEBUG:root:[ Iteration 300 ] Test loss: 0.0222156
DEBUG:root:[ Iteration 303 ] Training loss: 0.0204427
DEBUG:root:[ Iteration 306 ] Training loss: 0.0213932
DEBUG:root:[ Iteration 309 ] Training loss: 0.0235982
DEBUG:root:[ Iteration 312 ] Training loss: 0.016697
DEBUG:root:[ Iteration 315 ] Training loss: 0.0165668
DEBUG:root:[ Iteration 318 ] Training loss: 0.0238602
DEBUG:root:[ Iteration 320 ] Test loss: 0.0239974
DEBUG:root:[ Iteration 321 ] Training loss: 0.0158609
DEBUG:root:[ Iteration 324 ] Training loss: 0.0178366
DEBUG:root:[ Iteration 327 ] Training loss: 0.0251699
DEBUG:root:[ Iteration 330 ] Training loss: 0.0138714
DEBUG:root:[ Iteration 333 ] Training loss: 0.0168719
DEBUG:root:[ Iteration 336 ] Training loss: 0.0200767
DEBUG:root:[ Iteration 339 ] Training loss: 0.0155395
DEBUG:root:[ Iteration 340 ] Test loss: 0.0225223
DEBUG:root:[ Iteration 342 ] Training loss: 0.0193373
DEBUG:root:[ Iteration 345 ] Training loss: 0.0162115
DEBUG:root:[ Iteration 348 ] Training loss: 0.0166552
DEBUG:root:[ Iteration 351 ] Training loss: 0.0173751
DEBUG:root:[ Iteration 354 ] Training loss: 0.0262223
DEBUG:root:[ Iteration 357 ] Training loss: 0.0170682
DEBUG:root:[ Iteration 360 ] Training loss: 0.0155515
DEBUG:root:[ Iteration 360 ] Test loss: 0.0227352
DEBUG:root:[ Iteration 363 ] Training loss: 0.0143634
DEBUG:root:[ Iteration 366 ] Training loss: 0.0130232
DEBUG:root:[ Iteration 369 ] Training loss: 0.0118128
DEBUG:root:[ Iteration 372 ] Training loss: 0.0199624
DEBUG:root:[ Iteration 375 ] Training loss: 0.0208249
DEBUG:root:[ Iteration 378 ] Training loss: 0.0227342
DEBUG:root:[ Iteration 380 ] Test loss: 0.0201131
DEBUG:root:[ Iteration 381 ] Training loss: 0.024042
DEBUG:root:[ Iteration 384 ] Training loss: 0.0215979
DEBUG:root:[ Iteration 387 ] Training loss: 0.01355
DEBUG:root:[ Iteration 390 ] Training loss: 0.0106741
DEBUG:root:[ Iteration 393 ] Training loss: 0.0170554
DEBUG:root:[ Iteration 396 ] Training loss: 0.023398
DEBUG:root:[ Iteration 399 ] Training loss: 0.0196398
DEBUG:root:[ Iteration 400 ] Test loss: 0.022887
DEBUG:root:[ Iteration 402 ] Training loss: 0.0154133
DEBUG:root:[ Iteration 405 ] Training loss: 0.0191079
DEBUG:root:[ Iteration 408 ] Training loss: 0.0218515
DEBUG:root:[ Iteration 411 ] Training loss: 0.0200064
DEBUG:root:[ Iteration 414 ] Training loss: 0.0145062
DEBUG:root:[ Iteration 417 ] Training loss: 0.0145421
DEBUG:root:[ Iteration 420 ] Training loss: 0.013434
DEBUG:root:[ Iteration 420 ] Test loss: 0.0196187
DEBUG:root:[ Iteration 423 ] Training loss: 0.0164056
DEBUG:root:[ Iteration 426 ] Training loss: 0.0112844
DEBUG:root:[ Iteration 429 ] Training loss: 0.0142239
DEBUG:root:[ Iteration 432 ] Training loss: 0.0183829
DEBUG:root:[ Iteration 435 ] Training loss: 0.017159
DEBUG:root:[ Iteration 438 ] Training loss: 0.0144555
DEBUG:root:[ Iteration 440 ] Test loss: 0.0191679
DEBUG:root:[ Iteration 441 ] Training loss: 0.0121491
DEBUG:root:[ Iteration 444 ] Training loss: 0.013875
DEBUG:root:[ Iteration 447 ] Training loss: 0.0155215
DEBUG:root:[ Iteration 450 ] Training loss: 0.0144938
DEBUG:root:[ Iteration 453 ] Training loss: 0.0174403
DEBUG:root:[ Iteration 456 ] Training loss: 0.0165538
DEBUG:root:[ Iteration 459 ] Training loss: 0.0171515
DEBUG:root:[ Iteration 460 ] Test loss: 0.0185818
DEBUG:root:[ Iteration 462 ] Training loss: 0.0151316
DEBUG:root:[ Iteration 465 ] Training loss: 0.0145094
DEBUG:root:[ Iteration 468 ] Training loss: 0.0134713
DEBUG:root:[ Iteration 471 ] Training loss: 0.0140205
DEBUG:root:[ Iteration 474 ] Training loss: 0.0072382
DEBUG:root:[ Iteration 477 ] Training loss: 0.0139255
DEBUG:root:[ Iteration 480 ] Training loss: 0.00741304
DEBUG:root:[ Iteration 480 ] Test loss: 0.0180883
DEBUG:root:[ Iteration 483 ] Training loss: 0.0202328
DEBUG:root:[ Iteration 486 ] Training loss: 0.0145213
DEBUG:root:[ Iteration 489 ] Training loss: 0.0187509
DEBUG:root:[ Iteration 492 ] Training loss: 0.0259067
DEBUG:root:[ Iteration 495 ] Training loss: 0.0190983
DEBUG:root:[ Iteration 498 ] Training loss: 0.013173
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-24-2016_19h32m42s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.111572
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-24-2016_20h18m17s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.190947
DEBUG:root:[ Iteration 0 ] Test loss: 0.186202
DEBUG:root:[ Iteration 3 ] Training loss: 0.187886
DEBUG:root:[ Iteration 6 ] Training loss: 0.179263
DEBUG:root:[ Iteration 9 ] Training loss: 0.158565
DEBUG:root:[ Iteration 12 ] Training loss: 0.131518
DEBUG:root:[ Iteration 15 ] Training loss: 0.13602
DEBUG:root:[ Iteration 18 ] Training loss: 0.16352
DEBUG:root:[ Iteration 20 ] Test loss: 0.149667
DEBUG:root:[ Iteration 21 ] Training loss: 0.150737
DEBUG:root:[ Iteration 24 ] Training loss: 0.153951
DEBUG:root:[ Iteration 27 ] Training loss: 0.129768
DEBUG:root:[ Iteration 30 ] Training loss: 0.135108
DEBUG:root:[ Iteration 33 ] Training loss: 0.142738
DEBUG:root:[ Iteration 36 ] Training loss: 0.12299
DEBUG:root:[ Iteration 39 ] Training loss: 0.130231
DEBUG:root:[ Iteration 40 ] Test loss: 0.126916
DEBUG:root:[ Iteration 42 ] Training loss: 0.121756
DEBUG:root:[ Iteration 45 ] Training loss: 0.134879
DEBUG:root:[ Iteration 48 ] Training loss: 0.121883
DEBUG:root:[ Iteration 51 ] Training loss: 0.10334
DEBUG:root:[ Iteration 54 ] Training loss: 0.1103
DEBUG:root:[ Iteration 57 ] Training loss: 0.112531
DEBUG:root:[ Iteration 60 ] Training loss: 0.114472
DEBUG:root:[ Iteration 60 ] Test loss: 0.10245
DEBUG:root:[ Iteration 63 ] Training loss: 0.0936162
DEBUG:root:[ Iteration 66 ] Training loss: 0.082879
DEBUG:root:[ Iteration 69 ] Training loss: 0.109671
DEBUG:root:[ Iteration 72 ] Training loss: 0.098685
DEBUG:root:[ Iteration 75 ] Training loss: 0.0810841
DEBUG:root:[ Iteration 78 ] Training loss: 0.0852487
DEBUG:root:[ Iteration 80 ] Test loss: 0.0850653
DEBUG:root:[ Iteration 81 ] Training loss: 0.0847289
DEBUG:root:[ Iteration 84 ] Training loss: 0.065714
DEBUG:root:[ Iteration 87 ] Training loss: 0.0805255
DEBUG:root:[ Iteration 90 ] Training loss: 0.0699199
DEBUG:root:[ Iteration 93 ] Training loss: 0.0689057
DEBUG:root:[ Iteration 96 ] Training loss: 0.072139
DEBUG:root:[ Iteration 99 ] Training loss: 0.0695292
DEBUG:root:[ Iteration 100 ] Test loss: 0.0705034
DEBUG:root:[ Iteration 102 ] Training loss: 0.0635397
DEBUG:root:[ Iteration 105 ] Training loss: 0.0517193
DEBUG:root:[ Iteration 108 ] Training loss: 0.0625582
DEBUG:root:[ Iteration 111 ] Training loss: 0.0545529
DEBUG:root:[ Iteration 114 ] Training loss: 0.0568451
DEBUG:root:[ Iteration 117 ] Training loss: 0.0504555
DEBUG:root:[ Iteration 120 ] Training loss: 0.0504076
DEBUG:root:[ Iteration 120 ] Test loss: 0.0568174
DEBUG:root:[ Iteration 123 ] Training loss: 0.0478315
DEBUG:root:[ Iteration 126 ] Training loss: 0.0776335
DEBUG:root:[ Iteration 129 ] Training loss: 0.061756
DEBUG:root:[ Iteration 132 ] Training loss: 0.0517977
DEBUG:root:[ Iteration 135 ] Training loss: 0.0711219
DEBUG:root:[ Iteration 138 ] Training loss: 0.0887291
DEBUG:root:[ Iteration 140 ] Test loss: 0.0707594
DEBUG:root:[ Iteration 141 ] Training loss: 0.0495594
DEBUG:root:[ Iteration 144 ] Training loss: 0.061663
DEBUG:root:[ Iteration 147 ] Training loss: 0.0481368
DEBUG:root:[ Iteration 150 ] Training loss: 0.0408209
DEBUG:root:[ Iteration 153 ] Training loss: 0.0482426
DEBUG:root:[ Iteration 156 ] Training loss: 0.0511302
DEBUG:root:[ Iteration 159 ] Training loss: 0.0460872
DEBUG:root:[ Iteration 160 ] Test loss: 0.0462488
DEBUG:root:[ Iteration 162 ] Training loss: 0.0607398
DEBUG:root:[ Iteration 165 ] Training loss: 0.0460934
DEBUG:root:[ Iteration 168 ] Training loss: 0.0393713
DEBUG:root:[ Iteration 171 ] Training loss: 0.0455376
DEBUG:root:[ Iteration 174 ] Training loss: 0.0439235
DEBUG:root:[ Iteration 177 ] Training loss: 0.0440873
DEBUG:root:[ Iteration 180 ] Training loss: 0.0328144
DEBUG:root:[ Iteration 180 ] Test loss: 0.0425659
DEBUG:root:[ Iteration 183 ] Training loss: 0.0335207
DEBUG:root:[ Iteration 186 ] Training loss: 0.031501
DEBUG:root:[ Iteration 189 ] Training loss: 0.0477511
DEBUG:root:[ Iteration 192 ] Training loss: 0.038192
DEBUG:root:[ Iteration 195 ] Training loss: 0.0326524
DEBUG:root:[ Iteration 198 ] Training loss: 0.0393278
DEBUG:root:[ Iteration 200 ] Test loss: 0.0466656
DEBUG:root:[ Iteration 201 ] Training loss: 0.0479858
DEBUG:root:[ Iteration 204 ] Training loss: 0.035069
DEBUG:root:[ Iteration 207 ] Training loss: 0.0283289
DEBUG:root:[ Iteration 210 ] Training loss: 0.0293892
DEBUG:root:[ Iteration 213 ] Training loss: 0.0566048
DEBUG:root:[ Iteration 216 ] Training loss: 0.0325843
DEBUG:root:[ Iteration 219 ] Training loss: 0.0335109
DEBUG:root:[ Iteration 220 ] Test loss: 0.0329071
DEBUG:root:[ Iteration 222 ] Training loss: 0.0399015
DEBUG:root:[ Iteration 225 ] Training loss: 0.0198455
DEBUG:root:[ Iteration 228 ] Training loss: 0.0174804
DEBUG:root:[ Iteration 231 ] Training loss: 0.0258716
DEBUG:root:[ Iteration 234 ] Training loss: 0.0323075
DEBUG:root:[ Iteration 237 ] Training loss: 0.0249865
DEBUG:root:[ Iteration 240 ] Training loss: 0.0309448
DEBUG:root:[ Iteration 240 ] Test loss: 0.0334155
DEBUG:root:[ Iteration 243 ] Training loss: 0.0218413
DEBUG:root:[ Iteration 246 ] Training loss: 0.0248323
DEBUG:root:[ Iteration 249 ] Training loss: 0.027907
DEBUG:root:[ Iteration 252 ] Training loss: 0.0240497
DEBUG:root:[ Iteration 255 ] Training loss: 0.0193944
DEBUG:root:[ Iteration 258 ] Training loss: 0.0303744
DEBUG:root:[ Iteration 260 ] Test loss: 0.0301941
DEBUG:root:[ Iteration 261 ] Training loss: 0.0329688
DEBUG:root:[ Iteration 264 ] Training loss: 0.0279536
DEBUG:root:[ Iteration 267 ] Training loss: 0.0209247
DEBUG:root:[ Iteration 270 ] Training loss: 0.0260057
DEBUG:root:[ Iteration 273 ] Training loss: 0.0287774
DEBUG:root:[ Iteration 276 ] Training loss: 0.0274412
DEBUG:root:[ Iteration 279 ] Training loss: 0.0293288
DEBUG:root:[ Iteration 280 ] Test loss: 0.0384475
DEBUG:root:[ Iteration 282 ] Training loss: 0.0338869
DEBUG:root:[ Iteration 285 ] Training loss: 0.0239147
DEBUG:root:[ Iteration 288 ] Training loss: 0.0315047
DEBUG:root:[ Iteration 291 ] Training loss: 0.0230068
DEBUG:root:[ Iteration 294 ] Training loss: 0.0334898
DEBUG:root:[ Iteration 297 ] Training loss: 0.0320999
DEBUG:root:[ Iteration 300 ] Training loss: 0.0294876
DEBUG:root:[ Iteration 300 ] Test loss: 0.0285717
DEBUG:root:[ Iteration 303 ] Training loss: 0.0309945
DEBUG:root:[ Iteration 306 ] Training loss: 0.0305083
DEBUG:root:[ Iteration 309 ] Training loss: 0.0322229
DEBUG:root:[ Iteration 312 ] Training loss: 0.0281424
DEBUG:root:[ Iteration 315 ] Training loss: 0.0262912
DEBUG:root:[ Iteration 318 ] Training loss: 0.0168687
DEBUG:root:[ Iteration 320 ] Test loss: 0.0307706
DEBUG:root:[ Iteration 321 ] Training loss: 0.0413713
DEBUG:root:[ Iteration 324 ] Training loss: 0.0220732
DEBUG:root:[ Iteration 327 ] Training loss: 0.0286857
DEBUG:root:[ Iteration 330 ] Training loss: 0.0441488
DEBUG:root:[ Iteration 333 ] Training loss: 0.0252076
DEBUG:root:[ Iteration 336 ] Training loss: 0.0268144
DEBUG:root:[ Iteration 339 ] Training loss: 0.0251045
DEBUG:root:[ Iteration 340 ] Test loss: 0.0277365
DEBUG:root:[ Iteration 342 ] Training loss: 0.0227613
DEBUG:root:[ Iteration 345 ] Training loss: 0.0233297
DEBUG:root:[ Iteration 348 ] Training loss: 0.0291934
DEBUG:root:[ Iteration 351 ] Training loss: 0.0259976
DEBUG:root:[ Iteration 354 ] Training loss: 0.0222444
DEBUG:root:[ Iteration 357 ] Training loss: 0.0255455
DEBUG:root:[ Iteration 360 ] Training loss: 0.0229468
DEBUG:root:[ Iteration 360 ] Test loss: 0.0258575
DEBUG:root:[ Iteration 363 ] Training loss: 0.0281362
DEBUG:root:[ Iteration 366 ] Training loss: 0.0283952
DEBUG:root:[ Iteration 369 ] Training loss: 0.0240724
DEBUG:root:[ Iteration 372 ] Training loss: 0.018041
DEBUG:root:[ Iteration 375 ] Training loss: 0.0203645
DEBUG:root:[ Iteration 378 ] Training loss: 0.0175349
DEBUG:root:[ Iteration 380 ] Test loss: 0.0266911
DEBUG:root:[ Iteration 381 ] Training loss: 0.0297456
DEBUG:root:[ Iteration 384 ] Training loss: 0.0298791
DEBUG:root:[ Iteration 387 ] Training loss: 0.0324732
DEBUG:root:[ Iteration 390 ] Training loss: 0.0316213
DEBUG:root:[ Iteration 393 ] Training loss: 0.0292636
DEBUG:root:[ Iteration 396 ] Training loss: 0.0252126
DEBUG:root:[ Iteration 399 ] Training loss: 0.0270371
DEBUG:root:[ Iteration 400 ] Test loss: 0.0322844
DEBUG:root:[ Iteration 402 ] Training loss: 0.0195823
DEBUG:root:[ Iteration 405 ] Training loss: 0.014286
DEBUG:root:[ Iteration 408 ] Training loss: 0.0271895
DEBUG:root:[ Iteration 411 ] Training loss: 0.039146
DEBUG:root:[ Iteration 414 ] Training loss: 0.0390347
DEBUG:root:[ Iteration 417 ] Training loss: 0.0310734
DEBUG:root:[ Iteration 420 ] Training loss: 0.0250333
DEBUG:root:[ Iteration 420 ] Test loss: 0.0302345
DEBUG:root:[ Iteration 423 ] Training loss: 0.0266005
DEBUG:root:[ Iteration 426 ] Training loss: 0.0207861
DEBUG:root:[ Iteration 429 ] Training loss: 0.0258284
DEBUG:root:[ Iteration 432 ] Training loss: 0.0322121
DEBUG:root:[ Iteration 435 ] Training loss: 0.0228818
DEBUG:root:[ Iteration 438 ] Training loss: 0.0408412
DEBUG:root:[ Iteration 440 ] Test loss: 0.0264063
DEBUG:root:[ Iteration 441 ] Training loss: 0.0260121
DEBUG:root:[ Iteration 444 ] Training loss: 0.0253173
DEBUG:root:[ Iteration 447 ] Training loss: 0.0209982
DEBUG:root:[ Iteration 450 ] Training loss: 0.0279963
DEBUG:root:[ Iteration 453 ] Training loss: 0.0246322
DEBUG:root:[ Iteration 456 ] Training loss: 0.0231875
DEBUG:root:[ Iteration 459 ] Training loss: 0.0161599
DEBUG:root:[ Iteration 460 ] Test loss: 0.0241774
DEBUG:root:[ Iteration 462 ] Training loss: 0.0206655
DEBUG:root:[ Iteration 465 ] Training loss: 0.0263788
DEBUG:root:[ Iteration 468 ] Training loss: 0.0242328
DEBUG:root:[ Iteration 471 ] Training loss: 0.0164805
DEBUG:root:[ Iteration 474 ] Training loss: 0.0226484
DEBUG:root:[ Iteration 477 ] Training loss: 0.0238253
DEBUG:root:[ Iteration 480 ] Training loss: 0.0180986
DEBUG:root:[ Iteration 480 ] Test loss: 0.0252592
DEBUG:root:[ Iteration 483 ] Training loss: 0.0191151
DEBUG:root:[ Iteration 486 ] Training loss: 0.015249
DEBUG:root:[ Iteration 489 ] Training loss: 0.0276087
DEBUG:root:[ Iteration 492 ] Training loss: 0.0200005
DEBUG:root:[ Iteration 495 ] Training loss: 0.0194663
DEBUG:root:[ Iteration 498 ] Training loss: 0.0153116
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-26-2016_17h40m20s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.190548
DEBUG:root:[ Iteration 0 ] Test loss: 0.195021
DEBUG:root:[ Iteration 0 ] Training loss: 0.19576
DEBUG:root:[ Iteration 0 ] Test loss: 0.192101
DEBUG:root:[ Iteration 3 ] Training loss: 0.188104
DEBUG:root:[ Iteration 6 ] Training loss: 0.18679
DEBUG:root:[ Iteration 9 ] Training loss: 0.159852
DEBUG:root:[ Iteration 12 ] Training loss: 0.103247
DEBUG:root:[ Iteration 15 ] Training loss: 0.103308
DEBUG:root:[ Iteration 18 ] Training loss: 0.0846903
DEBUG:root:[ Iteration 20 ] Test loss: 0.112413
DEBUG:root:[ Iteration 21 ] Training loss: 0.096644
DEBUG:root:[ Iteration 24 ] Training loss: 0.0826352
DEBUG:root:[ Iteration 27 ] Training loss: 0.111435
DEBUG:root:[ Iteration 30 ] Training loss: 0.0938661
DEBUG:root:[ Iteration 33 ] Training loss: 0.106176
DEBUG:root:[ Iteration 36 ] Training loss: 0.0905686
DEBUG:root:[ Iteration 39 ] Training loss: 0.0948699
DEBUG:root:[ Iteration 40 ] Test loss: 0.0958132
DEBUG:root:[ Iteration 42 ] Training loss: 0.0865473
DEBUG:root:[ Iteration 45 ] Training loss: 0.064206
DEBUG:root:[ Iteration 48 ] Training loss: 0.0721484
DEBUG:root:[ Iteration 51 ] Training loss: 0.0940173
DEBUG:root:[ Iteration 54 ] Training loss: 0.0612186
DEBUG:root:[ Iteration 57 ] Training loss: 0.124887
DEBUG:root:[ Iteration 60 ] Training loss: 0.102044
DEBUG:root:[ Iteration 60 ] Test loss: 0.0886006
DEBUG:root:[ Iteration 63 ] Training loss: 0.0816128
DEBUG:root:[ Iteration 66 ] Training loss: 0.0875887
DEBUG:root:[ Iteration 69 ] Training loss: 0.0914781
DEBUG:root:[ Iteration 72 ] Training loss: 0.0605695
DEBUG:root:[ Iteration 75 ] Training loss: 0.06496
DEBUG:root:[ Iteration 78 ] Training loss: 0.0709501
DEBUG:root:[ Iteration 80 ] Test loss: 0.0805985
DEBUG:root:[ Iteration 81 ] Training loss: 0.0658099
DEBUG:root:[ Iteration 84 ] Training loss: 0.0741077
DEBUG:root:[ Iteration 87 ] Training loss: 0.0560582
DEBUG:root:[ Iteration 90 ] Training loss: 0.072273
DEBUG:root:[ Iteration 93 ] Training loss: 0.0681604
DEBUG:root:[ Iteration 96 ] Training loss: 0.06562
DEBUG:root:[ Iteration 99 ] Training loss: 0.0570883
DEBUG:root:[ Iteration 100 ] Test loss: 0.0636696
DEBUG:root:[ Iteration 102 ] Training loss: 0.0611815
DEBUG:root:[ Iteration 105 ] Training loss: 0.076567
DEBUG:root:[ Iteration 108 ] Training loss: 0.0634574
DEBUG:root:[ Iteration 111 ] Training loss: 0.0356394
DEBUG:root:[ Iteration 114 ] Training loss: 0.0646989
DEBUG:root:[ Iteration 117 ] Training loss: 0.0576584
DEBUG:root:[ Iteration 120 ] Training loss: 0.0760773
DEBUG:root:[ Iteration 120 ] Test loss: 0.0544105
DEBUG:root:[ Iteration 123 ] Training loss: 0.0569043
DEBUG:root:[ Iteration 126 ] Training loss: 0.0439256
DEBUG:root:[ Iteration 129 ] Training loss: 0.0612912
DEBUG:root:[ Iteration 132 ] Training loss: 0.037147
DEBUG:root:[ Iteration 135 ] Training loss: 0.0473421
DEBUG:root:[ Iteration 138 ] Training loss: 0.0512117
DEBUG:root:[ Iteration 140 ] Test loss: 0.0486392
DEBUG:root:[ Iteration 141 ] Training loss: 0.0306653
DEBUG:root:[ Iteration 144 ] Training loss: 0.0496742
DEBUG:root:[ Iteration 147 ] Training loss: 0.0460915
DEBUG:root:[ Iteration 150 ] Training loss: 0.0351806
DEBUG:root:[ Iteration 153 ] Training loss: 0.0321042
DEBUG:root:[ Iteration 156 ] Training loss: 0.0443484
DEBUG:root:[ Iteration 159 ] Training loss: 0.0490867
DEBUG:root:[ Iteration 160 ] Test loss: 0.0426806
DEBUG:root:[ Iteration 162 ] Training loss: 0.0378146
DEBUG:root:[ Iteration 165 ] Training loss: 0.0318293
DEBUG:root:[ Iteration 168 ] Training loss: 0.0376107
DEBUG:root:[ Iteration 171 ] Training loss: 0.0358282
DEBUG:root:[ Iteration 174 ] Training loss: 0.0324386
DEBUG:root:[ Iteration 177 ] Training loss: 0.0343443
DEBUG:root:[ Iteration 180 ] Training loss: 0.0257152
DEBUG:root:[ Iteration 180 ] Test loss: 0.0314327
DEBUG:root:[ Iteration 183 ] Training loss: 0.0343348
DEBUG:root:[ Iteration 186 ] Training loss: 0.0231477
DEBUG:root:[ Iteration 189 ] Training loss: 0.0356343
DEBUG:root:[ Iteration 192 ] Training loss: 0.029457
DEBUG:root:[ Iteration 195 ] Training loss: 0.0257577
DEBUG:root:[ Iteration 198 ] Training loss: 0.0366239
DEBUG:root:[ Iteration 200 ] Test loss: 0.0257589
DEBUG:root:[ Iteration 201 ] Training loss: 0.0279998
DEBUG:root:[ Iteration 204 ] Training loss: 0.0372669
DEBUG:root:[ Iteration 207 ] Training loss: 0.0237437
DEBUG:root:[ Iteration 210 ] Training loss: 0.0236715
DEBUG:root:[ Iteration 213 ] Training loss: 0.0164766
DEBUG:root:[ Iteration 216 ] Training loss: 0.0173549
DEBUG:root:[ Iteration 219 ] Training loss: 0.0164954
DEBUG:root:[ Iteration 220 ] Test loss: 0.0190027
DEBUG:root:[ Iteration 222 ] Training loss: 0.0198089
DEBUG:root:[ Iteration 225 ] Training loss: 0.0230361
DEBUG:root:[ Iteration 228 ] Training loss: 0.0189079
DEBUG:root:[ Iteration 231 ] Training loss: 0.0183528
DEBUG:root:[ Iteration 234 ] Training loss: 0.0161142
DEBUG:root:[ Iteration 237 ] Training loss: 0.0240026
DEBUG:root:[ Iteration 240 ] Training loss: 0.0205594
DEBUG:root:[ Iteration 240 ] Test loss: 0.0220086
DEBUG:root:[ Iteration 243 ] Training loss: 0.0136576
DEBUG:root:[ Iteration 246 ] Training loss: 0.017722
DEBUG:root:[ Iteration 249 ] Training loss: 0.0149137
DEBUG:root:[ Iteration 252 ] Training loss: 0.0128067
DEBUG:root:[ Iteration 255 ] Training loss: 0.0247911
DEBUG:root:[ Iteration 258 ] Training loss: 0.0107948
DEBUG:root:[ Iteration 260 ] Test loss: 0.0123889
DEBUG:root:[ Iteration 261 ] Training loss: 0.00842133
DEBUG:root:[ Iteration 264 ] Training loss: 0.0125022
DEBUG:root:[ Iteration 267 ] Training loss: 0.0152746
DEBUG:root:[ Iteration 270 ] Training loss: 0.00896913
DEBUG:root:[ Iteration 273 ] Training loss: 0.00974462
DEBUG:root:[ Iteration 276 ] Training loss: 0.0130907
DEBUG:root:[ Iteration 279 ] Training loss: 0.0132084
DEBUG:root:[ Iteration 280 ] Test loss: 0.0113
DEBUG:root:[ Iteration 282 ] Training loss: 0.0103305
DEBUG:root:[ Iteration 285 ] Training loss: 0.00855718
DEBUG:root:[ Iteration 288 ] Training loss: 0.013516
DEBUG:root:[ Iteration 291 ] Training loss: 0.015288
DEBUG:root:[ Iteration 294 ] Training loss: 0.0105752
DEBUG:root:[ Iteration 297 ] Training loss: 0.0129885
DEBUG:root:[ Iteration 300 ] Training loss: 0.013554
DEBUG:root:[ Iteration 300 ] Test loss: 0.0135686
DEBUG:root:[ Iteration 303 ] Training loss: 0.0090275
DEBUG:root:[ Iteration 306 ] Training loss: 0.0202038
DEBUG:root:[ Iteration 309 ] Training loss: 0.0104383
DEBUG:root:[ Iteration 312 ] Training loss: 0.0208198
DEBUG:root:[ Iteration 315 ] Training loss: 0.0127038
DEBUG:root:[ Iteration 318 ] Training loss: 0.0105571
DEBUG:root:[ Iteration 320 ] Test loss: 0.00955541
DEBUG:root:[ Iteration 321 ] Training loss: 0.00871224
DEBUG:root:[ Iteration 324 ] Training loss: 0.00700008
DEBUG:root:[ Iteration 327 ] Training loss: 0.00481762
DEBUG:root:[ Iteration 330 ] Training loss: 0.00876188
DEBUG:root:[ Iteration 333 ] Training loss: 0.0156079
DEBUG:root:[ Iteration 336 ] Training loss: 0.00946309
DEBUG:root:[ Iteration 339 ] Training loss: 0.00971402
DEBUG:root:[ Iteration 340 ] Test loss: 0.00929439
DEBUG:root:[ Iteration 342 ] Training loss: 0.00811219
DEBUG:root:[ Iteration 345 ] Training loss: 0.0117513
DEBUG:root:[ Iteration 348 ] Training loss: 0.00559436
DEBUG:root:[ Iteration 351 ] Training loss: 0.00944735
DEBUG:root:[ Iteration 354 ] Training loss: 0.00506766
DEBUG:root:[ Iteration 357 ] Training loss: 0.00591955
DEBUG:root:[ Iteration 360 ] Training loss: 0.0173723
DEBUG:root:[ Iteration 360 ] Test loss: 0.00857606
DEBUG:root:[ Iteration 363 ] Training loss: 0.0148009
DEBUG:root:[ Iteration 366 ] Training loss: 0.0049979
DEBUG:root:[ Iteration 369 ] Training loss: 0.0116809
DEBUG:root:[ Iteration 372 ] Training loss: 0.00521547
DEBUG:root:[ Iteration 375 ] Training loss: 0.0159464
DEBUG:root:[ Iteration 378 ] Training loss: 0.0136461
DEBUG:root:[ Iteration 380 ] Test loss: 0.0106003
DEBUG:root:[ Iteration 381 ] Training loss: 0.00710027
DEBUG:root:[ Iteration 384 ] Training loss: 0.0099996
DEBUG:root:[ Iteration 387 ] Training loss: 0.00736942
DEBUG:root:[ Iteration 390 ] Training loss: 0.00891009
DEBUG:root:[ Iteration 393 ] Training loss: 0.00881186
DEBUG:root:[ Iteration 396 ] Training loss: 0.0114372
DEBUG:root:[ Iteration 399 ] Training loss: 0.00957413
DEBUG:root:[ Iteration 400 ] Test loss: 0.00975413
DEBUG:root:[ Iteration 402 ] Training loss: 0.00742517
DEBUG:root:[ Iteration 405 ] Training loss: 0.0108593
DEBUG:root:[ Iteration 408 ] Training loss: 0.00641898
DEBUG:root:[ Iteration 411 ] Training loss: 0.00516221
DEBUG:root:[ Iteration 414 ] Training loss: 0.012005
DEBUG:root:[ Iteration 417 ] Training loss: 0.00493316
DEBUG:root:[ Iteration 420 ] Training loss: 0.00722859
DEBUG:root:[ Iteration 420 ] Test loss: 0.00754176
DEBUG:root:[ Iteration 423 ] Training loss: 0.00736654
DEBUG:root:[ Iteration 426 ] Training loss: 0.00711169
DEBUG:root:[ Iteration 429 ] Training loss: 0.00410612
DEBUG:root:[ Iteration 432 ] Training loss: 0.00814848
DEBUG:root:[ Iteration 435 ] Training loss: 0.00623049
DEBUG:root:[ Iteration 438 ] Training loss: 0.0121639
DEBUG:root:[ Iteration 440 ] Test loss: 0.00813579
DEBUG:root:[ Iteration 441 ] Training loss: 0.00423852
DEBUG:root:[ Iteration 444 ] Training loss: 0.0104152
DEBUG:root:[ Iteration 447 ] Training loss: 0.0132024
DEBUG:root:[ Iteration 450 ] Training loss: 0.0074769
DEBUG:root:[ Iteration 453 ] Training loss: 0.0184661
DEBUG:root:[ Iteration 456 ] Training loss: 0.0147637
DEBUG:root:[ Iteration 459 ] Training loss: 0.00882288
DEBUG:root:[ Iteration 460 ] Test loss: 0.00729616
DEBUG:root:[ Iteration 462 ] Training loss: 0.00695077
DEBUG:root:[ Iteration 465 ] Training loss: 0.00695202
DEBUG:root:[ Iteration 468 ] Training loss: 0.00591762
DEBUG:root:[ Iteration 471 ] Training loss: 0.0113513
DEBUG:root:[ Iteration 474 ] Training loss: 0.00823832
DEBUG:root:[ Iteration 477 ] Training loss: 0.0150103
DEBUG:root:[ Iteration 480 ] Training loss: 0.00704745
DEBUG:root:[ Iteration 480 ] Test loss: 0.00927408
DEBUG:root:[ Iteration 483 ] Training loss: 0.00494169
DEBUG:root:[ Iteration 486 ] Training loss: 0.00849595
DEBUG:root:[ Iteration 489 ] Training loss: 0.00569708
DEBUG:root:[ Iteration 492 ] Training loss: 0.00447162
DEBUG:root:[ Iteration 495 ] Training loss: 0.00446653
DEBUG:root:[ Iteration 498 ] Training loss: 0.00762198
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-26-2016_17h58m15s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.218238
DEBUG:root:[ Iteration 0 ] Test loss: 0.205865
DEBUG:root:[ Iteration 3 ] Training loss: 0.183639
DEBUG:root:[ Iteration 6 ] Training loss: 0.158901
DEBUG:root:[ Iteration 9 ] Training loss: 0.123474
DEBUG:root:[ Iteration 12 ] Training loss: 0.136179
DEBUG:root:[ Iteration 15 ] Training loss: 0.173194
DEBUG:root:[ Iteration 18 ] Training loss: 0.201471
DEBUG:root:[ Iteration 20 ] Test loss: 0.184516
DEBUG:root:[ Iteration 21 ] Training loss: 0.184171
DEBUG:root:[ Iteration 24 ] Training loss: 0.201824
DEBUG:root:[ Iteration 27 ] Training loss: 0.228328
DEBUG:root:[ Iteration 30 ] Training loss: 0.176343
DEBUG:root:[ Iteration 33 ] Training loss: 0.211356
DEBUG:root:[ Iteration 36 ] Training loss: 0.224149
DEBUG:root:[ Iteration 39 ] Training loss: 0.239845
DEBUG:root:[ Iteration 40 ] Test loss: 0.17905
DEBUG:root:[ Iteration 42 ] Training loss: 0.190738
DEBUG:root:[ Iteration 45 ] Training loss: 0.173975
DEBUG:root:[ Iteration 48 ] Training loss: 0.143702
DEBUG:root:[ Iteration 51 ] Training loss: 0.113286
DEBUG:root:[ Iteration 54 ] Training loss: 0.138791
DEBUG:root:[ Iteration 57 ] Training loss: 0.11883
DEBUG:root:[ Iteration 60 ] Training loss: 0.103188
DEBUG:root:[ Iteration 60 ] Test loss: 0.11509
DEBUG:root:[ Iteration 63 ] Training loss: 0.116078
DEBUG:root:[ Iteration 66 ] Training loss: 0.105003
DEBUG:root:[ Iteration 69 ] Training loss: 0.104364
DEBUG:root:[ Iteration 72 ] Training loss: 0.115529
DEBUG:root:[ Iteration 75 ] Training loss: 0.102106
DEBUG:root:[ Iteration 78 ] Training loss: 0.108122
DEBUG:root:[ Iteration 80 ] Test loss: 0.104473
DEBUG:root:[ Iteration 81 ] Training loss: 0.108504
DEBUG:root:[ Iteration 84 ] Training loss: 0.110535
DEBUG:root:[ Iteration 87 ] Training loss: 0.104227
DEBUG:root:[ Iteration 90 ] Training loss: 0.104369
DEBUG:root:[ Iteration 93 ] Training loss: 0.100362
DEBUG:root:[ Iteration 96 ] Training loss: 0.0950214
DEBUG:root:[ Iteration 99 ] Training loss: 0.107021
DEBUG:root:[ Iteration 100 ] Test loss: 0.0964365
DEBUG:root:[ Iteration 102 ] Training loss: 0.0866241
DEBUG:root:[ Iteration 105 ] Training loss: 0.0961256
DEBUG:root:[ Iteration 108 ] Training loss: 0.0958751
DEBUG:root:[ Iteration 111 ] Training loss: 0.107073
DEBUG:root:[ Iteration 114 ] Training loss: 0.0919859
DEBUG:root:[ Iteration 117 ] Training loss: 0.0915296
DEBUG:root:[ Iteration 120 ] Training loss: 0.0956583
DEBUG:root:[ Iteration 120 ] Test loss: 0.0905343
DEBUG:root:[ Iteration 123 ] Training loss: 0.0882947
DEBUG:root:[ Iteration 126 ] Training loss: 0.0900151
DEBUG:root:[ Iteration 129 ] Training loss: 0.087271
DEBUG:root:[ Iteration 132 ] Training loss: 0.0855403
DEBUG:root:[ Iteration 135 ] Training loss: 0.101132
DEBUG:root:[ Iteration 138 ] Training loss: 0.0901149
DEBUG:root:[ Iteration 140 ] Test loss: 0.0893784
DEBUG:root:[ Iteration 141 ] Training loss: 0.0854613
DEBUG:root:[ Iteration 144 ] Training loss: 0.0938134
DEBUG:root:[ Iteration 147 ] Training loss: 0.0801969
DEBUG:root:[ Iteration 150 ] Training loss: 0.0925581
DEBUG:root:[ Iteration 153 ] Training loss: 0.0963181
DEBUG:root:[ Iteration 156 ] Training loss: 0.0877853
DEBUG:root:[ Iteration 159 ] Training loss: 0.0736176
DEBUG:root:[ Iteration 160 ] Test loss: 0.0827266
DEBUG:root:[ Iteration 162 ] Training loss: 0.0782004
DEBUG:root:[ Iteration 165 ] Training loss: 0.0805869
DEBUG:root:[ Iteration 168 ] Training loss: 0.0888722
DEBUG:root:[ Iteration 171 ] Training loss: 0.0874658
DEBUG:root:[ Iteration 174 ] Training loss: 0.0746857
DEBUG:root:[ Iteration 177 ] Training loss: 0.0777435
DEBUG:root:[ Iteration 180 ] Training loss: 0.0832885
DEBUG:root:[ Iteration 180 ] Test loss: 0.0820572
DEBUG:root:[ Iteration 183 ] Training loss: 0.0803089
DEBUG:root:[ Iteration 186 ] Training loss: 0.0833018
DEBUG:root:[ Iteration 189 ] Training loss: 0.0750754
DEBUG:root:[ Iteration 192 ] Training loss: 0.0687025
DEBUG:root:[ Iteration 195 ] Training loss: 0.0737234
DEBUG:root:[ Iteration 198 ] Training loss: 0.0716735
DEBUG:root:[ Iteration 200 ] Test loss: 0.0792545
DEBUG:root:[ Iteration 201 ] Training loss: 0.0723326
DEBUG:root:[ Iteration 204 ] Training loss: 0.0700112
DEBUG:root:[ Iteration 207 ] Training loss: 0.076948
DEBUG:root:[ Iteration 210 ] Training loss: 0.0740392
DEBUG:root:[ Iteration 213 ] Training loss: 0.0833089
DEBUG:root:[ Iteration 216 ] Training loss: 0.0765453
DEBUG:root:[ Iteration 219 ] Training loss: 0.0718576
DEBUG:root:[ Iteration 220 ] Test loss: 0.0743113
DEBUG:root:[ Iteration 222 ] Training loss: 0.0717209
DEBUG:root:[ Iteration 225 ] Training loss: 0.0727556
DEBUG:root:[ Iteration 228 ] Training loss: 0.0690018
DEBUG:root:[ Iteration 231 ] Training loss: 0.0725491
DEBUG:root:[ Iteration 234 ] Training loss: 0.0639409
DEBUG:root:[ Iteration 237 ] Training loss: 0.0687039
DEBUG:root:[ Iteration 240 ] Training loss: 0.0657248
DEBUG:root:[ Iteration 240 ] Test loss: 0.0714499
DEBUG:root:[ Iteration 243 ] Training loss: 0.0636643
DEBUG:root:[ Iteration 246 ] Training loss: 0.0722723
DEBUG:root:[ Iteration 249 ] Training loss: 0.0646555
DEBUG:root:[ Iteration 252 ] Training loss: 0.0711956
DEBUG:root:[ Iteration 255 ] Training loss: 0.0841549
DEBUG:root:[ Iteration 258 ] Training loss: 0.0618602
DEBUG:root:[ Iteration 260 ] Test loss: 0.0687979
DEBUG:root:[ Iteration 261 ] Training loss: 0.0579011
DEBUG:root:[ Iteration 264 ] Training loss: 0.0711861
DEBUG:root:[ Iteration 267 ] Training loss: 0.0724868
DEBUG:root:[ Iteration 270 ] Training loss: 0.0644908
DEBUG:root:[ Iteration 273 ] Training loss: 0.061488
DEBUG:root:[ Iteration 276 ] Training loss: 0.0620807
DEBUG:root:[ Iteration 279 ] Training loss: 0.0655611
DEBUG:root:[ Iteration 280 ] Test loss: 0.0853149
DEBUG:root:[ Iteration 282 ] Training loss: 0.0666506
DEBUG:root:[ Iteration 285 ] Training loss: 0.0681181
DEBUG:root:[ Iteration 288 ] Training loss: 0.0744049
DEBUG:root:[ Iteration 291 ] Training loss: 0.0671348
DEBUG:root:[ Iteration 294 ] Training loss: 0.0749754
DEBUG:root:[ Iteration 297 ] Training loss: 0.0730683
DEBUG:root:[ Iteration 300 ] Training loss: 0.0677045
DEBUG:root:[ Iteration 300 ] Test loss: 0.0698802
DEBUG:root:[ Iteration 303 ] Training loss: 0.0825507
DEBUG:root:[ Iteration 306 ] Training loss: 0.0599546
DEBUG:root:[ Iteration 309 ] Training loss: 0.0735831
DEBUG:root:[ Iteration 312 ] Training loss: 0.0748293
DEBUG:root:[ Iteration 315 ] Training loss: 0.0581509
DEBUG:root:[ Iteration 318 ] Training loss: 0.0524198
DEBUG:root:[ Iteration 320 ] Test loss: 0.0676614
DEBUG:root:[ Iteration 321 ] Training loss: 0.0464562
DEBUG:root:[ Iteration 324 ] Training loss: 0.068048
DEBUG:root:[ Iteration 327 ] Training loss: 0.0589941
DEBUG:root:[ Iteration 330 ] Training loss: 0.0606474
DEBUG:root:[ Iteration 333 ] Training loss: 0.057974
DEBUG:root:[ Iteration 336 ] Training loss: 0.0672888
DEBUG:root:[ Iteration 339 ] Training loss: 0.052068
DEBUG:root:[ Iteration 340 ] Test loss: 0.0673823
DEBUG:root:[ Iteration 342 ] Training loss: 0.0840344
DEBUG:root:[ Iteration 345 ] Training loss: 0.0979009
DEBUG:root:[ Iteration 348 ] Training loss: 0.0623229
DEBUG:root:[ Iteration 351 ] Training loss: 0.0855876
DEBUG:root:[ Iteration 354 ] Training loss: 0.0591988
DEBUG:root:[ Iteration 357 ] Training loss: 0.0729733
DEBUG:root:[ Iteration 360 ] Training loss: 0.0599284
DEBUG:root:[ Iteration 360 ] Test loss: 0.0649783
DEBUG:root:[ Iteration 363 ] Training loss: 0.0657911
DEBUG:root:[ Iteration 366 ] Training loss: 0.0535169
DEBUG:root:[ Iteration 369 ] Training loss: 0.0532502
DEBUG:root:[ Iteration 372 ] Training loss: 0.0660791
DEBUG:root:[ Iteration 375 ] Training loss: 0.0601448
DEBUG:root:[ Iteration 378 ] Training loss: 0.049976
DEBUG:root:[ Iteration 380 ] Test loss: 0.0623764
DEBUG:root:[ Iteration 381 ] Training loss: 0.0624852
DEBUG:root:[ Iteration 384 ] Training loss: 0.0589686
DEBUG:root:[ Iteration 387 ] Training loss: 0.0600493
DEBUG:root:[ Iteration 390 ] Training loss: 0.058676
DEBUG:root:[ Iteration 393 ] Training loss: 0.0601332
DEBUG:root:[ Iteration 396 ] Training loss: 0.0570414
DEBUG:root:[ Iteration 399 ] Training loss: 0.0660034
DEBUG:root:[ Iteration 400 ] Test loss: 0.0643381
DEBUG:root:[ Iteration 402 ] Training loss: 0.0457082
DEBUG:root:[ Iteration 405 ] Training loss: 0.0546875
DEBUG:root:[ Iteration 408 ] Training loss: 0.0534086
DEBUG:root:[ Iteration 411 ] Training loss: 0.0582568
DEBUG:root:[ Iteration 414 ] Training loss: 0.0489736
DEBUG:root:[ Iteration 417 ] Training loss: 0.0698385
DEBUG:root:[ Iteration 420 ] Training loss: 0.057398
DEBUG:root:[ Iteration 420 ] Test loss: 0.0625294
DEBUG:root:[ Iteration 423 ] Training loss: 0.0549724
DEBUG:root:[ Iteration 426 ] Training loss: 0.0535591
DEBUG:root:[ Iteration 429 ] Training loss: 0.0587769
DEBUG:root:[ Iteration 432 ] Training loss: 0.0544746
DEBUG:root:[ Iteration 435 ] Training loss: 0.0736531
DEBUG:root:[ Iteration 438 ] Training loss: 0.0455389
DEBUG:root:[ Iteration 440 ] Test loss: 0.0611639
DEBUG:root:[ Iteration 441 ] Training loss: 0.0522633
DEBUG:root:[ Iteration 444 ] Training loss: 0.049796
DEBUG:root:[ Iteration 447 ] Training loss: 0.0590012
DEBUG:root:[ Iteration 450 ] Training loss: 0.050787
DEBUG:root:[ Iteration 453 ] Training loss: 0.0590822
DEBUG:root:[ Iteration 456 ] Training loss: 0.0702862
DEBUG:root:[ Iteration 459 ] Training loss: 0.060695
DEBUG:root:[ Iteration 460 ] Test loss: 0.062451
DEBUG:root:[ Iteration 462 ] Training loss: 0.0632199
DEBUG:root:[ Iteration 465 ] Training loss: 0.0668376
DEBUG:root:[ Iteration 468 ] Training loss: 0.0468946
DEBUG:root:[ Iteration 471 ] Training loss: 0.0387231
DEBUG:root:[ Iteration 474 ] Training loss: 0.0637932
DEBUG:root:[ Iteration 477 ] Training loss: 0.0659008
DEBUG:root:[ Iteration 480 ] Training loss: 0.0598747
DEBUG:root:[ Iteration 480 ] Test loss: 0.0640702
DEBUG:root:[ Iteration 483 ] Training loss: 0.0592922
DEBUG:root:[ Iteration 486 ] Training loss: 0.0502446
DEBUG:root:[ Iteration 489 ] Training loss: 0.0544373
DEBUG:root:[ Iteration 492 ] Training loss: 0.0381614
DEBUG:root:[ Iteration 495 ] Training loss: 0.0661398
DEBUG:root:[ Iteration 498 ] Training loss: 0.056549
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-26-2016_18h08m10s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.057945
DEBUG:root:[ Iteration 0 ] Test loss: 0.0530236
DEBUG:root:[ Iteration 3 ] Training loss: 0.0493688
DEBUG:root:[ Iteration 6 ] Training loss: 0.0570179
DEBUG:root:[ Iteration 9 ] Training loss: 0.0471654
DEBUG:root:[ Iteration 12 ] Training loss: 0.045514
DEBUG:root:[ Iteration 15 ] Training loss: 0.0569786
DEBUG:root:[ Iteration 18 ] Training loss: 0.0433518
DEBUG:root:[ Iteration 20 ] Test loss: 0.0474707
DEBUG:root:[ Iteration 21 ] Training loss: 0.0497173
DEBUG:root:[ Iteration 24 ] Training loss: 0.0475623
DEBUG:root:[ Iteration 27 ] Training loss: 0.0476456
DEBUG:root:[ Iteration 30 ] Training loss: 0.0504171
DEBUG:root:[ Iteration 33 ] Training loss: 0.0387201
DEBUG:root:[ Iteration 36 ] Training loss: 0.0433622
DEBUG:root:[ Iteration 39 ] Training loss: 0.049119
DEBUG:root:[ Iteration 40 ] Test loss: 0.0448097
DEBUG:root:[ Iteration 42 ] Training loss: 0.0517803
DEBUG:root:[ Iteration 45 ] Training loss: 0.0494417
DEBUG:root:[ Iteration 48 ] Training loss: 0.0467292
DEBUG:root:[ Iteration 51 ] Training loss: 0.0501919
DEBUG:root:[ Iteration 54 ] Training loss: 0.047197
DEBUG:root:[ Iteration 57 ] Training loss: 0.0419563
DEBUG:root:[ Iteration 60 ] Training loss: 0.0432846
DEBUG:root:[ Iteration 60 ] Test loss: 0.0539209
DEBUG:root:[ Iteration 63 ] Training loss: 0.0485972
DEBUG:root:[ Iteration 66 ] Training loss: 0.0327416
DEBUG:root:[ Iteration 69 ] Training loss: 0.037404
DEBUG:root:[ Iteration 72 ] Training loss: 0.0453598
DEBUG:root:[ Iteration 75 ] Training loss: 0.0489787
DEBUG:root:[ Iteration 78 ] Training loss: 0.0504331
DEBUG:root:[ Iteration 80 ] Test loss: 0.0489395
DEBUG:root:[ Iteration 81 ] Training loss: 0.0423769
DEBUG:root:[ Iteration 84 ] Training loss: 0.0432569
DEBUG:root:[ Iteration 87 ] Training loss: 0.0490616
DEBUG:root:[ Iteration 90 ] Training loss: 0.0392112
DEBUG:root:[ Iteration 93 ] Training loss: 0.0372966
DEBUG:root:[ Iteration 96 ] Training loss: 0.0495445
DEBUG:root:[ Iteration 99 ] Training loss: 0.0542622
DEBUG:root:[ Iteration 100 ] Test loss: 0.0502335
DEBUG:root:[ Iteration 102 ] Training loss: 0.0481703
DEBUG:root:[ Iteration 105 ] Training loss: 0.0468384
DEBUG:root:[ Iteration 108 ] Training loss: 0.0418066
DEBUG:root:[ Iteration 111 ] Training loss: 0.0425955
DEBUG:root:[ Iteration 114 ] Training loss: 0.0433603
DEBUG:root:[ Iteration 117 ] Training loss: 0.0403315
DEBUG:root:[ Iteration 120 ] Training loss: 0.0443831
DEBUG:root:[ Iteration 120 ] Test loss: 0.046726
DEBUG:root:[ Iteration 123 ] Training loss: 0.0383685
DEBUG:root:[ Iteration 126 ] Training loss: 0.0461227
DEBUG:root:[ Iteration 129 ] Training loss: 0.0374709
DEBUG:root:[ Iteration 132 ] Training loss: 0.0411963
DEBUG:root:[ Iteration 135 ] Training loss: 0.04208
DEBUG:root:[ Iteration 138 ] Training loss: 0.0366633
DEBUG:root:[ Iteration 140 ] Test loss: 0.0442566
DEBUG:root:[ Iteration 141 ] Training loss: 0.0407295
DEBUG:root:[ Iteration 144 ] Training loss: 0.0478729
DEBUG:root:[ Iteration 147 ] Training loss: 0.0470406
DEBUG:root:[ Iteration 150 ] Training loss: 0.0441368
DEBUG:root:[ Iteration 153 ] Training loss: 0.0500464
DEBUG:root:[ Iteration 156 ] Training loss: 0.0468395
DEBUG:root:[ Iteration 159 ] Training loss: 0.0520083
DEBUG:root:[ Iteration 160 ] Test loss: 0.0492958
DEBUG:root:[ Iteration 162 ] Training loss: 0.0387972
DEBUG:root:[ Iteration 165 ] Training loss: 0.0422901
DEBUG:root:[ Iteration 168 ] Training loss: 0.0420113
DEBUG:root:[ Iteration 171 ] Training loss: 0.0413712
DEBUG:root:[ Iteration 174 ] Training loss: 0.0391526
DEBUG:root:[ Iteration 177 ] Training loss: 0.0363675
DEBUG:root:[ Iteration 180 ] Training loss: 0.0386038
DEBUG:root:[ Iteration 180 ] Test loss: 0.0475868
DEBUG:root:[ Iteration 183 ] Training loss: 0.0418258
DEBUG:root:[ Iteration 186 ] Training loss: 0.045012
DEBUG:root:[ Iteration 189 ] Training loss: 0.0396224
DEBUG:root:[ Iteration 192 ] Training loss: 0.037108
DEBUG:root:[ Iteration 195 ] Training loss: 0.0400002
DEBUG:root:[ Iteration 198 ] Training loss: 0.0354925
DEBUG:root:[ Iteration 200 ] Test loss: 0.0411585
DEBUG:root:[ Iteration 201 ] Training loss: 0.0451268
DEBUG:root:[ Iteration 204 ] Training loss: 0.0424582
DEBUG:root:[ Iteration 207 ] Training loss: 0.0441182
DEBUG:root:[ Iteration 210 ] Training loss: 0.0336311
DEBUG:root:[ Iteration 213 ] Training loss: 0.0361724
DEBUG:root:[ Iteration 216 ] Training loss: 0.0383481
DEBUG:root:[ Iteration 219 ] Training loss: 0.0411235
DEBUG:root:[ Iteration 220 ] Test loss: 0.0474915
DEBUG:root:[ Iteration 222 ] Training loss: 0.0344008
DEBUG:root:[ Iteration 225 ] Training loss: 0.0406147
DEBUG:root:[ Iteration 228 ] Training loss: 0.0400334
DEBUG:root:[ Iteration 231 ] Training loss: 0.0384074
DEBUG:root:[ Iteration 234 ] Training loss: 0.0414844
DEBUG:root:[ Iteration 237 ] Training loss: 0.0447592
DEBUG:root:[ Iteration 240 ] Training loss: 0.0375835
DEBUG:root:[ Iteration 240 ] Test loss: 0.0430445
DEBUG:root:[ Iteration 243 ] Training loss: 0.0398271
DEBUG:root:[ Iteration 246 ] Training loss: 0.036817
DEBUG:root:[ Iteration 249 ] Training loss: 0.0461012
DEBUG:root:[ Iteration 252 ] Training loss: 0.0336033
DEBUG:root:[ Iteration 255 ] Training loss: 0.0376835
DEBUG:root:[ Iteration 258 ] Training loss: 0.0349455
DEBUG:root:[ Iteration 260 ] Test loss: 0.0481755
DEBUG:root:[ Iteration 261 ] Training loss: 0.047733
DEBUG:root:[ Iteration 264 ] Training loss: 0.0457835
DEBUG:root:[ Iteration 267 ] Training loss: 0.0353313
DEBUG:root:[ Iteration 270 ] Training loss: 0.0465572
DEBUG:root:[ Iteration 273 ] Training loss: 0.0312078
DEBUG:root:[ Iteration 276 ] Training loss: 0.0404882
DEBUG:root:[ Iteration 279 ] Training loss: 0.0407236
DEBUG:root:[ Iteration 280 ] Test loss: 0.0505029
DEBUG:root:[ Iteration 282 ] Training loss: 0.0393242
DEBUG:root:[ Iteration 285 ] Training loss: 0.0358576
DEBUG:root:[ Iteration 288 ] Training loss: 0.0311618
DEBUG:root:[ Iteration 291 ] Training loss: 0.0397941
DEBUG:root:[ Iteration 294 ] Training loss: 0.0362948
DEBUG:root:[ Iteration 297 ] Training loss: 0.0328924
DEBUG:root:[ Iteration 300 ] Training loss: 0.0363339
DEBUG:root:[ Iteration 300 ] Test loss: 0.0401859
DEBUG:root:[ Iteration 303 ] Training loss: 0.0426071
DEBUG:root:[ Iteration 306 ] Training loss: 0.031353
DEBUG:root:[ Iteration 309 ] Training loss: 0.0321374
DEBUG:root:[ Iteration 312 ] Training loss: 0.0391816
DEBUG:root:[ Iteration 315 ] Training loss: 0.0349318
DEBUG:root:[ Iteration 318 ] Training loss: 0.0372892
DEBUG:root:[ Iteration 320 ] Test loss: 0.0370523
DEBUG:root:[ Iteration 321 ] Training loss: 0.0312773
DEBUG:root:[ Iteration 324 ] Training loss: 0.0425017
DEBUG:root:[ Iteration 327 ] Training loss: 0.037939
DEBUG:root:[ Iteration 330 ] Training loss: 0.0606413
DEBUG:root:[ Iteration 333 ] Training loss: 0.0438841
DEBUG:root:[ Iteration 336 ] Training loss: 0.0478014
DEBUG:root:[ Iteration 339 ] Training loss: 0.0297686
DEBUG:root:[ Iteration 340 ] Test loss: 0.0471135
DEBUG:root:[ Iteration 342 ] Training loss: 0.0310629
DEBUG:root:[ Iteration 345 ] Training loss: 0.0369243
DEBUG:root:[ Iteration 348 ] Training loss: 0.0383231
DEBUG:root:[ Iteration 351 ] Training loss: 0.0352723
DEBUG:root:[ Iteration 354 ] Training loss: 0.0347919
DEBUG:root:[ Iteration 357 ] Training loss: 0.0415259
DEBUG:root:[ Iteration 360 ] Training loss: 0.039954
DEBUG:root:[ Iteration 360 ] Test loss: 0.0369149
DEBUG:root:[ Iteration 363 ] Training loss: 0.0321111
DEBUG:root:[ Iteration 366 ] Training loss: 0.0386909
DEBUG:root:[ Iteration 369 ] Training loss: 0.0289592
DEBUG:root:[ Iteration 372 ] Training loss: 0.0407368
DEBUG:root:[ Iteration 375 ] Training loss: 0.0365543
DEBUG:root:[ Iteration 378 ] Training loss: 0.0352345
DEBUG:root:[ Iteration 380 ] Test loss: 0.0465813
DEBUG:root:[ Iteration 381 ] Training loss: 0.0387478
DEBUG:root:[ Iteration 384 ] Training loss: 0.0294373
DEBUG:root:[ Iteration 387 ] Training loss: 0.0393661
DEBUG:root:[ Iteration 390 ] Training loss: 0.0326934
DEBUG:root:[ Iteration 393 ] Training loss: 0.0303512
DEBUG:root:[ Iteration 396 ] Training loss: 0.0411066
DEBUG:root:[ Iteration 399 ] Training loss: 0.035578
DEBUG:root:[ Iteration 400 ] Test loss: 0.0415361
DEBUG:root:[ Iteration 402 ] Training loss: 0.0456975
DEBUG:root:[ Iteration 405 ] Training loss: 0.0352717
DEBUG:root:[ Iteration 408 ] Training loss: 0.0380667
DEBUG:root:[ Iteration 411 ] Training loss: 0.0383743
DEBUG:root:[ Iteration 414 ] Training loss: 0.0349551
DEBUG:root:[ Iteration 417 ] Training loss: 0.032639
DEBUG:root:[ Iteration 420 ] Training loss: 0.0341729
DEBUG:root:[ Iteration 420 ] Test loss: 0.0352103
DEBUG:root:[ Iteration 423 ] Training loss: 0.03789
DEBUG:root:[ Iteration 426 ] Training loss: 0.0336779
DEBUG:root:[ Iteration 429 ] Training loss: 0.0313864
DEBUG:root:[ Iteration 432 ] Training loss: 0.0349535
DEBUG:root:[ Iteration 435 ] Training loss: 0.0336169
DEBUG:root:[ Iteration 438 ] Training loss: 0.0397282
DEBUG:root:[ Iteration 440 ] Test loss: 0.0469333
DEBUG:root:[ Iteration 441 ] Training loss: 0.0408858
DEBUG:root:[ Iteration 444 ] Training loss: 0.0346715
DEBUG:root:[ Iteration 447 ] Training loss: 0.0439071
DEBUG:root:[ Iteration 450 ] Training loss: 0.0418195
DEBUG:root:[ Iteration 453 ] Training loss: 0.0344892
DEBUG:root:[ Iteration 456 ] Training loss: 0.0379842
DEBUG:root:[ Iteration 459 ] Training loss: 0.0378653
DEBUG:root:[ Iteration 460 ] Test loss: 0.0463122
DEBUG:root:[ Iteration 462 ] Training loss: 0.0372246
DEBUG:root:[ Iteration 465 ] Training loss: 0.0449456
DEBUG:root:[ Iteration 468 ] Training loss: 0.030316
DEBUG:root:[ Iteration 471 ] Training loss: 0.0392914
DEBUG:root:[ Iteration 474 ] Training loss: 0.0407312
DEBUG:root:[ Iteration 477 ] Training loss: 0.0389135
DEBUG:root:[ Iteration 480 ] Training loss: 0.0335715
DEBUG:root:[ Iteration 480 ] Test loss: 0.0405088
DEBUG:root:[ Iteration 483 ] Training loss: 0.0308984
DEBUG:root:[ Iteration 486 ] Training loss: 0.036324
DEBUG:root:[ Iteration 489 ] Training loss: 0.0392231
DEBUG:root:[ Iteration 492 ] Training loss: 0.040814
DEBUG:root:[ Iteration 495 ] Training loss: 0.0405401
DEBUG:root:[ Iteration 498 ] Training loss: 0.0299206
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_12h06m19s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.145324
DEBUG:root:[ Iteration 0 ] Test loss: 0.145383
DEBUG:root:[ Iteration 3 ] Training loss: 0.132269
DEBUG:root:[ Iteration 6 ] Training loss: 0.10138
DEBUG:root:[ Iteration 9 ] Training loss: 0.0725761
DEBUG:root:[ Iteration 12 ] Training loss: 0.0709006
DEBUG:root:[ Iteration 15 ] Training loss: 0.0645622
DEBUG:root:[ Iteration 18 ] Training loss: 0.0538337
DEBUG:root:[ Iteration 20 ] Test loss: 0.0629369
DEBUG:root:[ Iteration 21 ] Training loss: 0.0567282
DEBUG:root:[ Iteration 24 ] Training loss: 0.055568
DEBUG:root:[ Iteration 27 ] Training loss: 0.0479183
DEBUG:root:[ Iteration 30 ] Training loss: 0.0430864
DEBUG:root:[ Iteration 33 ] Training loss: 0.0336128
DEBUG:root:[ Iteration 36 ] Training loss: 0.0366784
DEBUG:root:[ Iteration 39 ] Training loss: 0.031238
DEBUG:root:[ Iteration 40 ] Test loss: 0.0398727
DEBUG:root:[ Iteration 42 ] Training loss: 0.0279767
DEBUG:root:[ Iteration 45 ] Training loss: 0.0293905
DEBUG:root:[ Iteration 48 ] Training loss: 0.0261465
DEBUG:root:[ Iteration 51 ] Training loss: 0.0230032
DEBUG:root:[ Iteration 54 ] Training loss: 0.018029
DEBUG:root:[ Iteration 57 ] Training loss: 0.0188368
DEBUG:root:[ Iteration 60 ] Training loss: 0.0202019
DEBUG:root:[ Iteration 60 ] Test loss: 0.0256379
DEBUG:root:[ Iteration 63 ] Training loss: 0.018551
DEBUG:root:[ Iteration 66 ] Training loss: 0.0168542
DEBUG:root:[ Iteration 69 ] Training loss: 0.0158669
DEBUG:root:[ Iteration 72 ] Training loss: 0.0136412
DEBUG:root:[ Iteration 75 ] Training loss: 0.0197317
DEBUG:root:[ Iteration 78 ] Training loss: 0.0163406
DEBUG:root:[ Iteration 80 ] Test loss: 0.0206386
DEBUG:root:[ Iteration 81 ] Training loss: 0.0141477
DEBUG:root:[ Iteration 84 ] Training loss: 0.00937366
DEBUG:root:[ Iteration 87 ] Training loss: 0.0121447
DEBUG:root:[ Iteration 90 ] Training loss: 0.0139704
DEBUG:root:[ Iteration 93 ] Training loss: 0.0122603
DEBUG:root:[ Iteration 96 ] Training loss: 0.0100407
DEBUG:root:[ Iteration 99 ] Training loss: 0.0141851
DEBUG:root:[ Iteration 100 ] Test loss: 0.0183667
DEBUG:root:[ Iteration 102 ] Training loss: 0.010977
DEBUG:root:[ Iteration 105 ] Training loss: 0.0105845
DEBUG:root:[ Iteration 108 ] Training loss: 0.0113523
DEBUG:root:[ Iteration 111 ] Training loss: 0.0112092
DEBUG:root:[ Iteration 114 ] Training loss: 0.00941269
DEBUG:root:[ Iteration 117 ] Training loss: 0.011463
DEBUG:root:[ Iteration 120 ] Training loss: 0.0118492
DEBUG:root:[ Iteration 120 ] Test loss: 0.0157923
DEBUG:root:[ Iteration 123 ] Training loss: 0.00918902
DEBUG:root:[ Iteration 126 ] Training loss: 0.00958742
DEBUG:root:[ Iteration 129 ] Training loss: 0.00909889
DEBUG:root:[ Iteration 132 ] Training loss: 0.0102585
DEBUG:root:[ Iteration 135 ] Training loss: 0.00856025
DEBUG:root:[ Iteration 138 ] Training loss: 0.00897996
DEBUG:root:[ Iteration 140 ] Test loss: 0.0143192
DEBUG:root:[ Iteration 141 ] Training loss: 0.00643489
DEBUG:root:[ Iteration 144 ] Training loss: 0.00944126
DEBUG:root:[ Iteration 147 ] Training loss: 0.00923579
DEBUG:root:[ Iteration 150 ] Training loss: 0.00943849
DEBUG:root:[ Iteration 153 ] Training loss: 0.00940516
DEBUG:root:[ Iteration 156 ] Training loss: 0.00773225
DEBUG:root:[ Iteration 159 ] Training loss: 0.00744138
DEBUG:root:[ Iteration 160 ] Test loss: 0.0124411
DEBUG:root:[ Iteration 162 ] Training loss: 0.00797019
DEBUG:root:[ Iteration 165 ] Training loss: 0.00903052
DEBUG:root:[ Iteration 168 ] Training loss: 0.00959457
DEBUG:root:[ Iteration 171 ] Training loss: 0.00851513
DEBUG:root:[ Iteration 174 ] Training loss: 0.00679462
DEBUG:root:[ Iteration 177 ] Training loss: 0.0060104
DEBUG:root:[ Iteration 180 ] Training loss: 0.0120845
DEBUG:root:[ Iteration 180 ] Test loss: 0.0147937
DEBUG:root:[ Iteration 183 ] Training loss: 0.0075645
DEBUG:root:[ Iteration 186 ] Training loss: 0.00869816
DEBUG:root:[ Iteration 189 ] Training loss: 0.00638967
DEBUG:root:[ Iteration 192 ] Training loss: 0.00720338
DEBUG:root:[ Iteration 195 ] Training loss: 0.00710892
DEBUG:root:[ Iteration 198 ] Training loss: 0.00563762
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_14h27m35s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.135872
DEBUG:root:[ Iteration 0 ] Test loss: 0.109921
DEBUG:root:[ Iteration 3 ] Training loss: 0.118803
DEBUG:root:[ Iteration 6 ] Training loss: 0.0974384
DEBUG:root:[ Iteration 9 ] Training loss: 0.0793706
DEBUG:root:[ Iteration 12 ] Training loss: 0.0829507
DEBUG:root:[ Iteration 15 ] Training loss: 0.0640314
DEBUG:root:[ Iteration 18 ] Training loss: 0.0572622
DEBUG:root:[ Iteration 20 ] Test loss: 0.0528262
DEBUG:root:[ Iteration 21 ] Training loss: 0.0573761
DEBUG:root:[ Iteration 24 ] Training loss: 0.0559985
DEBUG:root:[ Iteration 27 ] Training loss: 0.0575652
DEBUG:root:[ Iteration 30 ] Training loss: 0.0511035
DEBUG:root:[ Iteration 33 ] Training loss: 0.0444592
DEBUG:root:[ Iteration 36 ] Training loss: 0.0406761
DEBUG:root:[ Iteration 39 ] Training loss: 0.0316635
DEBUG:root:[ Iteration 40 ] Test loss: 0.027045
DEBUG:root:[ Iteration 42 ] Training loss: 0.0305441
DEBUG:root:[ Iteration 45 ] Training loss: 0.030626
DEBUG:root:[ Iteration 48 ] Training loss: 0.0255553
DEBUG:root:[ Iteration 51 ] Training loss: 0.0283536
DEBUG:root:[ Iteration 54 ] Training loss: 0.0251647
DEBUG:root:[ Iteration 57 ] Training loss: 0.0245401
DEBUG:root:[ Iteration 60 ] Training loss: 0.0184639
DEBUG:root:[ Iteration 60 ] Test loss: 0.0220407
DEBUG:root:[ Iteration 63 ] Training loss: 0.0230307
DEBUG:root:[ Iteration 66 ] Training loss: 0.0196787
DEBUG:root:[ Iteration 69 ] Training loss: 0.0231225
DEBUG:root:[ Iteration 72 ] Training loss: 0.0188831
DEBUG:root:[ Iteration 75 ] Training loss: 0.0162794
DEBUG:root:[ Iteration 78 ] Training loss: 0.0165557
DEBUG:root:[ Iteration 80 ] Test loss: 0.0119594
DEBUG:root:[ Iteration 81 ] Training loss: 0.0162574
DEBUG:root:[ Iteration 84 ] Training loss: 0.0215824
DEBUG:root:[ Iteration 87 ] Training loss: 0.0161561
DEBUG:root:[ Iteration 90 ] Training loss: 0.0223877
DEBUG:root:[ Iteration 93 ] Training loss: 0.0203899
DEBUG:root:[ Iteration 96 ] Training loss: 0.0171477
DEBUG:root:[ Iteration 99 ] Training loss: 0.0143175
DEBUG:root:[ Iteration 100 ] Test loss: 0.0178198
DEBUG:root:[ Iteration 102 ] Training loss: 0.0159825
DEBUG:root:[ Iteration 105 ] Training loss: 0.0184587
DEBUG:root:[ Iteration 108 ] Training loss: 0.0139586
DEBUG:root:[ Iteration 111 ] Training loss: 0.0118942
DEBUG:root:[ Iteration 114 ] Training loss: 0.00998137
DEBUG:root:[ Iteration 117 ] Training loss: 0.0130577
DEBUG:root:[ Iteration 120 ] Training loss: 0.0119137
DEBUG:root:[ Iteration 120 ] Test loss: 0.0102643
DEBUG:root:[ Iteration 123 ] Training loss: 0.012207
DEBUG:root:[ Iteration 126 ] Training loss: 0.00920021
DEBUG:root:[ Iteration 129 ] Training loss: 0.0116399
DEBUG:root:[ Iteration 132 ] Training loss: 0.00958822
DEBUG:root:[ Iteration 135 ] Training loss: 0.0112466
DEBUG:root:[ Iteration 138 ] Training loss: 0.00858734
DEBUG:root:[ Iteration 140 ] Test loss: 0.0103198
DEBUG:root:[ Iteration 141 ] Training loss: 0.00944949
DEBUG:root:[ Iteration 144 ] Training loss: 0.00992119
DEBUG:root:[ Iteration 147 ] Training loss: 0.00763682
DEBUG:root:[ Iteration 150 ] Training loss: 0.01
DEBUG:root:[ Iteration 153 ] Training loss: 0.00597819
DEBUG:root:[ Iteration 156 ] Training loss: 0.0096032
DEBUG:root:[ Iteration 159 ] Training loss: 0.0093804
DEBUG:root:[ Iteration 160 ] Test loss: 0.00873472
DEBUG:root:[ Iteration 162 ] Training loss: 0.0101987
DEBUG:root:[ Iteration 165 ] Training loss: 0.0099221
DEBUG:root:[ Iteration 168 ] Training loss: 0.00909236
DEBUG:root:[ Iteration 171 ] Training loss: 0.00841397
DEBUG:root:[ Iteration 174 ] Training loss: 0.0103276
DEBUG:root:[ Iteration 177 ] Training loss: 0.00551137
DEBUG:root:[ Iteration 180 ] Training loss: 0.0120747
DEBUG:root:[ Iteration 180 ] Test loss: 0.00970817
DEBUG:root:[ Iteration 183 ] Training loss: 0.00812059
DEBUG:root:[ Iteration 186 ] Training loss: 0.00611838
DEBUG:root:[ Iteration 189 ] Training loss: 0.005868
DEBUG:root:[ Iteration 192 ] Training loss: 0.00599127
DEBUG:root:[ Iteration 195 ] Training loss: 0.00570342
DEBUG:root:[ Iteration 198 ] Training loss: 0.00621704
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_15h30m01s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.137565
DEBUG:root:[ Iteration 0 ] Test loss: 0.119392
DEBUG:root:[ Iteration 3 ] Training loss: 0.111971
DEBUG:root:[ Iteration 6 ] Training loss: 0.0989706
DEBUG:root:[ Iteration 9 ] Training loss: 0.0846478
DEBUG:root:[ Iteration 12 ] Training loss: 0.0700202
DEBUG:root:[ Iteration 15 ] Training loss: 0.0651526
DEBUG:root:[ Iteration 18 ] Training loss: 0.0607773
DEBUG:root:[ Iteration 20 ] Test loss: 0.0557568
DEBUG:root:[ Iteration 21 ] Training loss: 0.0505611
DEBUG:root:[ Iteration 24 ] Training loss: 0.0488368
DEBUG:root:[ Iteration 27 ] Training loss: 0.0513182
DEBUG:root:[ Iteration 30 ] Training loss: 0.0452079
DEBUG:root:[ Iteration 33 ] Training loss: 0.0417616
DEBUG:root:[ Iteration 36 ] Training loss: 0.0393467
DEBUG:root:[ Iteration 39 ] Training loss: 0.0346682
DEBUG:root:[ Iteration 40 ] Test loss: 0.0323566
DEBUG:root:[ Iteration 42 ] Training loss: 0.0368153
DEBUG:root:[ Iteration 45 ] Training loss: 0.0363255
DEBUG:root:[ Iteration 48 ] Training loss: 0.026735
DEBUG:root:[ Iteration 51 ] Training loss: 0.0297045
DEBUG:root:[ Iteration 54 ] Training loss: 0.0239968
DEBUG:root:[ Iteration 57 ] Training loss: 0.0274016
DEBUG:root:[ Iteration 60 ] Training loss: 0.0215688
DEBUG:root:[ Iteration 60 ] Test loss: 0.022742
DEBUG:root:[ Iteration 63 ] Training loss: 0.023427
DEBUG:root:[ Iteration 66 ] Training loss: 0.0184614
DEBUG:root:[ Iteration 69 ] Training loss: 0.0180418
DEBUG:root:[ Iteration 72 ] Training loss: 0.0188646
DEBUG:root:[ Iteration 75 ] Training loss: 0.0187388
DEBUG:root:[ Iteration 78 ] Training loss: 0.018081
DEBUG:root:[ Iteration 80 ] Test loss: 0.0118137
DEBUG:root:[ Iteration 81 ] Training loss: 0.0144679
DEBUG:root:[ Iteration 84 ] Training loss: 0.0157398
DEBUG:root:[ Iteration 87 ] Training loss: 0.0179147
DEBUG:root:[ Iteration 90 ] Training loss: 0.0124807
DEBUG:root:[ Iteration 93 ] Training loss: 0.01456
DEBUG:root:[ Iteration 96 ] Training loss: 0.0131196
DEBUG:root:[ Iteration 99 ] Training loss: 0.0154821
DEBUG:root:[ Iteration 100 ] Test loss: 0.013052
DEBUG:root:[ Iteration 102 ] Training loss: 0.0145299
DEBUG:root:[ Iteration 105 ] Training loss: 0.0145438
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_16h09m20s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0710406
DEBUG:root:[ Iteration 0 ] Test loss: 0.0819122
DEBUG:root:[ Iteration 3 ] Training loss: 0.0757393
DEBUG:root:[ Iteration 6 ] Training loss: 0.0824374
DEBUG:root:[ Iteration 9 ] Training loss: 0.0510314
DEBUG:root:[ Iteration 12 ] Training loss: 0.066369
DEBUG:root:[ Iteration 15 ] Training loss: 0.061211
DEBUG:root:[ Iteration 18 ] Training loss: 0.0501622
DEBUG:root:[ Iteration 20 ] Test loss: 0.047644
DEBUG:root:[ Iteration 21 ] Training loss: 0.0577791
DEBUG:root:[ Iteration 24 ] Training loss: 0.0535259
DEBUG:root:[ Iteration 27 ] Training loss: 0.0450313
DEBUG:root:[ Iteration 30 ] Training loss: 0.0453095
DEBUG:root:[ Iteration 33 ] Training loss: 0.047802
DEBUG:root:[ Iteration 36 ] Training loss: 0.0400634
DEBUG:root:[ Iteration 39 ] Training loss: 0.0379586
DEBUG:root:[ Iteration 40 ] Test loss: 0.0361267
DEBUG:root:[ Iteration 42 ] Training loss: 0.0422204
DEBUG:root:[ Iteration 45 ] Training loss: 0.0401924
DEBUG:root:[ Iteration 48 ] Training loss: 0.0487459
DEBUG:root:[ Iteration 51 ] Training loss: 0.0386591
DEBUG:root:[ Iteration 54 ] Training loss: 0.0395959
DEBUG:root:[ Iteration 57 ] Training loss: 0.0322319
DEBUG:root:[ Iteration 60 ] Training loss: 0.0419852
DEBUG:root:[ Iteration 60 ] Test loss: 0.0394815
DEBUG:root:[ Iteration 63 ] Training loss: 0.0341276
DEBUG:root:[ Iteration 66 ] Training loss: 0.033553
DEBUG:root:[ Iteration 69 ] Training loss: 0.039207
DEBUG:root:[ Iteration 72 ] Training loss: 0.0382311
DEBUG:root:[ Iteration 75 ] Training loss: 0.0343675
DEBUG:root:[ Iteration 78 ] Training loss: 0.0335612
DEBUG:root:[ Iteration 80 ] Test loss: 0.0365389
DEBUG:root:[ Iteration 81 ] Training loss: 0.0356107
DEBUG:root:[ Iteration 84 ] Training loss: 0.0313732
DEBUG:root:[ Iteration 87 ] Training loss: 0.0297823
DEBUG:root:[ Iteration 90 ] Training loss: 0.0298455
DEBUG:root:[ Iteration 93 ] Training loss: 0.0316155
DEBUG:root:[ Iteration 96 ] Training loss: 0.0297843
DEBUG:root:[ Iteration 99 ] Training loss: 0.0359791
DEBUG:root:[ Iteration 100 ] Test loss: 0.0309309
DEBUG:root:[ Iteration 102 ] Training loss: 0.0297629
DEBUG:root:[ Iteration 105 ] Training loss: 0.0272115
DEBUG:root:[ Iteration 108 ] Training loss: 0.028665
DEBUG:root:[ Iteration 111 ] Training loss: 0.0277568
DEBUG:root:[ Iteration 114 ] Training loss: 0.030144
DEBUG:root:[ Iteration 117 ] Training loss: 0.0259168
DEBUG:root:[ Iteration 120 ] Training loss: 0.0293579
DEBUG:root:[ Iteration 120 ] Test loss: 0.0296487
DEBUG:root:[ Iteration 123 ] Training loss: 0.0349673
DEBUG:root:[ Iteration 126 ] Training loss: 0.0294181
DEBUG:root:[ Iteration 129 ] Training loss: 0.0318323
DEBUG:root:[ Iteration 132 ] Training loss: 0.0260253
DEBUG:root:[ Iteration 135 ] Training loss: 0.0362684
DEBUG:root:[ Iteration 138 ] Training loss: 0.029167
DEBUG:root:[ Iteration 140 ] Test loss: 0.0276554
DEBUG:root:[ Iteration 141 ] Training loss: 0.0323924
DEBUG:root:[ Iteration 144 ] Training loss: 0.0251247
DEBUG:root:[ Iteration 147 ] Training loss: 0.0276234
DEBUG:root:[ Iteration 150 ] Training loss: 0.0308279
DEBUG:root:[ Iteration 153 ] Training loss: 0.0232597
DEBUG:root:[ Iteration 156 ] Training loss: 0.0383902
DEBUG:root:[ Iteration 159 ] Training loss: 0.0245727
DEBUG:root:[ Iteration 160 ] Test loss: 0.026544
DEBUG:root:[ Iteration 162 ] Training loss: 0.0330004
DEBUG:root:[ Iteration 165 ] Training loss: 0.0284123
DEBUG:root:[ Iteration 168 ] Training loss: 0.0297752
DEBUG:root:[ Iteration 171 ] Training loss: 0.028907
DEBUG:root:[ Iteration 174 ] Training loss: 0.0305388
DEBUG:root:[ Iteration 177 ] Training loss: 0.0269843
DEBUG:root:[ Iteration 180 ] Training loss: 0.0242389
DEBUG:root:[ Iteration 180 ] Test loss: 0.0272112
DEBUG:root:[ Iteration 183 ] Training loss: 0.0267282
DEBUG:root:[ Iteration 186 ] Training loss: 0.0263008
DEBUG:root:[ Iteration 189 ] Training loss: 0.0266801
DEBUG:root:[ Iteration 192 ] Training loss: 0.0286309
DEBUG:root:[ Iteration 195 ] Training loss: 0.0250267
DEBUG:root:[ Iteration 198 ] Training loss: 0.0267541
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_16h16m02s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0258224
DEBUG:root:[ Iteration 0 ] Test loss: 0.0207389
DEBUG:root:[ Iteration 3 ] Training loss: 0.0225778
DEBUG:root:[ Iteration 6 ] Training loss: 0.0248504
DEBUG:root:[ Iteration 9 ] Training loss: 0.0298401
DEBUG:root:[ Iteration 12 ] Training loss: 0.0233382
DEBUG:root:[ Iteration 15 ] Training loss: 0.0208628
DEBUG:root:[ Iteration 18 ] Training loss: 0.0232084
DEBUG:root:[ Iteration 20 ] Test loss: 0.0233655
DEBUG:root:[ Iteration 21 ] Training loss: 0.0283115
DEBUG:root:[ Iteration 24 ] Training loss: 0.0206788
DEBUG:root:[ Iteration 27 ] Training loss: 0.0224817
DEBUG:root:[ Iteration 30 ] Training loss: 0.0223423
DEBUG:root:[ Iteration 33 ] Training loss: 0.0259307
DEBUG:root:[ Iteration 36 ] Training loss: 0.0256062
DEBUG:root:[ Iteration 39 ] Training loss: 0.01957
DEBUG:root:[ Iteration 40 ] Test loss: 0.021394
DEBUG:root:[ Iteration 42 ] Training loss: 0.0204115
DEBUG:root:[ Iteration 45 ] Training loss: 0.0175056
DEBUG:root:[ Iteration 48 ] Training loss: 0.0241174
DEBUG:root:[ Iteration 51 ] Training loss: 0.0260569
DEBUG:root:[ Iteration 54 ] Training loss: 0.0219911
DEBUG:root:[ Iteration 57 ] Training loss: 0.0224868
DEBUG:root:[ Iteration 60 ] Training loss: 0.0217116
DEBUG:root:[ Iteration 60 ] Test loss: 0.0232491
DEBUG:root:[ Iteration 63 ] Training loss: 0.0193628
DEBUG:root:[ Iteration 66 ] Training loss: 0.023766
DEBUG:root:[ Iteration 69 ] Training loss: 0.0193984
DEBUG:root:[ Iteration 72 ] Training loss: 0.022324
DEBUG:root:[ Iteration 75 ] Training loss: 0.0221265
DEBUG:root:[ Iteration 78 ] Training loss: 0.0191013
DEBUG:root:[ Iteration 80 ] Test loss: 0.0189637
DEBUG:root:[ Iteration 81 ] Training loss: 0.0232711
DEBUG:root:[ Iteration 84 ] Training loss: 0.0236819
DEBUG:root:[ Iteration 87 ] Training loss: 0.025431
DEBUG:root:[ Iteration 90 ] Training loss: 0.0239108
DEBUG:root:[ Iteration 93 ] Training loss: 0.0170145
DEBUG:root:[ Iteration 96 ] Training loss: 0.0201
DEBUG:root:[ Iteration 99 ] Training loss: 0.019247
DEBUG:root:[ Iteration 100 ] Test loss: 0.0167453
DEBUG:root:[ Iteration 102 ] Training loss: 0.0165706
DEBUG:root:[ Iteration 105 ] Training loss: 0.02423
DEBUG:root:[ Iteration 108 ] Training loss: 0.0153349
DEBUG:root:[ Iteration 111 ] Training loss: 0.0152776
DEBUG:root:[ Iteration 114 ] Training loss: 0.0193108
DEBUG:root:[ Iteration 117 ] Training loss: 0.0226929
DEBUG:root:[ Iteration 120 ] Training loss: 0.0187626
DEBUG:root:[ Iteration 120 ] Test loss: 0.0174802
DEBUG:root:[ Iteration 123 ] Training loss: 0.0139722
DEBUG:root:[ Iteration 126 ] Training loss: 0.0237948
DEBUG:root:[ Iteration 129 ] Training loss: 0.018231
DEBUG:root:[ Iteration 132 ] Training loss: 0.0183859
DEBUG:root:[ Iteration 135 ] Training loss: 0.0167849
DEBUG:root:[ Iteration 138 ] Training loss: 0.0166049
DEBUG:root:[ Iteration 140 ] Test loss: 0.0184522
DEBUG:root:[ Iteration 141 ] Training loss: 0.0168402
DEBUG:root:[ Iteration 144 ] Training loss: 0.026575
DEBUG:root:[ Iteration 147 ] Training loss: 0.0163016
DEBUG:root:[ Iteration 150 ] Training loss: 0.0170531
DEBUG:root:[ Iteration 153 ] Training loss: 0.0167926
DEBUG:root:[ Iteration 156 ] Training loss: 0.0237217
DEBUG:root:[ Iteration 159 ] Training loss: 0.0205589
DEBUG:root:[ Iteration 160 ] Test loss: 0.0189214
DEBUG:root:[ Iteration 162 ] Training loss: 0.0178385
DEBUG:root:[ Iteration 165 ] Training loss: 0.0167236
DEBUG:root:[ Iteration 168 ] Training loss: 0.0132729
DEBUG:root:[ Iteration 171 ] Training loss: 0.0162788
DEBUG:root:[ Iteration 174 ] Training loss: 0.0146948
DEBUG:root:[ Iteration 177 ] Training loss: 0.0154507
DEBUG:root:[ Iteration 180 ] Training loss: 0.0163296
DEBUG:root:[ Iteration 180 ] Test loss: 0.0190572
DEBUG:root:[ Iteration 183 ] Training loss: 0.020596
DEBUG:root:[ Iteration 186 ] Training loss: 0.0161082
DEBUG:root:[ Iteration 189 ] Training loss: 0.0160654
DEBUG:root:[ Iteration 192 ] Training loss: 0.0176865
DEBUG:root:[ Iteration 195 ] Training loss: 0.0204524
DEBUG:root:[ Iteration 198 ] Training loss: 0.0148676
DEBUG:root:[ Iteration 200 ] Test loss: 0.0176993
DEBUG:root:[ Iteration 201 ] Training loss: 0.0159056
DEBUG:root:[ Iteration 204 ] Training loss: 0.0176859
DEBUG:root:[ Iteration 207 ] Training loss: 0.0192578
DEBUG:root:[ Iteration 210 ] Training loss: 0.0154983
DEBUG:root:[ Iteration 213 ] Training loss: 0.0139502
DEBUG:root:[ Iteration 216 ] Training loss: 0.0185883
DEBUG:root:[ Iteration 219 ] Training loss: 0.0155138
DEBUG:root:[ Iteration 220 ] Test loss: 0.0197
DEBUG:root:[ Iteration 222 ] Training loss: 0.0207517
DEBUG:root:[ Iteration 225 ] Training loss: 0.0184921
DEBUG:root:[ Iteration 228 ] Training loss: 0.0149598
DEBUG:root:[ Iteration 231 ] Training loss: 0.0164178
DEBUG:root:[ Iteration 234 ] Training loss: 0.0190963
DEBUG:root:[ Iteration 237 ] Training loss: 0.0162516
DEBUG:root:[ Iteration 240 ] Training loss: 0.0204471
DEBUG:root:[ Iteration 240 ] Test loss: 0.0249276
DEBUG:root:[ Iteration 243 ] Training loss: 0.0138099
DEBUG:root:[ Iteration 246 ] Training loss: 0.0178183
DEBUG:root:[ Iteration 249 ] Training loss: 0.0155275
DEBUG:root:[ Iteration 252 ] Training loss: 0.0153226
DEBUG:root:[ Iteration 255 ] Training loss: 0.0192884
DEBUG:root:[ Iteration 258 ] Training loss: 0.0210332
DEBUG:root:[ Iteration 260 ] Test loss: 0.0162814
DEBUG:root:[ Iteration 261 ] Training loss: 0.0176945
DEBUG:root:[ Iteration 264 ] Training loss: 0.0166211
DEBUG:root:[ Iteration 267 ] Training loss: 0.0146668
DEBUG:root:[ Iteration 270 ] Training loss: 0.0181038
DEBUG:root:[ Iteration 273 ] Training loss: 0.0150848
DEBUG:root:[ Iteration 276 ] Training loss: 0.0154577
DEBUG:root:[ Iteration 279 ] Training loss: 0.0129859
DEBUG:root:[ Iteration 280 ] Test loss: 0.0151077
DEBUG:root:[ Iteration 282 ] Training loss: 0.0129649
DEBUG:root:[ Iteration 285 ] Training loss: 0.0161648
DEBUG:root:[ Iteration 288 ] Training loss: 0.0130392
DEBUG:root:[ Iteration 291 ] Training loss: 0.0139671
DEBUG:root:[ Iteration 294 ] Training loss: 0.0148856
DEBUG:root:[ Iteration 297 ] Training loss: 0.0155534
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_16h23m55s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.19094
DEBUG:root:[ Iteration 0 ] Test loss: 0.190359
DEBUG:root:[ Iteration 3 ] Training loss: 0.193623
DEBUG:root:[ Iteration 6 ] Training loss: 0.190103
DEBUG:root:[ Iteration 9 ] Training loss: 0.184255
DEBUG:root:[ Iteration 12 ] Training loss: 0.179976
DEBUG:root:[ Iteration 15 ] Training loss: 0.181588
DEBUG:root:[ Iteration 18 ] Training loss: 0.173982
DEBUG:root:[ Iteration 20 ] Test loss: 0.166412
DEBUG:root:[ Iteration 21 ] Training loss: 0.157122
DEBUG:root:[ Iteration 24 ] Training loss: 0.124214
DEBUG:root:[ Iteration 27 ] Training loss: 0.0908677
DEBUG:root:[ Iteration 30 ] Training loss: 0.0863205
DEBUG:root:[ Iteration 33 ] Training loss: 0.104173
DEBUG:root:[ Iteration 36 ] Training loss: 0.0917369
DEBUG:root:[ Iteration 39 ] Training loss: 0.0691521
DEBUG:root:[ Iteration 40 ] Test loss: 0.0788921
DEBUG:root:[ Iteration 42 ] Training loss: 0.083868
DEBUG:root:[ Iteration 45 ] Training loss: 0.0766178
DEBUG:root:[ Iteration 48 ] Training loss: 0.059246
DEBUG:root:[ Iteration 51 ] Training loss: 0.0720508
DEBUG:root:[ Iteration 54 ] Training loss: 0.0770464
DEBUG:root:[ Iteration 57 ] Training loss: 0.0824575
DEBUG:root:[ Iteration 60 ] Training loss: 0.0817674
DEBUG:root:[ Iteration 60 ] Test loss: 0.0917225
DEBUG:root:[ Iteration 63 ] Training loss: 0.0728328
DEBUG:root:[ Iteration 66 ] Training loss: 0.0633921
DEBUG:root:[ Iteration 69 ] Training loss: 0.0607435
DEBUG:root:[ Iteration 72 ] Training loss: 0.0613389
DEBUG:root:[ Iteration 75 ] Training loss: 0.0646404
DEBUG:root:[ Iteration 78 ] Training loss: 0.0562672
DEBUG:root:[ Iteration 80 ] Test loss: 0.0741207
DEBUG:root:[ Iteration 81 ] Training loss: 0.0780896
DEBUG:root:[ Iteration 84 ] Training loss: 0.0567227
DEBUG:root:[ Iteration 87 ] Training loss: 0.0607909
DEBUG:root:[ Iteration 90 ] Training loss: 0.0601487
DEBUG:root:[ Iteration 93 ] Training loss: 0.0591621
DEBUG:root:[ Iteration 96 ] Training loss: 0.0666145
DEBUG:root:[ Iteration 99 ] Training loss: 0.0669556
DEBUG:root:[ Iteration 100 ] Test loss: 0.0566902
DEBUG:root:[ Iteration 102 ] Training loss: 0.0562197
DEBUG:root:[ Iteration 105 ] Training loss: 0.0704421
DEBUG:root:[ Iteration 108 ] Training loss: 0.052096
DEBUG:root:[ Iteration 111 ] Training loss: 0.056269
DEBUG:root:[ Iteration 114 ] Training loss: 0.0608123
DEBUG:root:[ Iteration 117 ] Training loss: 0.0801912
DEBUG:root:[ Iteration 120 ] Training loss: 0.0588106
DEBUG:root:[ Iteration 120 ] Test loss: 0.063276
DEBUG:root:[ Iteration 123 ] Training loss: 0.0707839
DEBUG:root:[ Iteration 126 ] Training loss: 0.0436058
DEBUG:root:[ Iteration 129 ] Training loss: 0.0530427
DEBUG:root:[ Iteration 132 ] Training loss: 0.0587902
DEBUG:root:[ Iteration 135 ] Training loss: 0.0519148
DEBUG:root:[ Iteration 138 ] Training loss: 0.0474879
DEBUG:root:[ Iteration 140 ] Test loss: 0.0350313
DEBUG:root:[ Iteration 141 ] Training loss: 0.0658635
DEBUG:root:[ Iteration 144 ] Training loss: 0.040401
DEBUG:root:[ Iteration 147 ] Training loss: 0.0569693
DEBUG:root:[ Iteration 150 ] Training loss: 0.0487519
DEBUG:root:[ Iteration 153 ] Training loss: 0.0389473
DEBUG:root:[ Iteration 156 ] Training loss: 0.0664834
DEBUG:root:[ Iteration 159 ] Training loss: 0.0595529
DEBUG:root:[ Iteration 160 ] Test loss: 0.0513225
DEBUG:root:[ Iteration 162 ] Training loss: 0.0491038
DEBUG:root:[ Iteration 165 ] Training loss: 0.0468287
DEBUG:root:[ Iteration 168 ] Training loss: 0.0521418
DEBUG:root:[ Iteration 171 ] Training loss: 0.0451249
DEBUG:root:[ Iteration 174 ] Training loss: 0.0513512
DEBUG:root:[ Iteration 177 ] Training loss: 0.0417252
DEBUG:root:[ Iteration 180 ] Training loss: 0.0552855
DEBUG:root:[ Iteration 180 ] Test loss: 0.0432459
DEBUG:root:[ Iteration 183 ] Training loss: 0.0366209
DEBUG:root:[ Iteration 186 ] Training loss: 0.0442075
DEBUG:root:[ Iteration 189 ] Training loss: 0.0491258
DEBUG:root:[ Iteration 192 ] Training loss: 0.0383902
DEBUG:root:[ Iteration 195 ] Training loss: 0.0404742
DEBUG:root:[ Iteration 198 ] Training loss: 0.0403054
DEBUG:root:[ Iteration 200 ] Test loss: 0.038527
DEBUG:root:[ Iteration 201 ] Training loss: 0.0351791
DEBUG:root:[ Iteration 204 ] Training loss: 0.0357334
DEBUG:root:[ Iteration 207 ] Training loss: 0.0332563
DEBUG:root:[ Iteration 210 ] Training loss: 0.0409334
DEBUG:root:[ Iteration 213 ] Training loss: 0.0369082
DEBUG:root:[ Iteration 216 ] Training loss: 0.0333406
DEBUG:root:[ Iteration 219 ] Training loss: 0.034548
DEBUG:root:[ Iteration 220 ] Test loss: 0.0520515
DEBUG:root:[ Iteration 222 ] Training loss: 0.047104
DEBUG:root:[ Iteration 225 ] Training loss: 0.0289563
DEBUG:root:[ Iteration 228 ] Training loss: 0.0345654
DEBUG:root:[ Iteration 231 ] Training loss: 0.028181
DEBUG:root:[ Iteration 234 ] Training loss: 0.0335365
DEBUG:root:[ Iteration 237 ] Training loss: 0.0501044
DEBUG:root:[ Iteration 240 ] Training loss: 0.0292053
DEBUG:root:[ Iteration 240 ] Test loss: 0.0367223
DEBUG:root:[ Iteration 243 ] Training loss: 0.0326912
DEBUG:root:[ Iteration 246 ] Training loss: 0.0373661
DEBUG:root:[ Iteration 249 ] Training loss: 0.0416496
DEBUG:root:[ Iteration 252 ] Training loss: 0.0301898
DEBUG:root:[ Iteration 255 ] Training loss: 0.033979
DEBUG:root:[ Iteration 258 ] Training loss: 0.0333023
DEBUG:root:[ Iteration 260 ] Test loss: 0.0360943
DEBUG:root:[ Iteration 261 ] Training loss: 0.0247093
DEBUG:root:[ Iteration 264 ] Training loss: 0.0290357
DEBUG:root:[ Iteration 267 ] Training loss: 0.0327707
DEBUG:root:[ Iteration 270 ] Training loss: 0.0398457
DEBUG:root:[ Iteration 273 ] Training loss: 0.0321159
DEBUG:root:[ Iteration 276 ] Training loss: 0.0402308
DEBUG:root:[ Iteration 279 ] Training loss: 0.0389345
DEBUG:root:[ Iteration 280 ] Test loss: 0.038067
DEBUG:root:[ Iteration 282 ] Training loss: 0.0319362
DEBUG:root:[ Iteration 285 ] Training loss: 0.0288917
DEBUG:root:[ Iteration 288 ] Training loss: 0.0314227
DEBUG:root:[ Iteration 291 ] Training loss: 0.0444028
DEBUG:root:[ Iteration 294 ] Training loss: 0.0284135
DEBUG:root:[ Iteration 297 ] Training loss: 0.0270718
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-27-2016_17h28m48s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0131695
DEBUG:root:[ Iteration 0 ] Test loss: 0.0205296
DEBUG:root:[ Iteration 3 ] Training loss: 0.0149998
DEBUG:root:[ Iteration 6 ] Training loss: 0.0152573
DEBUG:root:[ Iteration 9 ] Training loss: 0.0158843
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-28-2016_12h14m27s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0546677
DEBUG:root:[ Iteration 0 ] Test loss: 0.0615343
DEBUG:root:[ Iteration 3 ] Training loss: 0.0298627
DEBUG:root:[ Iteration 6 ] Training loss: 0.0499861
DEBUG:root:[ Iteration 9 ] Training loss: 0.0326184
DEBUG:root:[ Iteration 12 ] Training loss: 0.0295753
DEBUG:root:[ Iteration 15 ] Training loss: 0.0284456
DEBUG:root:[ Iteration 18 ] Training loss: 0.0324675
DEBUG:root:[ Iteration 20 ] Test loss: 0.0355379
DEBUG:root:[ Iteration 21 ] Training loss: 0.0331678
DEBUG:root:[ Iteration 24 ] Training loss: 0.0290082
DEBUG:root:[ Iteration 27 ] Training loss: 0.0270501
DEBUG:root:[ Iteration 30 ] Training loss: 0.02362
DEBUG:root:[ Iteration 33 ] Training loss: 0.0267994
DEBUG:root:[ Iteration 36 ] Training loss: 0.0314531
DEBUG:root:[ Iteration 39 ] Training loss: 0.0308181
DEBUG:root:[ Iteration 40 ] Test loss: 0.0281243
DEBUG:root:[ Iteration 42 ] Training loss: 0.0245541
DEBUG:root:[ Iteration 45 ] Training loss: 0.0229941
DEBUG:root:[ Iteration 48 ] Training loss: 0.0204825
DEBUG:root:[ Iteration 51 ] Training loss: 0.025022
DEBUG:root:[ Iteration 54 ] Training loss: 0.0243337
DEBUG:root:[ Iteration 57 ] Training loss: 0.0209944
DEBUG:root:[ Iteration 60 ] Training loss: 0.0215729
DEBUG:root:[ Iteration 60 ] Test loss: 0.0268793
DEBUG:root:[ Iteration 63 ] Training loss: 0.0208597
DEBUG:root:[ Iteration 66 ] Training loss: 0.019589
DEBUG:root:[ Iteration 69 ] Training loss: 0.0195133
DEBUG:root:[ Iteration 72 ] Training loss: 0.0223371
DEBUG:root:[ Iteration 75 ] Training loss: 0.0209346
DEBUG:root:[ Iteration 78 ] Training loss: 0.0211646
DEBUG:root:[ Iteration 80 ] Test loss: 0.0235954
DEBUG:root:[ Iteration 81 ] Training loss: 0.024149
DEBUG:root:[ Iteration 84 ] Training loss: 0.0234441
DEBUG:root:[ Iteration 87 ] Training loss: 0.0202384
DEBUG:root:[ Iteration 90 ] Training loss: 0.0198821
DEBUG:root:[ Iteration 93 ] Training loss: 0.019401
DEBUG:root:[ Iteration 96 ] Training loss: 0.0181421
DEBUG:root:[ Iteration 99 ] Training loss: 0.0151169
DEBUG:root:[ Iteration 100 ] Test loss: 0.0195753
DEBUG:root:[ Iteration 102 ] Training loss: 0.0176552
DEBUG:root:[ Iteration 105 ] Training loss: 0.0192483
DEBUG:root:[ Iteration 108 ] Training loss: 0.0224062
DEBUG:root:[ Iteration 111 ] Training loss: 0.0139648
DEBUG:root:[ Iteration 114 ] Training loss: 0.0164901
DEBUG:root:[ Iteration 117 ] Training loss: 0.0187122
DEBUG:root:[ Iteration 120 ] Training loss: 0.0190263
DEBUG:root:[ Iteration 120 ] Test loss: 0.0198431
DEBUG:root:[ Iteration 123 ] Training loss: 0.0160818
DEBUG:root:[ Iteration 126 ] Training loss: 0.016186
DEBUG:root:[ Iteration 129 ] Training loss: 0.0160522
DEBUG:root:[ Iteration 132 ] Training loss: 0.0143184
DEBUG:root:[ Iteration 135 ] Training loss: 0.0187356
DEBUG:root:[ Iteration 138 ] Training loss: 0.0160767
DEBUG:root:[ Iteration 140 ] Test loss: 0.01732
DEBUG:root:[ Iteration 141 ] Training loss: 0.0183531
DEBUG:root:[ Iteration 144 ] Training loss: 0.0176846
DEBUG:root:[ Iteration 147 ] Training loss: 0.0139486
DEBUG:root:[ Iteration 150 ] Training loss: 0.0165246
DEBUG:root:[ Iteration 153 ] Training loss: 0.0174735
DEBUG:root:[ Iteration 156 ] Training loss: 0.0142586
DEBUG:root:[ Iteration 159 ] Training loss: 0.0177648
DEBUG:root:[ Iteration 160 ] Test loss: 0.0170321
DEBUG:root:[ Iteration 162 ] Training loss: 0.0166674
DEBUG:root:[ Iteration 165 ] Training loss: 0.0157518
DEBUG:root:[ Iteration 168 ] Training loss: 0.0162748
DEBUG:root:[ Iteration 171 ] Training loss: 0.0193185
DEBUG:root:[ Iteration 174 ] Training loss: 0.0180709
DEBUG:root:[ Iteration 177 ] Training loss: 0.0148115
DEBUG:root:[ Iteration 180 ] Training loss: 0.0138822
DEBUG:root:[ Iteration 180 ] Test loss: 0.0179308
DEBUG:root:[ Iteration 183 ] Training loss: 0.0158375
DEBUG:root:[ Iteration 186 ] Training loss: 0.018199
DEBUG:root:[ Iteration 189 ] Training loss: 0.0123266
DEBUG:root:[ Iteration 192 ] Training loss: 0.0117773
DEBUG:root:[ Iteration 195 ] Training loss: 0.0169405
DEBUG:root:[ Iteration 198 ] Training loss: 0.0132185
DEBUG:root:[ Iteration 200 ] Test loss: 0.0153247
DEBUG:root:[ Iteration 201 ] Training loss: 0.0100398
DEBUG:root:[ Iteration 204 ] Training loss: 0.0119622
DEBUG:root:[ Iteration 207 ] Training loss: 0.0167687
DEBUG:root:[ Iteration 210 ] Training loss: 0.0154672
DEBUG:root:[ Iteration 213 ] Training loss: 0.0169686
DEBUG:root:[ Iteration 216 ] Training loss: 0.0139269
DEBUG:root:[ Iteration 219 ] Training loss: 0.0214051
DEBUG:root:[ Iteration 220 ] Test loss: 0.0172257
DEBUG:root:[ Iteration 222 ] Training loss: 0.0152099
DEBUG:root:[ Iteration 225 ] Training loss: 0.0136143
DEBUG:root:[ Iteration 228 ] Training loss: 0.0212661
DEBUG:root:[ Iteration 231 ] Training loss: 0.0128042
DEBUG:root:[ Iteration 234 ] Training loss: 0.0125197
DEBUG:root:[ Iteration 237 ] Training loss: 0.0200794
DEBUG:root:[ Iteration 240 ] Training loss: 0.0138049
DEBUG:root:[ Iteration 240 ] Test loss: 0.0196128
DEBUG:root:[ Iteration 243 ] Training loss: 0.0144304
DEBUG:root:[ Iteration 246 ] Training loss: 0.011582
DEBUG:root:[ Iteration 249 ] Training loss: 0.0131626
DEBUG:root:[ Iteration 252 ] Training loss: 0.0113071
DEBUG:root:[ Iteration 255 ] Training loss: 0.0143151
DEBUG:root:[ Iteration 258 ] Training loss: 0.011035
DEBUG:root:[ Iteration 260 ] Test loss: 0.0170645
DEBUG:root:[ Iteration 261 ] Training loss: 0.0112502
DEBUG:root:[ Iteration 264 ] Training loss: 0.0112403
DEBUG:root:[ Iteration 267 ] Training loss: 0.0145536
DEBUG:root:[ Iteration 270 ] Training loss: 0.017662
DEBUG:root:[ Iteration 273 ] Training loss: 0.0136244
DEBUG:root:[ Iteration 276 ] Training loss: 0.0132548
DEBUG:root:[ Iteration 279 ] Training loss: 0.0154543
DEBUG:root:[ Iteration 280 ] Test loss: 0.0143592
DEBUG:root:[ Iteration 282 ] Training loss: 0.0123836
DEBUG:root:[ Iteration 285 ] Training loss: 0.0125982
DEBUG:root:[ Iteration 288 ] Training loss: 0.0111404
DEBUG:root:[ Iteration 291 ] Training loss: 0.0119754
DEBUG:root:[ Iteration 294 ] Training loss: 0.0141463
DEBUG:root:[ Iteration 297 ] Training loss: 0.0129044
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-28-2016_12h22m03s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0108321
DEBUG:root:[ Iteration 0 ] Test loss: 0.0181895
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-28-2016_14h08m30s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.022956
DEBUG:root:[ Iteration 0 ] Test loss: 0.0164656
DEBUG:root:[ Iteration 3 ] Training loss: 0.0279833
DEBUG:root:[ Iteration 6 ] Training loss: 0.0187193
DEBUG:root:[ Iteration 9 ] Training loss: 0.0166312
DEBUG:root:[ Iteration 12 ] Training loss: 0.0184106
DEBUG:root:[ Iteration 15 ] Training loss: 0.0240697
DEBUG:root:[ Iteration 18 ] Training loss: 0.0232534
DEBUG:root:[ Iteration 20 ] Test loss: 0.0185547
DEBUG:root:[ Iteration 21 ] Training loss: 0.0155215
DEBUG:root:[ Iteration 24 ] Training loss: 0.0173943
DEBUG:root:[ Iteration 27 ] Training loss: 0.0182478
DEBUG:root:[ Iteration 30 ] Training loss: 0.018198
DEBUG:root:[ Iteration 33 ] Training loss: 0.0161618
DEBUG:root:[ Iteration 36 ] Training loss: 0.0163284
DEBUG:root:[ Iteration 39 ] Training loss: 0.0172736
DEBUG:root:[ Iteration 40 ] Test loss: 0.0211207
DEBUG:root:[ Iteration 42 ] Training loss: 0.0129195
DEBUG:root:[ Iteration 45 ] Training loss: 0.0148493
DEBUG:root:[ Iteration 48 ] Training loss: 0.0182865
DEBUG:root:[ Iteration 51 ] Training loss: 0.0186306
DEBUG:root:[ Iteration 54 ] Training loss: 0.0188093
DEBUG:root:[ Iteration 57 ] Training loss: 0.0145855
DEBUG:root:[ Iteration 60 ] Training loss: 0.0197159
DEBUG:root:[ Iteration 60 ] Test loss: 0.0199622
DEBUG:root:[ Iteration 63 ] Training loss: 0.0191929
DEBUG:root:[ Iteration 66 ] Training loss: 0.0172494
DEBUG:root:[ Iteration 69 ] Training loss: 0.014509
DEBUG:root:[ Iteration 72 ] Training loss: 0.0187386
DEBUG:root:[ Iteration 75 ] Training loss: 0.0122197
DEBUG:root:[ Iteration 78 ] Training loss: 0.0160621
DEBUG:root:[ Iteration 80 ] Test loss: 0.0198341
DEBUG:root:[ Iteration 81 ] Training loss: 0.017208
DEBUG:root:[ Iteration 84 ] Training loss: 0.0137634
DEBUG:root:[ Iteration 87 ] Training loss: 0.0147493
DEBUG:root:[ Iteration 90 ] Training loss: 0.0155091
DEBUG:root:[ Iteration 93 ] Training loss: 0.0141121
DEBUG:root:[ Iteration 96 ] Training loss: 0.0167122
DEBUG:root:[ Iteration 99 ] Training loss: 0.0166458
DEBUG:root:[ Iteration 100 ] Test loss: 0.0181334
DEBUG:root:[ Iteration 102 ] Training loss: 0.0190712
DEBUG:root:[ Iteration 105 ] Training loss: 0.0173375
DEBUG:root:[ Iteration 108 ] Training loss: 0.0161952
DEBUG:root:[ Iteration 111 ] Training loss: 0.0227336
DEBUG:root:[ Iteration 114 ] Training loss: 0.0164165
DEBUG:root:[ Iteration 117 ] Training loss: 0.0182663
DEBUG:root:[ Iteration 120 ] Training loss: 0.0135992
DEBUG:root:[ Iteration 120 ] Test loss: 0.0194733
DEBUG:root:[ Iteration 123 ] Training loss: 0.0153881
DEBUG:root:[ Iteration 126 ] Training loss: 0.0176843
DEBUG:root:[ Iteration 129 ] Training loss: 0.0159612
DEBUG:root:[ Iteration 132 ] Training loss: 0.0221283
DEBUG:root:[ Iteration 135 ] Training loss: 0.0166974
DEBUG:root:[ Iteration 138 ] Training loss: 0.0191841
DEBUG:root:[ Iteration 140 ] Test loss: 0.0168235
DEBUG:root:[ Iteration 141 ] Training loss: 0.0169763
DEBUG:root:[ Iteration 144 ] Training loss: 0.0173157
DEBUG:root:[ Iteration 147 ] Training loss: 0.0160057
DEBUG:root:[ Iteration 150 ] Training loss: 0.0134767
DEBUG:root:[ Iteration 153 ] Training loss: 0.014284
DEBUG:root:[ Iteration 156 ] Training loss: 0.0112273
DEBUG:root:[ Iteration 159 ] Training loss: 0.0152084
DEBUG:root:[ Iteration 160 ] Test loss: 0.0164922
DEBUG:root:[ Iteration 162 ] Training loss: 0.00939901
DEBUG:root:[ Iteration 165 ] Training loss: 0.0133378
DEBUG:root:[ Iteration 168 ] Training loss: 0.0113258
DEBUG:root:[ Iteration 171 ] Training loss: 0.0133784
DEBUG:root:[ Iteration 174 ] Training loss: 0.0139496
DEBUG:root:[ Iteration 177 ] Training loss: 0.0148943
DEBUG:root:[ Iteration 180 ] Training loss: 0.0151117
DEBUG:root:[ Iteration 180 ] Test loss: 0.0184551
DEBUG:root:[ Iteration 183 ] Training loss: 0.0189994
DEBUG:root:[ Iteration 186 ] Training loss: 0.0163438
DEBUG:root:[ Iteration 189 ] Training loss: 0.0118632
DEBUG:root:[ Iteration 192 ] Training loss: 0.0146005
DEBUG:root:[ Iteration 195 ] Training loss: 0.0124791
DEBUG:root:[ Iteration 198 ] Training loss: 0.0112879
DEBUG:root:[ Iteration 200 ] Test loss: 0.0138006
DEBUG:root:[ Iteration 201 ] Training loss: 0.0168466
DEBUG:root:[ Iteration 204 ] Training loss: 0.0133095
DEBUG:root:[ Iteration 207 ] Training loss: 0.0108432
DEBUG:root:[ Iteration 210 ] Training loss: 0.0144228
DEBUG:root:[ Iteration 213 ] Training loss: 0.0127857
DEBUG:root:[ Iteration 216 ] Training loss: 0.0108295
DEBUG:root:[ Iteration 219 ] Training loss: 0.0128315
DEBUG:root:[ Iteration 220 ] Test loss: 0.0114164
DEBUG:root:[ Iteration 222 ] Training loss: 0.0176956
DEBUG:root:[ Iteration 225 ] Training loss: 0.0151119
DEBUG:root:[ Iteration 228 ] Training loss: 0.0167808
DEBUG:root:[ Iteration 231 ] Training loss: 0.0172432
DEBUG:root:[ Iteration 234 ] Training loss: 0.0107024
DEBUG:root:[ Iteration 237 ] Training loss: 0.011781
DEBUG:root:[ Iteration 240 ] Training loss: 0.0155147
DEBUG:root:[ Iteration 240 ] Test loss: 0.0167468
DEBUG:root:[ Iteration 243 ] Training loss: 0.0164105
DEBUG:root:[ Iteration 246 ] Training loss: 0.0150335
DEBUG:root:[ Iteration 249 ] Training loss: 0.0133039
DEBUG:root:[ Iteration 252 ] Training loss: 0.0133689
DEBUG:root:[ Iteration 255 ] Training loss: 0.00942993
DEBUG:root:[ Iteration 258 ] Training loss: 0.0119644
DEBUG:root:[ Iteration 260 ] Test loss: 0.0149935
DEBUG:root:[ Iteration 261 ] Training loss: 0.0112192
DEBUG:root:[ Iteration 264 ] Training loss: 0.0134438
DEBUG:root:[ Iteration 267 ] Training loss: 0.00980147
DEBUG:root:[ Iteration 270 ] Training loss: 0.0126483
DEBUG:root:[ Iteration 273 ] Training loss: 0.0157371
DEBUG:root:[ Iteration 276 ] Training loss: 0.0126115
DEBUG:root:[ Iteration 279 ] Training loss: 0.0122921
DEBUG:root:[ Iteration 280 ] Test loss: 0.0172129
DEBUG:root:[ Iteration 282 ] Training loss: 0.0122648
DEBUG:root:[ Iteration 285 ] Training loss: 0.0167047
DEBUG:root:[ Iteration 288 ] Training loss: 0.0164128
DEBUG:root:[ Iteration 291 ] Training loss: 0.0132495
DEBUG:root:[ Iteration 294 ] Training loss: 0.0132708
DEBUG:root:[ Iteration 297 ] Training loss: 0.0112814
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-28-2016_14h16m01s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.190123
DEBUG:root:[ Iteration 0 ] Test loss: 0.19015
DEBUG:root:[ Iteration 3 ] Training loss: 0.177425
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_11h25m33s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.181004
DEBUG:root:[ Iteration 0 ] Test loss: 0.182612
DEBUG:root:[ Iteration 3 ] Training loss: 0.17949
DEBUG:root:[ Iteration 6 ] Training loss: 0.154341
DEBUG:root:[ Iteration 9 ] Training loss: 0.0646667
DEBUG:root:[ Iteration 12 ] Training loss: 0.0564318
DEBUG:root:[ Iteration 15 ] Training loss: 0.0364395
DEBUG:root:[ Iteration 18 ] Training loss: 0.0475107
DEBUG:root:[ Iteration 20 ] Test loss: 0.0514724
DEBUG:root:[ Iteration 21 ] Training loss: 0.0256859
DEBUG:root:[ Iteration 24 ] Training loss: 0.0318025
DEBUG:root:[ Iteration 27 ] Training loss: 0.0305943
DEBUG:root:[ Iteration 30 ] Training loss: 0.0174594
DEBUG:root:[ Iteration 33 ] Training loss: 0.0129946
DEBUG:root:[ Iteration 36 ] Training loss: 0.0118223
DEBUG:root:[ Iteration 39 ] Training loss: 0.010744
DEBUG:root:[ Iteration 40 ] Test loss: 0.0110133
DEBUG:root:[ Iteration 42 ] Training loss: 0.00864179
DEBUG:root:[ Iteration 45 ] Training loss: 0.00767312
DEBUG:root:[ Iteration 48 ] Training loss: 0.00852083
DEBUG:root:[ Iteration 51 ] Training loss: 0.00752235
DEBUG:root:[ Iteration 54 ] Training loss: 0.00754864
DEBUG:root:[ Iteration 57 ] Training loss: 0.00538166
DEBUG:root:[ Iteration 60 ] Training loss: 0.0068993
DEBUG:root:[ Iteration 60 ] Test loss: 0.00601261
DEBUG:root:[ Iteration 63 ] Training loss: 0.00582859
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_12h23m01s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.186806
DEBUG:root:[ Iteration 0 ] Test loss: 0.18565
DEBUG:root:[ Iteration 3 ] Training loss: 0.186617
DEBUG:root:[ Iteration 6 ] Training loss: 0.183914
DEBUG:root:[ Iteration 9 ] Training loss: 0.186242
DEBUG:root:[ Iteration 12 ] Training loss: 0.180663
DEBUG:root:[ Iteration 15 ] Training loss: 0.162656
DEBUG:root:[ Iteration 18 ] Training loss: 0.164976
DEBUG:root:[ Iteration 20 ] Test loss: 0.175766
DEBUG:root:[ Iteration 21 ] Training loss: 0.163579
DEBUG:root:[ Iteration 24 ] Training loss: 0.156581
DEBUG:root:[ Iteration 27 ] Training loss: 0.157286
DEBUG:root:[ Iteration 30 ] Training loss: 0.158448
DEBUG:root:[ Iteration 33 ] Training loss: 0.140528
DEBUG:root:[ Iteration 36 ] Training loss: 0.139232
DEBUG:root:[ Iteration 39 ] Training loss: 0.121602
DEBUG:root:[ Iteration 40 ] Test loss: 0.120194
DEBUG:root:[ Iteration 42 ] Training loss: 0.105191
DEBUG:root:[ Iteration 45 ] Training loss: 0.100503
DEBUG:root:[ Iteration 48 ] Training loss: 0.0882536
DEBUG:root:[ Iteration 51 ] Training loss: 0.0738778
DEBUG:root:[ Iteration 54 ] Training loss: 0.0767789
DEBUG:root:[ Iteration 57 ] Training loss: 0.0792054
DEBUG:root:[ Iteration 60 ] Training loss: 0.0769035
DEBUG:root:[ Iteration 60 ] Test loss: 0.102672
DEBUG:root:[ Iteration 63 ] Training loss: 0.0796831
DEBUG:root:[ Iteration 66 ] Training loss: 0.0708117
DEBUG:root:[ Iteration 69 ] Training loss: 0.0630703
DEBUG:root:[ Iteration 72 ] Training loss: 0.114717
DEBUG:root:[ Iteration 75 ] Training loss: 0.0667498
DEBUG:root:[ Iteration 78 ] Training loss: 0.0709804
DEBUG:root:[ Iteration 80 ] Test loss: 0.0641676
DEBUG:root:[ Iteration 81 ] Training loss: 0.0579358
DEBUG:root:[ Iteration 84 ] Training loss: 0.0617543
DEBUG:root:[ Iteration 87 ] Training loss: 0.0568728
DEBUG:root:[ Iteration 90 ] Training loss: 0.0512206
DEBUG:root:[ Iteration 93 ] Training loss: 0.0600225
DEBUG:root:[ Iteration 96 ] Training loss: 0.0498682
DEBUG:root:[ Iteration 99 ] Training loss: 0.058053
DEBUG:root:[ Iteration 100 ] Test loss: 0.0531893
DEBUG:root:[ Iteration 102 ] Training loss: 0.0442589
DEBUG:root:[ Iteration 105 ] Training loss: 0.053259
DEBUG:root:[ Iteration 108 ] Training loss: 0.0621839
DEBUG:root:[ Iteration 111 ] Training loss: 0.0426146
DEBUG:root:[ Iteration 114 ] Training loss: 0.0495606
DEBUG:root:[ Iteration 117 ] Training loss: 0.0405897
DEBUG:root:[ Iteration 120 ] Training loss: 0.0472709
DEBUG:root:[ Iteration 120 ] Test loss: 0.0580637
DEBUG:root:[ Iteration 123 ] Training loss: 0.0508074
DEBUG:root:[ Iteration 126 ] Training loss: 0.051842
DEBUG:root:[ Iteration 129 ] Training loss: 0.0372948
DEBUG:root:[ Iteration 132 ] Training loss: 0.0551717
DEBUG:root:[ Iteration 135 ] Training loss: 0.035127
DEBUG:root:[ Iteration 138 ] Training loss: 0.0496263
DEBUG:root:[ Iteration 140 ] Test loss: 0.0639518
DEBUG:root:[ Iteration 141 ] Training loss: 0.0564045
DEBUG:root:[ Iteration 144 ] Training loss: 0.0443382
DEBUG:root:[ Iteration 147 ] Training loss: 0.0403258
DEBUG:root:[ Iteration 150 ] Training loss: 0.0354993
DEBUG:root:[ Iteration 153 ] Training loss: 0.0391996
DEBUG:root:[ Iteration 156 ] Training loss: 0.0353533
DEBUG:root:[ Iteration 159 ] Training loss: 0.0290132
DEBUG:root:[ Iteration 160 ] Test loss: 0.0468364
DEBUG:root:[ Iteration 162 ] Training loss: 0.0347609
DEBUG:root:[ Iteration 165 ] Training loss: 0.0403981
DEBUG:root:[ Iteration 168 ] Training loss: 0.037562
DEBUG:root:[ Iteration 171 ] Training loss: 0.0358124
DEBUG:root:[ Iteration 174 ] Training loss: 0.0347614
DEBUG:root:[ Iteration 177 ] Training loss: 0.0261244
DEBUG:root:[ Iteration 180 ] Training loss: 0.0309751
DEBUG:root:[ Iteration 180 ] Test loss: 0.0509777
DEBUG:root:[ Iteration 183 ] Training loss: 0.0378648
DEBUG:root:[ Iteration 186 ] Training loss: 0.0326045
DEBUG:root:[ Iteration 189 ] Training loss: 0.0399591
DEBUG:root:[ Iteration 192 ] Training loss: 0.0309474
DEBUG:root:[ Iteration 195 ] Training loss: 0.0447677
DEBUG:root:[ Iteration 198 ] Training loss: 0.0577897
DEBUG:root:[ Iteration 200 ] Test loss: 0.0560835
DEBUG:root:[ Iteration 201 ] Training loss: 0.0436473
DEBUG:root:[ Iteration 204 ] Training loss: 0.0472854
DEBUG:root:[ Iteration 207 ] Training loss: 0.0420459
DEBUG:root:[ Iteration 210 ] Training loss: 0.0323545
DEBUG:root:[ Iteration 213 ] Training loss: 0.0305198
DEBUG:root:[ Iteration 216 ] Training loss: 0.0283647
DEBUG:root:[ Iteration 219 ] Training loss: 0.0241106
DEBUG:root:[ Iteration 220 ] Test loss: 0.0475472
DEBUG:root:[ Iteration 222 ] Training loss: 0.04694
DEBUG:root:[ Iteration 225 ] Training loss: 0.0301939
DEBUG:root:[ Iteration 228 ] Training loss: 0.0349138
DEBUG:root:[ Iteration 231 ] Training loss: 0.0419096
DEBUG:root:[ Iteration 234 ] Training loss: 0.0311457
DEBUG:root:[ Iteration 237 ] Training loss: 0.0277223
DEBUG:root:[ Iteration 240 ] Training loss: 0.021528
DEBUG:root:[ Iteration 240 ] Test loss: 0.0439961
DEBUG:root:[ Iteration 243 ] Training loss: 0.0285079
DEBUG:root:[ Iteration 246 ] Training loss: 0.0271057
DEBUG:root:[ Iteration 249 ] Training loss: 0.0220355
DEBUG:root:[ Iteration 252 ] Training loss: 0.0249274
DEBUG:root:[ Iteration 255 ] Training loss: 0.0277073
DEBUG:root:[ Iteration 258 ] Training loss: 0.0286629
DEBUG:root:[ Iteration 260 ] Test loss: 0.0369202
DEBUG:root:[ Iteration 261 ] Training loss: 0.0234791
DEBUG:root:[ Iteration 264 ] Training loss: 0.0180108
DEBUG:root:[ Iteration 267 ] Training loss: 0.0236738
DEBUG:root:[ Iteration 270 ] Training loss: 0.0128975
DEBUG:root:[ Iteration 273 ] Training loss: 0.0302839
DEBUG:root:[ Iteration 276 ] Training loss: 0.0227912
DEBUG:root:[ Iteration 279 ] Training loss: 0.0252283
DEBUG:root:[ Iteration 280 ] Test loss: 0.0257474
DEBUG:root:[ Iteration 282 ] Training loss: 0.0271382
DEBUG:root:[ Iteration 285 ] Training loss: 0.0231103
DEBUG:root:[ Iteration 288 ] Training loss: 0.0313089
DEBUG:root:[ Iteration 291 ] Training loss: 0.0284883
DEBUG:root:[ Iteration 294 ] Training loss: 0.029762
DEBUG:root:[ Iteration 297 ] Training loss: 0.0288593
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_14h27m56s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.195551
DEBUG:root:[ Iteration 0 ] Test loss: 0.200386
DEBUG:root:[ Iteration 3 ] Training loss: 0.192913
DEBUG:root:[ Iteration 6 ] Training loss: 0.203824
DEBUG:root:[ Iteration 9 ] Training loss: 0.196106
DEBUG:root:[ Iteration 12 ] Training loss: 0.204491
DEBUG:root:[ Iteration 15 ] Training loss: 0.194402
DEBUG:root:[ Iteration 18 ] Training loss: 0.194365
DEBUG:root:[ Iteration 20 ] Test loss: 0.19659
DEBUG:root:[ Iteration 21 ] Training loss: 0.197333
DEBUG:root:[ Iteration 24 ] Training loss: 0.188165
DEBUG:root:[ Iteration 27 ] Training loss: 0.201519
DEBUG:root:[ Iteration 30 ] Training loss: 0.19347
DEBUG:root:[ Iteration 33 ] Training loss: 0.19247
DEBUG:root:[ Iteration 36 ] Training loss: 0.191686
DEBUG:root:[ Iteration 39 ] Training loss: 0.194545
DEBUG:root:[ Iteration 40 ] Test loss: 0.196999
DEBUG:root:[ Iteration 42 ] Training loss: 0.184435
DEBUG:root:[ Iteration 45 ] Training loss: 0.174104
DEBUG:root:[ Iteration 48 ] Training loss: 0.176025
DEBUG:root:[ Iteration 51 ] Training loss: 0.164854
DEBUG:root:[ Iteration 54 ] Training loss: 0.155801
DEBUG:root:[ Iteration 57 ] Training loss: 0.160168
DEBUG:root:[ Iteration 60 ] Training loss: 0.144394
DEBUG:root:[ Iteration 60 ] Test loss: 0.148885
DEBUG:root:[ Iteration 63 ] Training loss: 0.131467
DEBUG:root:[ Iteration 66 ] Training loss: 0.132124
DEBUG:root:[ Iteration 69 ] Training loss: 0.12746
DEBUG:root:[ Iteration 72 ] Training loss: 0.109478
DEBUG:root:[ Iteration 75 ] Training loss: 0.100116
DEBUG:root:[ Iteration 78 ] Training loss: 0.0978699
DEBUG:root:[ Iteration 80 ] Test loss: 0.104703
DEBUG:root:[ Iteration 81 ] Training loss: 0.0952626
DEBUG:root:[ Iteration 84 ] Training loss: 0.102639
DEBUG:root:[ Iteration 87 ] Training loss: 0.0893779
DEBUG:root:[ Iteration 90 ] Training loss: 0.105738
DEBUG:root:[ Iteration 93 ] Training loss: 0.0972913
DEBUG:root:[ Iteration 96 ] Training loss: 0.0894862
DEBUG:root:[ Iteration 99 ] Training loss: 0.0896051
DEBUG:root:[ Iteration 100 ] Test loss: 0.0935939
DEBUG:root:[ Iteration 102 ] Training loss: 0.0827143
DEBUG:root:[ Iteration 105 ] Training loss: 0.100366
DEBUG:root:[ Iteration 108 ] Training loss: 0.079535
DEBUG:root:[ Iteration 111 ] Training loss: 0.075175
DEBUG:root:[ Iteration 114 ] Training loss: 0.0877624
DEBUG:root:[ Iteration 117 ] Training loss: 0.0742967
DEBUG:root:[ Iteration 120 ] Training loss: 0.0755171
DEBUG:root:[ Iteration 120 ] Test loss: 0.0667637
DEBUG:root:[ Iteration 123 ] Training loss: 0.0825844
DEBUG:root:[ Iteration 126 ] Training loss: 0.0969289
DEBUG:root:[ Iteration 129 ] Training loss: 0.0701617
DEBUG:root:[ Iteration 132 ] Training loss: 0.0688546
DEBUG:root:[ Iteration 135 ] Training loss: 0.0745622
DEBUG:root:[ Iteration 138 ] Training loss: 0.0598683
DEBUG:root:[ Iteration 140 ] Test loss: 0.0651723
DEBUG:root:[ Iteration 141 ] Training loss: 0.0606692
DEBUG:root:[ Iteration 144 ] Training loss: 0.0664224
DEBUG:root:[ Iteration 147 ] Training loss: 0.0715447
DEBUG:root:[ Iteration 150 ] Training loss: 0.0744499
DEBUG:root:[ Iteration 153 ] Training loss: 0.0639986
DEBUG:root:[ Iteration 156 ] Training loss: 0.0451133
DEBUG:root:[ Iteration 159 ] Training loss: 0.0506207
DEBUG:root:[ Iteration 160 ] Test loss: 0.062721
DEBUG:root:[ Iteration 162 ] Training loss: 0.0638353
DEBUG:root:[ Iteration 165 ] Training loss: 0.0610335
DEBUG:root:[ Iteration 168 ] Training loss: 0.0568071
DEBUG:root:[ Iteration 171 ] Training loss: 0.0704267
DEBUG:root:[ Iteration 174 ] Training loss: 0.043775
DEBUG:root:[ Iteration 177 ] Training loss: 0.0417295
DEBUG:root:[ Iteration 180 ] Training loss: 0.042915
DEBUG:root:[ Iteration 180 ] Test loss: 0.0428942
DEBUG:root:[ Iteration 183 ] Training loss: 0.0560837
DEBUG:root:[ Iteration 186 ] Training loss: 0.0503566
DEBUG:root:[ Iteration 189 ] Training loss: 0.0459234
DEBUG:root:[ Iteration 192 ] Training loss: 0.05314
DEBUG:root:[ Iteration 195 ] Training loss: 0.0452185
DEBUG:root:[ Iteration 198 ] Training loss: 0.0425732
DEBUG:root:[ Iteration 200 ] Test loss: 0.0839601
DEBUG:root:[ Iteration 201 ] Training loss: 0.0763391
DEBUG:root:[ Iteration 204 ] Training loss: 0.0604231
DEBUG:root:[ Iteration 207 ] Training loss: 0.0530354
DEBUG:root:[ Iteration 210 ] Training loss: 0.0467517
DEBUG:root:[ Iteration 213 ] Training loss: 0.0433581
DEBUG:root:[ Iteration 216 ] Training loss: 0.0398915
DEBUG:root:[ Iteration 219 ] Training loss: 0.0517148
DEBUG:root:[ Iteration 220 ] Test loss: 0.0438926
DEBUG:root:[ Iteration 222 ] Training loss: 0.0383441
DEBUG:root:[ Iteration 225 ] Training loss: 0.0487162
DEBUG:root:[ Iteration 228 ] Training loss: 0.0497184
DEBUG:root:[ Iteration 231 ] Training loss: 0.0417805
DEBUG:root:[ Iteration 234 ] Training loss: 0.0449644
DEBUG:root:[ Iteration 237 ] Training loss: 0.0511835
DEBUG:root:[ Iteration 240 ] Training loss: 0.0394007
DEBUG:root:[ Iteration 240 ] Test loss: 0.0481075
DEBUG:root:[ Iteration 243 ] Training loss: 0.038139
DEBUG:root:[ Iteration 246 ] Training loss: 0.0375517
DEBUG:root:[ Iteration 249 ] Training loss: 0.0450812
DEBUG:root:[ Iteration 252 ] Training loss: 0.0396052
DEBUG:root:[ Iteration 255 ] Training loss: 0.0338757
DEBUG:root:[ Iteration 258 ] Training loss: 0.0426878
DEBUG:root:[ Iteration 260 ] Test loss: 0.056616
DEBUG:root:[ Iteration 261 ] Training loss: 0.0349944
DEBUG:root:[ Iteration 264 ] Training loss: 0.038299
DEBUG:root:[ Iteration 267 ] Training loss: 0.030889
DEBUG:root:[ Iteration 270 ] Training loss: 0.0397262
DEBUG:root:[ Iteration 273 ] Training loss: 0.0318554
DEBUG:root:[ Iteration 276 ] Training loss: 0.0457207
DEBUG:root:[ Iteration 279 ] Training loss: 0.0421376
DEBUG:root:[ Iteration 280 ] Test loss: 0.0336539
DEBUG:root:[ Iteration 282 ] Training loss: 0.0338014
DEBUG:root:[ Iteration 285 ] Training loss: 0.0426707
DEBUG:root:[ Iteration 288 ] Training loss: 0.0363741
DEBUG:root:[ Iteration 291 ] Training loss: 0.0390086
DEBUG:root:[ Iteration 294 ] Training loss: 0.0614263
DEBUG:root:[ Iteration 297 ] Training loss: 0.0355698
DEBUG:root:[ Iteration 300 ] Training loss: 0.035104
DEBUG:root:[ Iteration 300 ] Test loss: 0.0389163
DEBUG:root:[ Iteration 303 ] Training loss: 0.0483815
DEBUG:root:[ Iteration 306 ] Training loss: 0.043076
DEBUG:root:[ Iteration 309 ] Training loss: 0.0329314
DEBUG:root:[ Iteration 312 ] Training loss: 0.0300436
DEBUG:root:[ Iteration 315 ] Training loss: 0.0332586
DEBUG:root:[ Iteration 318 ] Training loss: 0.0319651
DEBUG:root:[ Iteration 320 ] Test loss: 0.0354526
DEBUG:root:[ Iteration 321 ] Training loss: 0.0295205
DEBUG:root:[ Iteration 324 ] Training loss: 0.0333817
DEBUG:root:[ Iteration 327 ] Training loss: 0.0293077
DEBUG:root:[ Iteration 330 ] Training loss: 0.0267547
DEBUG:root:[ Iteration 333 ] Training loss: 0.0368778
DEBUG:root:[ Iteration 336 ] Training loss: 0.0315115
DEBUG:root:[ Iteration 339 ] Training loss: 0.0285326
DEBUG:root:[ Iteration 340 ] Test loss: 0.0378786
DEBUG:root:[ Iteration 342 ] Training loss: 0.043527
DEBUG:root:[ Iteration 345 ] Training loss: 0.0278618
DEBUG:root:[ Iteration 348 ] Training loss: 0.0475995
DEBUG:root:[ Iteration 351 ] Training loss: 0.0369414
DEBUG:root:[ Iteration 354 ] Training loss: 0.0362406
DEBUG:root:[ Iteration 357 ] Training loss: 0.0293231
DEBUG:root:[ Iteration 360 ] Training loss: 0.0305124
DEBUG:root:[ Iteration 360 ] Test loss: 0.0398515
DEBUG:root:[ Iteration 363 ] Training loss: 0.0261163
DEBUG:root:[ Iteration 366 ] Training loss: 0.0416178
DEBUG:root:[ Iteration 369 ] Training loss: 0.0243284
DEBUG:root:[ Iteration 372 ] Training loss: 0.0243691
DEBUG:root:[ Iteration 375 ] Training loss: 0.0241473
DEBUG:root:[ Iteration 378 ] Training loss: 0.023375
DEBUG:root:[ Iteration 380 ] Test loss: 0.0330924
DEBUG:root:[ Iteration 381 ] Training loss: 0.0381711
DEBUG:root:[ Iteration 384 ] Training loss: 0.0506214
DEBUG:root:[ Iteration 387 ] Training loss: 0.022294
DEBUG:root:[ Iteration 390 ] Training loss: 0.0285403
DEBUG:root:[ Iteration 393 ] Training loss: 0.0470634
DEBUG:root:[ Iteration 396 ] Training loss: 0.0283596
DEBUG:root:[ Iteration 399 ] Training loss: 0.0474858
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_15h46m42s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.201711
DEBUG:root:[ Iteration 0 ] Test loss: 0.210477
DEBUG:root:[ Iteration 3 ] Training loss: 0.202988
DEBUG:root:[ Iteration 6 ] Training loss: 0.202043
DEBUG:root:[ Iteration 9 ] Training loss: 0.198911
DEBUG:root:[ Iteration 12 ] Training loss: 0.19492
DEBUG:root:[ Iteration 15 ] Training loss: 0.193646
DEBUG:root:[ Iteration 18 ] Training loss: 0.20693
DEBUG:root:[ Iteration 20 ] Test loss: 0.206867
DEBUG:root:[ Iteration 21 ] Training loss: 0.200785
DEBUG:root:[ Iteration 24 ] Training loss: 0.201304
DEBUG:root:[ Iteration 27 ] Training loss: 0.187985
DEBUG:root:[ Iteration 30 ] Training loss: 0.192008
DEBUG:root:[ Iteration 33 ] Training loss: 0.195018
DEBUG:root:[ Iteration 36 ] Training loss: 0.196113
DEBUG:root:[ Iteration 39 ] Training loss: 0.195795
DEBUG:root:[ Iteration 40 ] Test loss: 0.202013
DEBUG:root:[ Iteration 42 ] Training loss: 0.194519
DEBUG:root:[ Iteration 45 ] Training loss: 0.197812
DEBUG:root:[ Iteration 48 ] Training loss: 0.188444
DEBUG:root:[ Iteration 51 ] Training loss: 0.181706
DEBUG:root:[ Iteration 54 ] Training loss: 0.184363
DEBUG:root:[ Iteration 57 ] Training loss: 0.169859
DEBUG:root:[ Iteration 60 ] Training loss: 0.17508
DEBUG:root:[ Iteration 60 ] Test loss: 0.170325
DEBUG:root:[ Iteration 63 ] Training loss: 0.15537
DEBUG:root:[ Iteration 66 ] Training loss: 0.154539
DEBUG:root:[ Iteration 69 ] Training loss: 0.149067
DEBUG:root:[ Iteration 72 ] Training loss: 0.137292
DEBUG:root:[ Iteration 75 ] Training loss: 0.137427
DEBUG:root:[ Iteration 78 ] Training loss: 0.125263
DEBUG:root:[ Iteration 80 ] Test loss: 0.138498
DEBUG:root:[ Iteration 81 ] Training loss: 0.141255
DEBUG:root:[ Iteration 84 ] Training loss: 0.133559
DEBUG:root:[ Iteration 87 ] Training loss: 0.126123
DEBUG:root:[ Iteration 90 ] Training loss: 0.126146
DEBUG:root:[ Iteration 93 ] Training loss: 0.123103
DEBUG:root:[ Iteration 96 ] Training loss: 0.119548
DEBUG:root:[ Iteration 99 ] Training loss: 0.10903
DEBUG:root:[ Iteration 100 ] Test loss: 0.114604
DEBUG:root:[ Iteration 102 ] Training loss: 0.116451
DEBUG:root:[ Iteration 105 ] Training loss: 0.143661
DEBUG:root:[ Iteration 108 ] Training loss: 0.11483
DEBUG:root:[ Iteration 111 ] Training loss: 0.101427
DEBUG:root:[ Iteration 114 ] Training loss: 0.118645
DEBUG:root:[ Iteration 117 ] Training loss: 0.0999819
DEBUG:root:[ Iteration 120 ] Training loss: 0.091281
DEBUG:root:[ Iteration 120 ] Test loss: 0.0976713
DEBUG:root:[ Iteration 123 ] Training loss: 0.10609
DEBUG:root:[ Iteration 126 ] Training loss: 0.114453
DEBUG:root:[ Iteration 129 ] Training loss: 0.0816016
DEBUG:root:[ Iteration 132 ] Training loss: 0.102253
DEBUG:root:[ Iteration 135 ] Training loss: 0.0852477
DEBUG:root:[ Iteration 138 ] Training loss: 0.0931399
DEBUG:root:[ Iteration 140 ] Test loss: 0.0969181
DEBUG:root:[ Iteration 141 ] Training loss: 0.0946802
DEBUG:root:[ Iteration 144 ] Training loss: 0.0910857
DEBUG:root:[ Iteration 147 ] Training loss: 0.0731345
DEBUG:root:[ Iteration 150 ] Training loss: 0.0770634
DEBUG:root:[ Iteration 153 ] Training loss: 0.0768498
DEBUG:root:[ Iteration 156 ] Training loss: 0.0753469
DEBUG:root:[ Iteration 159 ] Training loss: 0.0705205
DEBUG:root:[ Iteration 160 ] Test loss: 0.0691123
DEBUG:root:[ Iteration 162 ] Training loss: 0.0728493
DEBUG:root:[ Iteration 165 ] Training loss: 0.0871857
DEBUG:root:[ Iteration 168 ] Training loss: 0.0759365
DEBUG:root:[ Iteration 171 ] Training loss: 0.0677432
DEBUG:root:[ Iteration 174 ] Training loss: 0.0660356
DEBUG:root:[ Iteration 177 ] Training loss: 0.0751595
DEBUG:root:[ Iteration 180 ] Training loss: 0.0623817
DEBUG:root:[ Iteration 180 ] Test loss: 0.0627825
DEBUG:root:[ Iteration 183 ] Training loss: 0.0840933
DEBUG:root:[ Iteration 186 ] Training loss: 0.0625989
DEBUG:root:[ Iteration 189 ] Training loss: 0.118894
DEBUG:root:[ Iteration 192 ] Training loss: 0.0891257
DEBUG:root:[ Iteration 195 ] Training loss: 0.0804386
DEBUG:root:[ Iteration 198 ] Training loss: 0.0724681
DEBUG:root:[ Iteration 200 ] Test loss: 0.0857386
DEBUG:root:[ Iteration 201 ] Training loss: 0.0707201
DEBUG:root:[ Iteration 204 ] Training loss: 0.0661697
DEBUG:root:[ Iteration 207 ] Training loss: 0.0642088
DEBUG:root:[ Iteration 210 ] Training loss: 0.0646752
DEBUG:root:[ Iteration 213 ] Training loss: 0.0688783
DEBUG:root:[ Iteration 216 ] Training loss: 0.0575001
DEBUG:root:[ Iteration 219 ] Training loss: 0.0642394
DEBUG:root:[ Iteration 220 ] Test loss: 0.0643723
DEBUG:root:[ Iteration 222 ] Training loss: 0.0655245
DEBUG:root:[ Iteration 225 ] Training loss: 0.0652357
DEBUG:root:[ Iteration 228 ] Training loss: 0.0589385
DEBUG:root:[ Iteration 231 ] Training loss: 0.0657151
DEBUG:root:[ Iteration 234 ] Training loss: 0.0519709
DEBUG:root:[ Iteration 237 ] Training loss: 0.0704227
DEBUG:root:[ Iteration 240 ] Training loss: 0.059637
DEBUG:root:[ Iteration 240 ] Test loss: 0.0565528
DEBUG:root:[ Iteration 243 ] Training loss: 0.0557582
DEBUG:root:[ Iteration 246 ] Training loss: 0.0610446
DEBUG:root:[ Iteration 249 ] Training loss: 0.055294
DEBUG:root:[ Iteration 252 ] Training loss: 0.0562296
DEBUG:root:[ Iteration 255 ] Training loss: 0.057211
DEBUG:root:[ Iteration 258 ] Training loss: 0.0503253
DEBUG:root:[ Iteration 260 ] Test loss: 0.0479121
DEBUG:root:[ Iteration 261 ] Training loss: 0.0414909
DEBUG:root:[ Iteration 264 ] Training loss: 0.0505487
DEBUG:root:[ Iteration 267 ] Training loss: 0.0516273
DEBUG:root:[ Iteration 270 ] Training loss: 0.0409183
DEBUG:root:[ Iteration 273 ] Training loss: 0.0552138
DEBUG:root:[ Iteration 276 ] Training loss: 0.0350583
DEBUG:root:[ Iteration 279 ] Training loss: 0.0448417
DEBUG:root:[ Iteration 280 ] Test loss: 0.0599619
DEBUG:root:[ Iteration 282 ] Training loss: 0.0526219
DEBUG:root:[ Iteration 285 ] Training loss: 0.0488064
DEBUG:root:[ Iteration 288 ] Training loss: 0.0549471
DEBUG:root:[ Iteration 291 ] Training loss: 0.0452767
DEBUG:root:[ Iteration 294 ] Training loss: 0.0573322
DEBUG:root:[ Iteration 297 ] Training loss: 0.0537417
DEBUG:root:[ Iteration 300 ] Training loss: 0.0425738
DEBUG:root:[ Iteration 300 ] Test loss: 0.0455513
DEBUG:root:[ Iteration 303 ] Training loss: 0.0421425
DEBUG:root:[ Iteration 306 ] Training loss: 0.0411607
DEBUG:root:[ Iteration 309 ] Training loss: 0.0414235
DEBUG:root:[ Iteration 312 ] Training loss: 0.0328203
DEBUG:root:[ Iteration 315 ] Training loss: 0.0390149
DEBUG:root:[ Iteration 318 ] Training loss: 0.0724545
DEBUG:root:[ Iteration 320 ] Test loss: 0.0555598
DEBUG:root:[ Iteration 321 ] Training loss: 0.0439131
DEBUG:root:[ Iteration 324 ] Training loss: 0.0393892
DEBUG:root:[ Iteration 327 ] Training loss: 0.0497189
DEBUG:root:[ Iteration 330 ] Training loss: 0.0417493
DEBUG:root:[ Iteration 333 ] Training loss: 0.0375688
DEBUG:root:[ Iteration 336 ] Training loss: 0.0522601
DEBUG:root:[ Iteration 339 ] Training loss: 0.0553938
DEBUG:root:[ Iteration 340 ] Test loss: 0.0563117
DEBUG:root:[ Iteration 342 ] Training loss: 0.0432391
DEBUG:root:[ Iteration 345 ] Training loss: 0.0328775
DEBUG:root:[ Iteration 348 ] Training loss: 0.0487248
DEBUG:root:[ Iteration 351 ] Training loss: 0.0464698
DEBUG:root:[ Iteration 354 ] Training loss: 0.0394262
DEBUG:root:[ Iteration 357 ] Training loss: 0.0312197
DEBUG:root:[ Iteration 360 ] Training loss: 0.0402903
DEBUG:root:[ Iteration 360 ] Test loss: 0.043028
DEBUG:root:[ Iteration 363 ] Training loss: 0.0365558
DEBUG:root:[ Iteration 366 ] Training loss: 0.0405869
DEBUG:root:[ Iteration 369 ] Training loss: 0.0434401
DEBUG:root:[ Iteration 372 ] Training loss: 0.0493821
DEBUG:root:[ Iteration 375 ] Training loss: 0.039648
DEBUG:root:[ Iteration 378 ] Training loss: 0.0506792
DEBUG:root:[ Iteration 380 ] Test loss: 0.0410063
DEBUG:root:[ Iteration 381 ] Training loss: 0.038738
DEBUG:root:[ Iteration 384 ] Training loss: 0.030518
DEBUG:root:[ Iteration 387 ] Training loss: 0.0312618
DEBUG:root:[ Iteration 390 ] Training loss: 0.0420906
DEBUG:root:[ Iteration 393 ] Training loss: 0.0481888
DEBUG:root:[ Iteration 396 ] Training loss: 0.0367685
DEBUG:root:[ Iteration 399 ] Training loss: 0.035751
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_16h48m17s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.194548
DEBUG:root:[ Iteration 0 ] Test loss: 0.191219
DEBUG:root:[ Iteration 3 ] Training loss: 0.198693
DEBUG:root:[ Iteration 6 ] Training loss: 0.185266
DEBUG:root:[ Iteration 9 ] Training loss: 0.147506
DEBUG:root:[ Iteration 12 ] Training loss: 0.0792999
DEBUG:root:[ Iteration 15 ] Training loss: 0.0787701
DEBUG:root:[ Iteration 18 ] Training loss: 0.0791023
DEBUG:root:[ Iteration 20 ] Test loss: 0.0988289
DEBUG:root:[ Iteration 21 ] Training loss: 0.0666283
DEBUG:root:[ Iteration 24 ] Training loss: 0.0553296
DEBUG:root:[ Iteration 27 ] Training loss: 0.0623264
DEBUG:root:[ Iteration 30 ] Training loss: 0.0491871
DEBUG:root:[ Iteration 33 ] Training loss: 0.0271987
DEBUG:root:[ Iteration 36 ] Training loss: 0.0286156
DEBUG:root:[ Iteration 39 ] Training loss: 0.014858
DEBUG:root:[ Iteration 40 ] Test loss: 0.0185944
DEBUG:root:[ Iteration 42 ] Training loss: 0.0181703
DEBUG:root:[ Iteration 45 ] Training loss: 0.0160075
DEBUG:root:[ Iteration 48 ] Training loss: 0.0188165
DEBUG:root:[ Iteration 51 ] Training loss: 0.0164594
DEBUG:root:[ Iteration 54 ] Training loss: 0.0145969
DEBUG:root:[ Iteration 57 ] Training loss: 0.0222754
DEBUG:root:[ Iteration 60 ] Training loss: 0.0169363
DEBUG:root:[ Iteration 60 ] Test loss: 0.01578
DEBUG:root:[ Iteration 63 ] Training loss: 0.0266593
DEBUG:root:[ Iteration 66 ] Training loss: 0.0182557
DEBUG:root:[ Iteration 69 ] Training loss: 0.0267011
DEBUG:root:[ Iteration 72 ] Training loss: 0.015701
DEBUG:root:[ Iteration 75 ] Training loss: 0.0255807
DEBUG:root:[ Iteration 78 ] Training loss: 0.0237273
DEBUG:root:[ Iteration 80 ] Test loss: 0.0154273
DEBUG:root:[ Iteration 81 ] Training loss: 0.0153485
DEBUG:root:[ Iteration 84 ] Training loss: 0.0181614
DEBUG:root:[ Iteration 87 ] Training loss: 0.0146011
DEBUG:root:[ Iteration 90 ] Training loss: 0.0158869
DEBUG:root:[ Iteration 93 ] Training loss: 0.0163145
DEBUG:root:[ Iteration 96 ] Training loss: 0.0107598
DEBUG:root:[ Iteration 99 ] Training loss: 0.0121552
DEBUG:root:[ Iteration 100 ] Test loss: 0.01326
DEBUG:root:[ Iteration 102 ] Training loss: 0.0207831
DEBUG:root:[ Iteration 105 ] Training loss: 0.016146
DEBUG:root:[ Iteration 108 ] Training loss: 0.0182131
DEBUG:root:[ Iteration 111 ] Training loss: 0.0137167
DEBUG:root:[ Iteration 114 ] Training loss: 0.0174007
DEBUG:root:[ Iteration 117 ] Training loss: 0.0126748
DEBUG:root:[ Iteration 120 ] Training loss: 0.0123299
DEBUG:root:[ Iteration 120 ] Test loss: 0.0133513
DEBUG:root:[ Iteration 123 ] Training loss: 0.0127884
DEBUG:root:[ Iteration 126 ] Training loss: 0.0143514
DEBUG:root:[ Iteration 129 ] Training loss: 0.0116183
DEBUG:root:[ Iteration 132 ] Training loss: 0.0135523
DEBUG:root:[ Iteration 135 ] Training loss: 0.0129768
DEBUG:root:[ Iteration 138 ] Training loss: 0.0215555
DEBUG:root:[ Iteration 140 ] Test loss: 0.0131289
DEBUG:root:[ Iteration 141 ] Training loss: 0.011318
DEBUG:root:[ Iteration 144 ] Training loss: 0.0187438
DEBUG:root:[ Iteration 147 ] Training loss: 0.0197201
DEBUG:root:[ Iteration 150 ] Training loss: 0.0179756
DEBUG:root:[ Iteration 153 ] Training loss: 0.0149551
DEBUG:root:[ Iteration 156 ] Training loss: 0.0139747
DEBUG:root:[ Iteration 159 ] Training loss: 0.0171677
DEBUG:root:[ Iteration 160 ] Test loss: 0.0109679
DEBUG:root:[ Iteration 162 ] Training loss: 0.0240138
DEBUG:root:[ Iteration 165 ] Training loss: 0.0149382
DEBUG:root:[ Iteration 168 ] Training loss: 0.0126144
DEBUG:root:[ Iteration 171 ] Training loss: 0.0078674
DEBUG:root:[ Iteration 174 ] Training loss: 0.0188779
DEBUG:root:[ Iteration 177 ] Training loss: 0.0220754
DEBUG:root:[ Iteration 180 ] Training loss: 0.0185571
DEBUG:root:[ Iteration 180 ] Test loss: 0.00996216
DEBUG:root:[ Iteration 183 ] Training loss: 0.0159153
DEBUG:root:[ Iteration 186 ] Training loss: 0.012153
DEBUG:root:[ Iteration 189 ] Training loss: 0.0121321
DEBUG:root:[ Iteration 192 ] Training loss: 0.011941
DEBUG:root:[ Iteration 195 ] Training loss: 0.0182423
DEBUG:root:[ Iteration 198 ] Training loss: 0.0198039
DEBUG:root:[ Iteration 200 ] Test loss: 0.0108307
DEBUG:root:[ Iteration 201 ] Training loss: 0.0105742
DEBUG:root:[ Iteration 204 ] Training loss: 0.0106978
DEBUG:root:[ Iteration 207 ] Training loss: 0.0140594
DEBUG:root:[ Iteration 210 ] Training loss: 0.0175382
DEBUG:root:[ Iteration 213 ] Training loss: 0.0232486
DEBUG:root:[ Iteration 216 ] Training loss: 0.016909
DEBUG:root:[ Iteration 219 ] Training loss: 0.0137165
DEBUG:root:[ Iteration 220 ] Test loss: 0.0109072
DEBUG:root:[ Iteration 222 ] Training loss: 0.0175097
DEBUG:root:[ Iteration 225 ] Training loss: 0.0112943
DEBUG:root:[ Iteration 228 ] Training loss: 0.018787
DEBUG:root:[ Iteration 231 ] Training loss: 0.0168758
DEBUG:root:[ Iteration 234 ] Training loss: 0.0180563
DEBUG:root:[ Iteration 237 ] Training loss: 0.00899041
DEBUG:root:[ Iteration 240 ] Training loss: 0.0112116
DEBUG:root:[ Iteration 240 ] Test loss: 0.0112697
DEBUG:root:[ Iteration 243 ] Training loss: 0.0167128
DEBUG:root:[ Iteration 246 ] Training loss: 0.0144255
DEBUG:root:[ Iteration 249 ] Training loss: 0.020028
DEBUG:root:[ Iteration 252 ] Training loss: 0.0186125
DEBUG:root:[ Iteration 255 ] Training loss: 0.0117334
DEBUG:root:[ Iteration 258 ] Training loss: 0.0103722
DEBUG:root:[ Iteration 260 ] Test loss: 0.00954203
DEBUG:root:[ Iteration 261 ] Training loss: 0.00871187
DEBUG:root:[ Iteration 264 ] Training loss: 0.00738943
DEBUG:root:[ Iteration 267 ] Training loss: 0.0119953
DEBUG:root:[ Iteration 270 ] Training loss: 0.014663
DEBUG:root:[ Iteration 273 ] Training loss: 0.0186092
DEBUG:root:[ Iteration 276 ] Training loss: 0.0154215
DEBUG:root:[ Iteration 279 ] Training loss: 0.0161307
DEBUG:root:[ Iteration 280 ] Test loss: 0.0102404
DEBUG:root:[ Iteration 282 ] Training loss: 0.0185656
DEBUG:root:[ Iteration 285 ] Training loss: 0.010541
DEBUG:root:[ Iteration 288 ] Training loss: 0.0220414
DEBUG:root:[ Iteration 291 ] Training loss: 0.00834192
DEBUG:root:[ Iteration 294 ] Training loss: 0.0101233
DEBUG:root:[ Iteration 297 ] Training loss: 0.0135557
DEBUG:root:[ Iteration 300 ] Training loss: 0.00967682
DEBUG:root:[ Iteration 300 ] Test loss: 0.0100835
DEBUG:root:[ Iteration 303 ] Training loss: 0.0230327
DEBUG:root:[ Iteration 306 ] Training loss: 0.0091151
DEBUG:root:[ Iteration 309 ] Training loss: 0.00905906
DEBUG:root:[ Iteration 312 ] Training loss: 0.0165809
DEBUG:root:[ Iteration 315 ] Training loss: 0.0107888
DEBUG:root:[ Iteration 318 ] Training loss: 0.0170689
DEBUG:root:[ Iteration 320 ] Test loss: 0.00793933
DEBUG:root:[ Iteration 321 ] Training loss: 0.0109428
DEBUG:root:[ Iteration 324 ] Training loss: 0.0135083
DEBUG:root:[ Iteration 327 ] Training loss: 0.0102856
DEBUG:root:[ Iteration 330 ] Training loss: 0.0130349
DEBUG:root:[ Iteration 333 ] Training loss: 0.00984279
DEBUG:root:[ Iteration 336 ] Training loss: 0.0119514
DEBUG:root:[ Iteration 339 ] Training loss: 0.0180064
DEBUG:root:[ Iteration 340 ] Test loss: 0.00756764
DEBUG:root:[ Iteration 342 ] Training loss: 0.00890479
DEBUG:root:[ Iteration 345 ] Training loss: 0.0248381
DEBUG:root:[ Iteration 348 ] Training loss: 0.0151633
DEBUG:root:[ Iteration 351 ] Training loss: 0.0138169
DEBUG:root:[ Iteration 354 ] Training loss: 0.0216012
DEBUG:root:[ Iteration 357 ] Training loss: 0.0114478
DEBUG:root:[ Iteration 360 ] Training loss: 0.0119185
DEBUG:root:[ Iteration 360 ] Test loss: 0.00861058
DEBUG:root:[ Iteration 363 ] Training loss: 0.0145627
DEBUG:root:[ Iteration 366 ] Training loss: 0.0106234
DEBUG:root:[ Iteration 369 ] Training loss: 0.0105167
DEBUG:root:[ Iteration 372 ] Training loss: 0.016763
DEBUG:root:[ Iteration 375 ] Training loss: 0.0135297
DEBUG:root:[ Iteration 378 ] Training loss: 0.0128656
DEBUG:root:[ Iteration 380 ] Test loss: 0.0107573
DEBUG:root:[ Iteration 381 ] Training loss: 0.0157031
DEBUG:root:[ Iteration 384 ] Training loss: 0.0165336
DEBUG:root:[ Iteration 387 ] Training loss: 0.00896606
DEBUG:root:[ Iteration 390 ] Training loss: 0.0128048
DEBUG:root:[ Iteration 393 ] Training loss: 0.0177763
DEBUG:root:[ Iteration 396 ] Training loss: 0.00612192
DEBUG:root:[ Iteration 399 ] Training loss: 0.0143004
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_20h21m24s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.202612
DEBUG:root:[ Iteration 0 ] Test loss: 0.208904
DEBUG:root:[ Iteration 3 ] Training loss: 0.201331
DEBUG:root:[ Iteration 6 ] Training loss: 0.205022
DEBUG:root:[ Iteration 9 ] Training loss: 0.197436
DEBUG:root:[ Iteration 12 ] Training loss: 0.188115
DEBUG:root:[ Iteration 15 ] Training loss: 0.171405
DEBUG:root:[ Iteration 18 ] Training loss: 0.109112
DEBUG:root:[ Iteration 20 ] Test loss: 0.0917018
DEBUG:root:[ Iteration 21 ] Training loss: 0.0876005
DEBUG:root:[ Iteration 24 ] Training loss: 0.0934591
DEBUG:root:[ Iteration 27 ] Training loss: 0.0822135
DEBUG:root:[ Iteration 30 ] Training loss: 0.0926749
DEBUG:root:[ Iteration 33 ] Training loss: 0.0789554
DEBUG:root:[ Iteration 36 ] Training loss: 0.0736932
DEBUG:root:[ Iteration 39 ] Training loss: 0.0738806
DEBUG:root:[ Iteration 40 ] Test loss: 0.0773752
DEBUG:root:[ Iteration 42 ] Training loss: 0.0582026
DEBUG:root:[ Iteration 45 ] Training loss: 0.0564284
DEBUG:root:[ Iteration 48 ] Training loss: 0.0481362
DEBUG:root:[ Iteration 51 ] Training loss: 0.0385153
DEBUG:root:[ Iteration 54 ] Training loss: 0.0365079
DEBUG:root:[ Iteration 57 ] Training loss: 0.0214526
DEBUG:root:[ Iteration 60 ] Training loss: 0.0299146
DEBUG:root:[ Iteration 60 ] Test loss: 0.033698
DEBUG:root:[ Iteration 63 ] Training loss: 0.0252784
DEBUG:root:[ Iteration 66 ] Training loss: 0.0264801
DEBUG:root:[ Iteration 69 ] Training loss: 0.0244833
DEBUG:root:[ Iteration 72 ] Training loss: 0.0219651
DEBUG:root:[ Iteration 75 ] Training loss: 0.0256365
DEBUG:root:[ Iteration 78 ] Training loss: 0.0229566
DEBUG:root:[ Iteration 80 ] Test loss: 0.0248035
DEBUG:root:[ Iteration 81 ] Training loss: 0.0225689
DEBUG:root:[ Iteration 84 ] Training loss: 0.029154
DEBUG:root:[ Iteration 87 ] Training loss: 0.0169549
DEBUG:root:[ Iteration 90 ] Training loss: 0.0202535
DEBUG:root:[ Iteration 93 ] Training loss: 0.0188586
DEBUG:root:[ Iteration 96 ] Training loss: 0.0274502
DEBUG:root:[ Iteration 99 ] Training loss: 0.0202567
DEBUG:root:[ Iteration 100 ] Test loss: 0.0230728
DEBUG:root:[ Iteration 102 ] Training loss: 0.0155247
DEBUG:root:[ Iteration 105 ] Training loss: 0.018736
DEBUG:root:[ Iteration 108 ] Training loss: 0.01962
DEBUG:root:[ Iteration 111 ] Training loss: 0.0239073
DEBUG:root:[ Iteration 114 ] Training loss: 0.019216
DEBUG:root:[ Iteration 117 ] Training loss: 0.0173426
DEBUG:root:[ Iteration 120 ] Training loss: 0.0160223
DEBUG:root:[ Iteration 120 ] Test loss: 0.0264393
DEBUG:root:[ Iteration 123 ] Training loss: 0.0167141
DEBUG:root:[ Iteration 126 ] Training loss: 0.0211228
DEBUG:root:[ Iteration 129 ] Training loss: 0.0206329
DEBUG:root:[ Iteration 132 ] Training loss: 0.013882
DEBUG:root:[ Iteration 135 ] Training loss: 0.0188117
DEBUG:root:[ Iteration 138 ] Training loss: 0.0211044
DEBUG:root:[ Iteration 140 ] Test loss: 0.0119749
DEBUG:root:[ Iteration 141 ] Training loss: 0.0176434
DEBUG:root:[ Iteration 144 ] Training loss: 0.0143259
DEBUG:root:[ Iteration 147 ] Training loss: 0.0239853
DEBUG:root:[ Iteration 150 ] Training loss: 0.0201217
DEBUG:root:[ Iteration 153 ] Training loss: 0.0188115
DEBUG:root:[ Iteration 156 ] Training loss: 0.0151602
DEBUG:root:[ Iteration 159 ] Training loss: 0.0185245
DEBUG:root:[ Iteration 160 ] Test loss: 0.0190761
DEBUG:root:[ Iteration 162 ] Training loss: 0.016307
DEBUG:root:[ Iteration 165 ] Training loss: 0.0113161
DEBUG:root:[ Iteration 168 ] Training loss: 0.0159761
DEBUG:root:[ Iteration 171 ] Training loss: 0.0130001
DEBUG:root:[ Iteration 174 ] Training loss: 0.016204
DEBUG:root:[ Iteration 177 ] Training loss: 0.0211806
DEBUG:root:[ Iteration 180 ] Training loss: 0.0187614
DEBUG:root:[ Iteration 180 ] Test loss: 0.0191447
DEBUG:root:[ Iteration 183 ] Training loss: 0.0157355
DEBUG:root:[ Iteration 186 ] Training loss: 0.0193897
DEBUG:root:[ Iteration 189 ] Training loss: 0.0205728
DEBUG:root:[ Iteration 192 ] Training loss: 0.0161837
DEBUG:root:[ Iteration 195 ] Training loss: 0.0154083
DEBUG:root:[ Iteration 198 ] Training loss: 0.0150743
DEBUG:root:[ Iteration 200 ] Test loss: 0.0183422
DEBUG:root:[ Iteration 201 ] Training loss: 0.0179124
DEBUG:root:[ Iteration 204 ] Training loss: 0.0117886
DEBUG:root:[ Iteration 207 ] Training loss: 0.0190515
DEBUG:root:[ Iteration 210 ] Training loss: 0.0164606
DEBUG:root:[ Iteration 213 ] Training loss: 0.012129
DEBUG:root:[ Iteration 216 ] Training loss: 0.0132912
DEBUG:root:[ Iteration 219 ] Training loss: 0.017047
DEBUG:root:[ Iteration 220 ] Test loss: 0.0192333
DEBUG:root:[ Iteration 222 ] Training loss: 0.0128282
DEBUG:root:[ Iteration 225 ] Training loss: 0.0155044
DEBUG:root:[ Iteration 228 ] Training loss: 0.0150154
DEBUG:root:[ Iteration 231 ] Training loss: 0.0153697
DEBUG:root:[ Iteration 234 ] Training loss: 0.0126473
DEBUG:root:[ Iteration 237 ] Training loss: 0.0192745
DEBUG:root:[ Iteration 240 ] Training loss: 0.0185639
DEBUG:root:[ Iteration 240 ] Test loss: 0.0180829
DEBUG:root:[ Iteration 243 ] Training loss: 0.0138864
DEBUG:root:[ Iteration 246 ] Training loss: 0.0172436
DEBUG:root:[ Iteration 249 ] Training loss: 0.0125619
DEBUG:root:[ Iteration 252 ] Training loss: 0.0121636
DEBUG:root:[ Iteration 255 ] Training loss: 0.0156268
DEBUG:root:[ Iteration 258 ] Training loss: 0.0167705
DEBUG:root:[ Iteration 260 ] Test loss: 0.0203802
DEBUG:root:[ Iteration 261 ] Training loss: 0.0118997
DEBUG:root:[ Iteration 264 ] Training loss: 0.011895
DEBUG:root:[ Iteration 267 ] Training loss: 0.0136751
DEBUG:root:[ Iteration 270 ] Training loss: 0.0193755
DEBUG:root:[ Iteration 273 ] Training loss: 0.0119005
DEBUG:root:[ Iteration 276 ] Training loss: 0.0146461
DEBUG:root:[ Iteration 279 ] Training loss: 0.0133193
DEBUG:root:[ Iteration 280 ] Test loss: 0.0145971
DEBUG:root:[ Iteration 282 ] Training loss: 0.0154304
DEBUG:root:[ Iteration 285 ] Training loss: 0.0142789
DEBUG:root:[ Iteration 288 ] Training loss: 0.00949879
DEBUG:root:[ Iteration 291 ] Training loss: 0.00911565
DEBUG:root:[ Iteration 294 ] Training loss: 0.0205491
DEBUG:root:[ Iteration 297 ] Training loss: 0.0170138
DEBUG:root:[ Iteration 300 ] Training loss: 0.0136273
DEBUG:root:[ Iteration 300 ] Test loss: 0.0194128
DEBUG:root:[ Iteration 303 ] Training loss: 0.0144831
DEBUG:root:[ Iteration 306 ] Training loss: 0.0139763
DEBUG:root:[ Iteration 309 ] Training loss: 0.0155927
DEBUG:root:[ Iteration 312 ] Training loss: 0.0132559
DEBUG:root:[ Iteration 315 ] Training loss: 0.0104686
DEBUG:root:[ Iteration 318 ] Training loss: 0.0125706
DEBUG:root:[ Iteration 320 ] Test loss: 0.0207816
DEBUG:root:[ Iteration 321 ] Training loss: 0.006639
DEBUG:root:[ Iteration 324 ] Training loss: 0.0184548
DEBUG:root:[ Iteration 327 ] Training loss: 0.0100464
DEBUG:root:[ Iteration 330 ] Training loss: 0.0123209
DEBUG:root:[ Iteration 333 ] Training loss: 0.011821
DEBUG:root:[ Iteration 336 ] Training loss: 0.00955322
DEBUG:root:[ Iteration 339 ] Training loss: 0.0157388
DEBUG:root:[ Iteration 340 ] Test loss: 0.0131982
DEBUG:root:[ Iteration 342 ] Training loss: 0.00930443
DEBUG:root:[ Iteration 345 ] Training loss: 0.0119892
DEBUG:root:[ Iteration 348 ] Training loss: 0.016189
DEBUG:root:[ Iteration 351 ] Training loss: 0.00952057
DEBUG:root:[ Iteration 354 ] Training loss: 0.01041
DEBUG:root:[ Iteration 357 ] Training loss: 0.0158596
DEBUG:root:[ Iteration 360 ] Training loss: 0.010374
DEBUG:root:[ Iteration 360 ] Test loss: 0.0166341
DEBUG:root:[ Iteration 363 ] Training loss: 0.00903948
DEBUG:root:[ Iteration 366 ] Training loss: 0.0103266
DEBUG:root:[ Iteration 369 ] Training loss: 0.00903206
DEBUG:root:[ Iteration 372 ] Training loss: 0.0118154
DEBUG:root:[ Iteration 375 ] Training loss: 0.00934279
DEBUG:root:[ Iteration 378 ] Training loss: 0.0125358
DEBUG:root:[ Iteration 380 ] Test loss: 0.018559
DEBUG:root:[ Iteration 381 ] Training loss: 0.0060791
DEBUG:root:[ Iteration 384 ] Training loss: 0.0129177
DEBUG:root:[ Iteration 387 ] Training loss: 0.011238
DEBUG:root:[ Iteration 390 ] Training loss: 0.013587
DEBUG:root:[ Iteration 393 ] Training loss: 0.0128109
DEBUG:root:[ Iteration 396 ] Training loss: 0.0100334
DEBUG:root:[ Iteration 399 ] Training loss: 0.00988074
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_02-29-2016_22h44m24s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.0277549
DEBUG:root:[ Iteration 0 ] Test loss: 0.0310382
DEBUG:root:[ Iteration 3 ] Training loss: 0.031047
DEBUG:root:[ Iteration 6 ] Training loss: 0.0388238
DEBUG:root:[ Iteration 9 ] Training loss: 0.0291432
DEBUG:root:[ Iteration 12 ] Training loss: 0.027131
DEBUG:root:[ Iteration 15 ] Training loss: 0.0235835
DEBUG:root:[ Iteration 18 ] Training loss: 0.0220996
DEBUG:root:[ Iteration 20 ] Test loss: 0.0291044
DEBUG:root:[ Iteration 21 ] Training loss: 0.0216921
DEBUG:root:[ Iteration 24 ] Training loss: 0.0214234
DEBUG:root:[ Iteration 27 ] Training loss: 0.0275471
DEBUG:root:[ Iteration 30 ] Training loss: 0.0260739
DEBUG:root:[ Iteration 33 ] Training loss: 0.0254738
DEBUG:root:[ Iteration 36 ] Training loss: 0.0211983
DEBUG:root:[ Iteration 39 ] Training loss: 0.0203974
DEBUG:root:[ Iteration 40 ] Test loss: 0.0169305
DEBUG:root:[ Iteration 42 ] Training loss: 0.0216796
DEBUG:root:[ Iteration 45 ] Training loss: 0.0153242
DEBUG:root:[ Iteration 48 ] Training loss: 0.0172449
DEBUG:root:[ Iteration 51 ] Training loss: 0.0211795
DEBUG:root:[ Iteration 54 ] Training loss: 0.0188337
DEBUG:root:[ Iteration 57 ] Training loss: 0.0146129
DEBUG:root:[ Iteration 60 ] Training loss: 0.018164
DEBUG:root:[ Iteration 60 ] Test loss: 0.0155066
DEBUG:root:[ Iteration 63 ] Training loss: 0.0135167
DEBUG:root:[ Iteration 66 ] Training loss: 0.0128455
DEBUG:root:[ Iteration 69 ] Training loss: 0.015444
DEBUG:root:[ Iteration 72 ] Training loss: 0.015097
DEBUG:root:[ Iteration 75 ] Training loss: 0.0182066
DEBUG:root:[ Iteration 78 ] Training loss: 0.0215388
DEBUG:root:[ Iteration 80 ] Test loss: 0.0228344
DEBUG:root:[ Iteration 81 ] Training loss: 0.0223152
DEBUG:root:[ Iteration 84 ] Training loss: 0.0183027
DEBUG:root:[ Iteration 87 ] Training loss: 0.0181801
DEBUG:root:[ Iteration 90 ] Training loss: 0.0165192
DEBUG:root:[ Iteration 93 ] Training loss: 0.0223098
DEBUG:root:[ Iteration 96 ] Training loss: 0.0200102
DEBUG:root:[ Iteration 99 ] Training loss: 0.0174235
DEBUG:root:[ Iteration 100 ] Test loss: 0.0160481
DEBUG:root:[ Iteration 102 ] Training loss: 0.0147238
DEBUG:root:[ Iteration 105 ] Training loss: 0.0189913
DEBUG:root:[ Iteration 108 ] Training loss: 0.0150641
DEBUG:root:[ Iteration 111 ] Training loss: 0.0149814
DEBUG:root:[ Iteration 114 ] Training loss: 0.0171861
DEBUG:root:[ Iteration 117 ] Training loss: 0.0164016
DEBUG:root:[ Iteration 120 ] Training loss: 0.0128889
DEBUG:root:[ Iteration 120 ] Test loss: 0.0143086
DEBUG:root:[ Iteration 123 ] Training loss: 0.0135842
DEBUG:root:[ Iteration 126 ] Training loss: 0.0158153
DEBUG:root:[ Iteration 129 ] Training loss: 0.00979272
DEBUG:root:[ Iteration 132 ] Training loss: 0.0194674
DEBUG:root:[ Iteration 135 ] Training loss: 0.0122633
DEBUG:root:[ Iteration 138 ] Training loss: 0.0172201
DEBUG:root:[ Iteration 140 ] Test loss: 0.0189467
DEBUG:root:[ Iteration 141 ] Training loss: 0.0142086
DEBUG:root:[ Iteration 144 ] Training loss: 0.0189882
DEBUG:root:[ Iteration 147 ] Training loss: 0.0130775
DEBUG:root:Saving...
DEBUG:root:Saved model to /media/1tb/Izzy/nets/net6_03-01-2016_00h20m12s.ckpt
DEBUG:root:Optimization done.
