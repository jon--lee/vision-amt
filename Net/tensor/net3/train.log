DEBUG:root:[ Iteration 0 ] Training loss: 0.436584
DEBUG:root:[ Iteration 0 ] Test loss: 0.439716
DEBUG:root:[ Iteration 3 ] Training loss: 0.423576
DEBUG:root:[ Iteration 6 ] Training loss: 0.409045
DEBUG:root:[ Iteration 9 ] Training loss: 0.422921
DEBUG:root:[ Iteration 12 ] Training loss: 0.41143
DEBUG:root:[ Iteration 15 ] Training loss: 0.391924
DEBUG:root:[ Iteration 18 ] Training loss: 0.396995
DEBUG:root:[ Iteration 20 ] Test loss: 0.390483
DEBUG:root:[ Iteration 21 ] Training loss: 0.39023
DEBUG:root:[ Iteration 24 ] Training loss: 0.377133
DEBUG:root:[ Iteration 27 ] Training loss: 0.366963
DEBUG:root:[ Iteration 30 ] Training loss: 0.36154
DEBUG:root:[ Iteration 33 ] Training loss: 0.354497
DEBUG:root:[ Iteration 36 ] Training loss: 0.345153
DEBUG:root:[ Iteration 39 ] Training loss: 0.333619
DEBUG:root:[ Iteration 40 ] Test loss: 0.348584
DEBUG:root:[ Iteration 42 ] Training loss: 0.332496
DEBUG:root:[ Iteration 45 ] Training loss: 0.315317
DEBUG:root:[ Iteration 48 ] Training loss: 0.318497
DEBUG:root:[ Iteration 51 ] Training loss: 0.304773
DEBUG:root:[ Iteration 54 ] Training loss: 0.29078
DEBUG:root:[ Iteration 57 ] Training loss: 0.288141
DEBUG:root:[ Iteration 60 ] Training loss: 0.281789
DEBUG:root:[ Iteration 60 ] Test loss: 0.293119
DEBUG:root:[ Iteration 63 ] Training loss: 0.26966
DEBUG:root:[ Iteration 66 ] Training loss: 0.25466
DEBUG:root:[ Iteration 69 ] Training loss: 0.251499
DEBUG:root:[ Iteration 72 ] Training loss: 0.242062
DEBUG:root:[ Iteration 75 ] Training loss: 0.221518
DEBUG:root:[ Iteration 78 ] Training loss: 0.209392
DEBUG:root:[ Iteration 80 ] Test loss: 0.239221
DEBUG:root:[ Iteration 81 ] Training loss: 0.216882
DEBUG:root:[ Iteration 84 ] Training loss: 0.206815
DEBUG:root:[ Iteration 87 ] Training loss: 0.196987
DEBUG:root:[ Iteration 90 ] Training loss: 0.207476
DEBUG:root:[ Iteration 93 ] Training loss: 0.1855
DEBUG:root:[ Iteration 96 ] Training loss: 0.180792
DEBUG:root:[ Iteration 99 ] Training loss: 0.166032
DEBUG:root:[ Iteration 100 ] Test loss: 0.189628
DEBUG:root:[ Iteration 102 ] Training loss: 0.155739
DEBUG:root:[ Iteration 105 ] Training loss: 0.161371
DEBUG:root:[ Iteration 108 ] Training loss: 0.148878
DEBUG:root:[ Iteration 111 ] Training loss: 0.13606
DEBUG:root:[ Iteration 114 ] Training loss: 0.135496
DEBUG:root:[ Iteration 117 ] Training loss: 0.12757
DEBUG:root:[ Iteration 120 ] Training loss: 0.117196
DEBUG:root:[ Iteration 120 ] Test loss: 0.138719
DEBUG:root:[ Iteration 123 ] Training loss: 0.121648
DEBUG:root:[ Iteration 126 ] Training loss: 0.103193
DEBUG:root:[ Iteration 129 ] Training loss: 0.0978736
DEBUG:root:[ Iteration 132 ] Training loss: 0.10315
DEBUG:root:[ Iteration 135 ] Training loss: 0.0934386
DEBUG:root:[ Iteration 138 ] Training loss: 0.0893167
DEBUG:root:[ Iteration 140 ] Test loss: 0.0985935
DEBUG:root:[ Iteration 141 ] Training loss: 0.0758788
DEBUG:root:[ Iteration 144 ] Training loss: 0.0753532
DEBUG:root:[ Iteration 147 ] Training loss: 0.076852
DEBUG:root:[ Iteration 150 ] Training loss: 0.0694103
DEBUG:root:[ Iteration 153 ] Training loss: 0.0634677
DEBUG:root:[ Iteration 156 ] Training loss: 0.0618667
DEBUG:root:[ Iteration 159 ] Training loss: 0.0596804
DEBUG:root:[ Iteration 160 ] Test loss: 0.0706007
DEBUG:root:[ Iteration 162 ] Training loss: 0.0539207
DEBUG:root:[ Iteration 165 ] Training loss: 0.0480666
DEBUG:root:[ Iteration 168 ] Training loss: 0.0488122
DEBUG:root:[ Iteration 171 ] Training loss: 0.044785
DEBUG:root:[ Iteration 174 ] Training loss: 0.0405363
DEBUG:root:[ Iteration 177 ] Training loss: 0.0399981
DEBUG:root:[ Iteration 180 ] Training loss: 0.0414103
DEBUG:root:[ Iteration 180 ] Test loss: 0.0505808
DEBUG:root:[ Iteration 183 ] Training loss: 0.0378838
DEBUG:root:[ Iteration 186 ] Training loss: 0.0373547
DEBUG:root:[ Iteration 189 ] Training loss: 0.0317216
DEBUG:root:[ Iteration 192 ] Training loss: 0.0302991
DEBUG:root:[ Iteration 195 ] Training loss: 0.0329977
DEBUG:root:[ Iteration 198 ] Training loss: 0.0291039
DEBUG:root:[ Iteration 200 ] Test loss: 0.0363385
DEBUG:root:[ Iteration 201 ] Training loss: 0.0267641
DEBUG:root:[ Iteration 204 ] Training loss: 0.027236
DEBUG:root:[ Iteration 207 ] Training loss: 0.0228031
DEBUG:root:[ Iteration 210 ] Training loss: 0.0259711
DEBUG:root:[ Iteration 213 ] Training loss: 0.0224833
DEBUG:root:[ Iteration 216 ] Training loss: 0.0204946
DEBUG:root:[ Iteration 219 ] Training loss: 0.0205175
DEBUG:root:[ Iteration 220 ] Test loss: 0.027124
DEBUG:root:[ Iteration 222 ] Training loss: 0.0190157
DEBUG:root:[ Iteration 225 ] Training loss: 0.0190022
DEBUG:root:[ Iteration 228 ] Training loss: 0.0162988
DEBUG:root:[ Iteration 231 ] Training loss: 0.0160388
DEBUG:root:[ Iteration 234 ] Training loss: 0.0166204
DEBUG:root:[ Iteration 237 ] Training loss: 0.0146732
DEBUG:root:[ Iteration 240 ] Training loss: 0.0154028
DEBUG:root:[ Iteration 240 ] Test loss: 0.0197161
DEBUG:root:[ Iteration 243 ] Training loss: 0.0136799
DEBUG:root:[ Iteration 246 ] Training loss: 0.0116617
DEBUG:root:[ Iteration 249 ] Training loss: 0.0109677
DEBUG:root:[ Iteration 252 ] Training loss: 0.0118337
DEBUG:root:[ Iteration 255 ] Training loss: 0.0120782
DEBUG:root:[ Iteration 258 ] Training loss: 0.0107957
DEBUG:root:[ Iteration 260 ] Test loss: 0.0148991
DEBUG:root:[ Iteration 261 ] Training loss: 0.0104767
DEBUG:root:[ Iteration 264 ] Training loss: 0.0100925
DEBUG:root:[ Iteration 267 ] Training loss: 0.0102028
DEBUG:root:[ Iteration 270 ] Training loss: 0.00977484
DEBUG:root:[ Iteration 273 ] Training loss: 0.0096379
DEBUG:root:[ Iteration 276 ] Training loss: 0.00929133
DEBUG:root:[ Iteration 279 ] Training loss: 0.0090761
DEBUG:root:[ Iteration 280 ] Test loss: 0.011654
DEBUG:root:[ Iteration 282 ] Training loss: 0.00787884
DEBUG:root:[ Iteration 285 ] Training loss: 0.00876428
DEBUG:root:[ Iteration 288 ] Training loss: 0.00827659
DEBUG:root:[ Iteration 291 ] Training loss: 0.00693471
DEBUG:root:[ Iteration 294 ] Training loss: 0.00693963
DEBUG:root:[ Iteration 297 ] Training loss: 0.00654653
DEBUG:root:[ Iteration 300 ] Training loss: 0.00652869
DEBUG:root:[ Iteration 300 ] Test loss: 0.00893754
DEBUG:root:[ Iteration 303 ] Training loss: 0.00566833
DEBUG:root:[ Iteration 306 ] Training loss: 0.00616855
DEBUG:root:[ Iteration 309 ] Training loss: 0.00672326
DEBUG:root:[ Iteration 312 ] Training loss: 0.00589464
DEBUG:root:[ Iteration 315 ] Training loss: 0.00546642
DEBUG:root:[ Iteration 318 ] Training loss: 0.00480614
DEBUG:root:[ Iteration 320 ] Test loss: 0.00712607
DEBUG:root:[ Iteration 321 ] Training loss: 0.0053711
DEBUG:root:[ Iteration 324 ] Training loss: 0.00546821
DEBUG:root:[ Iteration 327 ] Training loss: 0.00520596
DEBUG:root:[ Iteration 330 ] Training loss: 0.00490139
DEBUG:root:[ Iteration 333 ] Training loss: 0.00457937
DEBUG:root:[ Iteration 336 ] Training loss: 0.00437915
DEBUG:root:[ Iteration 339 ] Training loss: 0.00415237
DEBUG:root:[ Iteration 340 ] Test loss: 0.00607118
DEBUG:root:[ Iteration 342 ] Training loss: 0.00399492
DEBUG:root:[ Iteration 345 ] Training loss: 0.00423234
DEBUG:root:[ Iteration 348 ] Training loss: 0.00428724
DEBUG:root:[ Iteration 351 ] Training loss: 0.00351027
DEBUG:root:[ Iteration 354 ] Training loss: 0.00362214
DEBUG:root:[ Iteration 357 ] Training loss: 0.00311908
DEBUG:root:[ Iteration 360 ] Training loss: 0.00393865
DEBUG:root:[ Iteration 360 ] Test loss: 0.00484928
DEBUG:root:[ Iteration 363 ] Training loss: 0.00360765
DEBUG:root:[ Iteration 366 ] Training loss: 0.00297758
DEBUG:root:[ Iteration 369 ] Training loss: 0.00305217
DEBUG:root:[ Iteration 372 ] Training loss: 0.00304979
DEBUG:root:[ Iteration 375 ] Training loss: 0.00276062
DEBUG:root:[ Iteration 378 ] Training loss: 0.00265483
DEBUG:root:[ Iteration 380 ] Test loss: 0.00390468
DEBUG:root:[ Iteration 381 ] Training loss: 0.00322893
DEBUG:root:[ Iteration 384 ] Training loss: 0.00267521
DEBUG:root:[ Iteration 387 ] Training loss: 0.00302912
DEBUG:root:[ Iteration 390 ] Training loss: 0.00248646
DEBUG:root:[ Iteration 393 ] Training loss: 0.00281338
DEBUG:root:[ Iteration 396 ] Training loss: 0.0023939
DEBUG:root:[ Iteration 399 ] Training loss: 0.0022899
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.465026
DEBUG:root:[ Iteration 0 ] Test loss: 0.469438
DEBUG:root:[ Iteration 3 ] Training loss: 0.459914
DEBUG:root:[ Iteration 6 ] Training loss: 0.468668
DEBUG:root:[ Iteration 9 ] Training loss: 0.454795
DEBUG:root:[ Iteration 12 ] Training loss: 0.454121
DEBUG:root:[ Iteration 15 ] Training loss: 0.459949
DEBUG:root:[ Iteration 18 ] Training loss: 0.448759
DEBUG:root:[ Iteration 20 ] Test loss: 0.464181
DEBUG:root:[ Iteration 21 ] Training loss: 0.456997
DEBUG:root:[ Iteration 24 ] Training loss: 0.454466
DEBUG:root:[ Iteration 27 ] Training loss: 0.45048
DEBUG:root:[ Iteration 30 ] Training loss: 0.454426
DEBUG:root:[ Iteration 33 ] Training loss: 0.43417
DEBUG:root:[ Iteration 36 ] Training loss: 0.451701
DEBUG:root:[ Iteration 39 ] Training loss: 0.443823
DEBUG:root:[ Iteration 40 ] Test loss: 0.449516
DEBUG:root:[ Iteration 42 ] Training loss: 0.440032
DEBUG:root:[ Iteration 45 ] Training loss: 0.429212
DEBUG:root:[ Iteration 48 ] Training loss: 0.439039
DEBUG:root:[ Iteration 51 ] Training loss: 0.452694
DEBUG:root:[ Iteration 54 ] Training loss: 0.421078
DEBUG:root:[ Iteration 57 ] Training loss: 0.427432
DEBUG:root:[ Iteration 60 ] Training loss: 0.440422
DEBUG:root:[ Iteration 60 ] Test loss: 0.437962
DEBUG:root:[ Iteration 63 ] Training loss: 0.403616
DEBUG:root:[ Iteration 66 ] Training loss: 0.430583
DEBUG:root:[ Iteration 69 ] Training loss: 0.419532
DEBUG:root:[ Iteration 72 ] Training loss: 0.423855
DEBUG:root:[ Iteration 75 ] Training loss: 0.389526
DEBUG:root:[ Iteration 78 ] Training loss: 0.375934
DEBUG:root:[ Iteration 80 ] Test loss: 0.391497
DEBUG:root:[ Iteration 81 ] Training loss: 0.393459
DEBUG:root:[ Iteration 84 ] Training loss: 0.381483
DEBUG:root:[ Iteration 87 ] Training loss: 0.383113
DEBUG:root:[ Iteration 90 ] Training loss: 0.350941
DEBUG:root:[ Iteration 93 ] Training loss: 0.364133
DEBUG:root:[ Iteration 96 ] Training loss: 0.346227
DEBUG:root:[ Iteration 99 ] Training loss: 0.340688
DEBUG:root:[ Iteration 100 ] Test loss: 0.34628
DEBUG:root:[ Iteration 102 ] Training loss: 0.336862
DEBUG:root:[ Iteration 105 ] Training loss: 0.330743
DEBUG:root:[ Iteration 108 ] Training loss: 0.321011
DEBUG:root:[ Iteration 111 ] Training loss: 0.305714
DEBUG:root:[ Iteration 114 ] Training loss: 0.299647
DEBUG:root:[ Iteration 117 ] Training loss: 0.288258
DEBUG:root:[ Iteration 120 ] Training loss: 0.278547
DEBUG:root:[ Iteration 120 ] Test loss: 0.296174
DEBUG:root:[ Iteration 123 ] Training loss: 0.28183
DEBUG:root:[ Iteration 126 ] Training loss: 0.272042
DEBUG:root:[ Iteration 129 ] Training loss: 0.263614
DEBUG:root:[ Iteration 132 ] Training loss: 0.26116
DEBUG:root:[ Iteration 135 ] Training loss: 0.240307
DEBUG:root:[ Iteration 138 ] Training loss: 0.239422
DEBUG:root:[ Iteration 140 ] Test loss: 0.241697
DEBUG:root:[ Iteration 141 ] Training loss: 0.222626
DEBUG:root:[ Iteration 144 ] Training loss: 0.166289
DEBUG:root:[ Iteration 147 ] Training loss: 0.181898
DEBUG:root:[ Iteration 150 ] Training loss: 0.163406
DEBUG:root:[ Iteration 153 ] Training loss: 0.148801
DEBUG:root:[ Iteration 156 ] Training loss: 0.138731
DEBUG:root:[ Iteration 159 ] Training loss: 0.140786
DEBUG:root:[ Iteration 160 ] Test loss: 0.146009
DEBUG:root:[ Iteration 162 ] Training loss: 0.120659
DEBUG:root:[ Iteration 165 ] Training loss: 0.118985
DEBUG:root:[ Iteration 168 ] Training loss: 0.104759
DEBUG:root:[ Iteration 171 ] Training loss: 0.102246
DEBUG:root:[ Iteration 174 ] Training loss: 0.107553
DEBUG:root:[ Iteration 177 ] Training loss: 0.0696205
DEBUG:root:[ Iteration 180 ] Training loss: 0.0808455
DEBUG:root:[ Iteration 180 ] Test loss: 0.0926137
DEBUG:root:[ Iteration 183 ] Training loss: 0.074797
DEBUG:root:[ Iteration 186 ] Training loss: 0.0658342
DEBUG:root:[ Iteration 189 ] Training loss: 0.0556022
DEBUG:root:[ Iteration 192 ] Training loss: 0.0546338
DEBUG:root:[ Iteration 195 ] Training loss: 0.0566487
DEBUG:root:[ Iteration 198 ] Training loss: 0.0506077
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.43742
DEBUG:root:[ Iteration 0 ] Test loss: 0.423669
DEBUG:root:[ Iteration 3 ] Training loss: 0.424089
DEBUG:root:[ Iteration 6 ] Training loss: 0.425536
DEBUG:root:[ Iteration 9 ] Training loss: 0.418406
DEBUG:root:[ Iteration 12 ] Training loss: 0.404637
DEBUG:root:[ Iteration 15 ] Training loss: 0.399182
DEBUG:root:[ Iteration 18 ] Training loss: 0.404217
DEBUG:root:[ Iteration 20 ] Test loss: 0.394426
DEBUG:root:[ Iteration 21 ] Training loss: 0.403293
DEBUG:root:[ Iteration 24 ] Training loss: 0.375211
DEBUG:root:[ Iteration 27 ] Training loss: 0.366699
DEBUG:root:[ Iteration 30 ] Training loss: 0.348772
DEBUG:root:[ Iteration 33 ] Training loss: 0.343657
DEBUG:root:[ Iteration 36 ] Training loss: 0.343078
DEBUG:root:[ Iteration 39 ] Training loss: 0.312223
DEBUG:root:[ Iteration 40 ] Test loss: 0.320842
DEBUG:root:[ Iteration 42 ] Training loss: 0.320086
DEBUG:root:[ Iteration 45 ] Training loss: 0.28973
DEBUG:root:[ Iteration 48 ] Training loss: 0.283447
DEBUG:root:[ Iteration 51 ] Training loss: 0.276069
DEBUG:root:[ Iteration 54 ] Training loss: 0.23536
DEBUG:root:[ Iteration 57 ] Training loss: 0.255098
DEBUG:root:[ Iteration 60 ] Training loss: 0.255528
DEBUG:root:[ Iteration 60 ] Test loss: 0.237933
DEBUG:root:[ Iteration 63 ] Training loss: 0.217521
DEBUG:root:[ Iteration 66 ] Training loss: 0.215246
DEBUG:root:[ Iteration 69 ] Training loss: 0.198212
DEBUG:root:[ Iteration 72 ] Training loss: 0.190309
DEBUG:root:[ Iteration 75 ] Training loss: 0.176449
DEBUG:root:[ Iteration 78 ] Training loss: 0.18322
DEBUG:root:[ Iteration 80 ] Test loss: 0.178403
DEBUG:root:[ Iteration 81 ] Training loss: 0.175766
DEBUG:root:[ Iteration 84 ] Training loss: 0.164524
DEBUG:root:[ Iteration 87 ] Training loss: 0.136502
DEBUG:root:[ Iteration 90 ] Training loss: 0.128149
DEBUG:root:[ Iteration 93 ] Training loss: 0.125953
DEBUG:root:[ Iteration 96 ] Training loss: 0.128195
DEBUG:root:[ Iteration 99 ] Training loss: 0.110173
DEBUG:root:[ Iteration 100 ] Test loss: 0.128018
DEBUG:root:[ Iteration 102 ] Training loss: 0.107849
DEBUG:root:[ Iteration 105 ] Training loss: 0.100291
DEBUG:root:[ Iteration 108 ] Training loss: 0.0929259
DEBUG:root:[ Iteration 111 ] Training loss: 0.0961372
DEBUG:root:[ Iteration 114 ] Training loss: 0.0858468
DEBUG:root:[ Iteration 117 ] Training loss: 0.0723365
DEBUG:root:[ Iteration 120 ] Training loss: 0.0815931
DEBUG:root:[ Iteration 120 ] Test loss: 0.0848157
DEBUG:root:[ Iteration 123 ] Training loss: 0.0714204
DEBUG:root:[ Iteration 126 ] Training loss: 0.0700982
DEBUG:root:[ Iteration 129 ] Training loss: 0.0582676
DEBUG:root:[ Iteration 132 ] Training loss: 0.0633857
DEBUG:root:[ Iteration 135 ] Training loss: 0.052774
DEBUG:root:[ Iteration 138 ] Training loss: 0.0493117
DEBUG:root:[ Iteration 140 ] Test loss: 0.0557709
DEBUG:root:[ Iteration 141 ] Training loss: 0.0438812
DEBUG:root:[ Iteration 144 ] Training loss: 0.0383332
DEBUG:root:[ Iteration 147 ] Training loss: 0.0381887
DEBUG:root:[ Iteration 150 ] Training loss: 0.0408271
DEBUG:root:[ Iteration 153 ] Training loss: 0.0441071
DEBUG:root:[ Iteration 156 ] Training loss: 0.0342974
DEBUG:root:[ Iteration 159 ] Training loss: 0.0268539
DEBUG:root:[ Iteration 160 ] Test loss: 0.0389334
DEBUG:root:[ Iteration 162 ] Training loss: 0.0279223
DEBUG:root:[ Iteration 165 ] Training loss: 0.025914
DEBUG:root:[ Iteration 168 ] Training loss: 0.0289282
DEBUG:root:[ Iteration 171 ] Training loss: 0.0243239
DEBUG:root:[ Iteration 174 ] Training loss: 0.0256068
DEBUG:root:[ Iteration 177 ] Training loss: 0.021459
DEBUG:root:[ Iteration 180 ] Training loss: 0.0198082
DEBUG:root:[ Iteration 180 ] Test loss: 0.0263708
DEBUG:root:[ Iteration 183 ] Training loss: 0.0197415
DEBUG:root:[ Iteration 186 ] Training loss: 0.0218648
DEBUG:root:[ Iteration 189 ] Training loss: 0.0157872
DEBUG:root:[ Iteration 192 ] Training loss: 0.0150783
DEBUG:root:[ Iteration 195 ] Training loss: 0.0193191
DEBUG:root:[ Iteration 198 ] Training loss: 0.0170992
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-10-2016_14h17m27s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.441758
DEBUG:root:[ Iteration 0 ] Test loss: 0.446178
DEBUG:root:[ Iteration 3 ] Training loss: 0.440519
DEBUG:root:[ Iteration 6 ] Training loss: 0.411469
DEBUG:root:[ Iteration 9 ] Training loss: 0.403133
DEBUG:root:[ Iteration 12 ] Training loss: 0.406357
DEBUG:root:[ Iteration 15 ] Training loss: 0.3978
DEBUG:root:[ Iteration 18 ] Training loss: 0.404856
DEBUG:root:[ Iteration 20 ] Test loss: 0.381454
DEBUG:root:[ Iteration 21 ] Training loss: 0.382
DEBUG:root:[ Iteration 24 ] Training loss: 0.375132
DEBUG:root:[ Iteration 27 ] Training loss: 0.364971
DEBUG:root:[ Iteration 30 ] Training loss: 0.346852
DEBUG:root:[ Iteration 33 ] Training loss: 0.351808
DEBUG:root:[ Iteration 36 ] Training loss: 0.343448
DEBUG:root:[ Iteration 39 ] Training loss: 0.337087
DEBUG:root:[ Iteration 40 ] Test loss: 0.345294
DEBUG:root:[ Iteration 42 ] Training loss: 0.312986
DEBUG:root:[ Iteration 45 ] Training loss: 0.314933
DEBUG:root:[ Iteration 48 ] Training loss: 0.300045
DEBUG:root:[ Iteration 51 ] Training loss: 0.287306
DEBUG:root:[ Iteration 54 ] Training loss: 0.277213
DEBUG:root:[ Iteration 57 ] Training loss: 0.257725
DEBUG:root:[ Iteration 60 ] Training loss: 0.234418
DEBUG:root:[ Iteration 60 ] Test loss: 0.261997
DEBUG:root:[ Iteration 63 ] Training loss: 0.229352
DEBUG:root:[ Iteration 66 ] Training loss: 0.247743
DEBUG:root:[ Iteration 69 ] Training loss: 0.229368
DEBUG:root:[ Iteration 72 ] Training loss: 0.230533
DEBUG:root:[ Iteration 75 ] Training loss: 0.20697
DEBUG:root:[ Iteration 78 ] Training loss: 0.185528
DEBUG:root:[ Iteration 80 ] Test loss: 0.208954
DEBUG:root:[ Iteration 81 ] Training loss: 0.185699
DEBUG:root:[ Iteration 84 ] Training loss: 0.178661
DEBUG:root:[ Iteration 87 ] Training loss: 0.172845
DEBUG:root:[ Iteration 90 ] Training loss: 0.1618
DEBUG:root:[ Iteration 93 ] Training loss: 0.148519
DEBUG:root:[ Iteration 96 ] Training loss: 0.142022
DEBUG:root:[ Iteration 99 ] Training loss: 0.137075
DEBUG:root:[ Iteration 100 ] Test loss: 0.149405
DEBUG:root:[ Iteration 102 ] Training loss: 0.122778
DEBUG:root:[ Iteration 105 ] Training loss: 0.121713
DEBUG:root:[ Iteration 108 ] Training loss: 0.112839
DEBUG:root:[ Iteration 111 ] Training loss: 0.104593
DEBUG:root:[ Iteration 114 ] Training loss: 0.0875621
DEBUG:root:[ Iteration 117 ] Training loss: 0.0885857
DEBUG:root:[ Iteration 120 ] Training loss: 0.0783595
DEBUG:root:[ Iteration 120 ] Test loss: 0.09834
DEBUG:root:[ Iteration 123 ] Training loss: 0.0772905
DEBUG:root:[ Iteration 126 ] Training loss: 0.0695899
DEBUG:root:[ Iteration 129 ] Training loss: 0.0664895
DEBUG:root:[ Iteration 132 ] Training loss: 0.0618145
DEBUG:root:[ Iteration 135 ] Training loss: 0.0570052
DEBUG:root:[ Iteration 138 ] Training loss: 0.054923
DEBUG:root:[ Iteration 140 ] Test loss: 0.0653703
DEBUG:root:[ Iteration 141 ] Training loss: 0.0535213
DEBUG:root:[ Iteration 144 ] Training loss: 0.0407127
DEBUG:root:[ Iteration 147 ] Training loss: 0.0467549
DEBUG:root:[ Iteration 150 ] Training loss: 0.0435171
DEBUG:root:[ Iteration 153 ] Training loss: 0.0441941
DEBUG:root:[ Iteration 156 ] Training loss: 0.0397407
DEBUG:root:[ Iteration 159 ] Training loss: 0.0376965
DEBUG:root:[ Iteration 160 ] Test loss: 0.0449644
DEBUG:root:[ Iteration 162 ] Training loss: 0.0309861
DEBUG:root:[ Iteration 165 ] Training loss: 0.03214
DEBUG:root:[ Iteration 168 ] Training loss: 0.0369285
DEBUG:root:[ Iteration 171 ] Training loss: 0.0289246
DEBUG:root:[ Iteration 174 ] Training loss: 0.0321584
DEBUG:root:[ Iteration 177 ] Training loss: 0.0253143
DEBUG:root:[ Iteration 180 ] Training loss: 0.0258858
DEBUG:root:[ Iteration 180 ] Test loss: 0.0320666
DEBUG:root:[ Iteration 183 ] Training loss: 0.0216005
DEBUG:root:[ Iteration 186 ] Training loss: 0.0241345
DEBUG:root:[ Iteration 189 ] Training loss: 0.0218479
DEBUG:root:[ Iteration 192 ] Training loss: 0.0211975
DEBUG:root:[ Iteration 195 ] Training loss: 0.0212557
DEBUG:root:[ Iteration 198 ] Training loss: 0.019205
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_17h03m16s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.540805
DEBUG:root:[ Iteration 0 ] Test loss: 0.544548
DEBUG:root:[ Iteration 3 ] Training loss: 0.55014
DEBUG:root:[ Iteration 6 ] Training loss: 0.433871
DEBUG:root:[ Iteration 9 ] Training loss: 0.43733
DEBUG:root:[ Iteration 12 ] Training loss: 0.434885
DEBUG:root:[ Iteration 15 ] Training loss: 0.435581
DEBUG:root:[ Iteration 18 ] Training loss: 0.423898
DEBUG:root:[ Iteration 20 ] Test loss: 0.436679
DEBUG:root:[ Iteration 21 ] Training loss: 0.433176
DEBUG:root:[ Iteration 24 ] Training loss: 0.422497
DEBUG:root:[ Iteration 27 ] Training loss: 0.430414
DEBUG:root:[ Iteration 30 ] Training loss: 0.436677
DEBUG:root:[ Iteration 33 ] Training loss: 0.432949
DEBUG:root:[ Iteration 36 ] Training loss: 0.433772
DEBUG:root:[ Iteration 39 ] Training loss: 0.435098
DEBUG:root:[ Iteration 40 ] Test loss: 0.436679
DEBUG:root:[ Iteration 42 ] Training loss: 0.440968
DEBUG:root:[ Iteration 45 ] Training loss: 0.428038
DEBUG:root:[ Iteration 48 ] Training loss: 0.439893
DEBUG:root:[ Iteration 51 ] Training loss: 0.431639
DEBUG:root:[ Iteration 54 ] Training loss: 0.437032
DEBUG:root:[ Iteration 57 ] Training loss: 0.425803
DEBUG:root:[ Iteration 60 ] Training loss: 0.432699
DEBUG:root:[ Iteration 60 ] Test loss: 0.436679
DEBUG:root:[ Iteration 63 ] Training loss: 0.441493
DEBUG:root:[ Iteration 66 ] Training loss: 0.427359
DEBUG:root:[ Iteration 69 ] Training loss: 0.426393
DEBUG:root:[ Iteration 72 ] Training loss: 0.440813
DEBUG:root:[ Iteration 75 ] Training loss: 0.438108
DEBUG:root:[ Iteration 78 ] Training loss: 0.439254
DEBUG:root:[ Iteration 80 ] Test loss: 0.436679
DEBUG:root:[ Iteration 81 ] Training loss: 0.425248
DEBUG:root:[ Iteration 84 ] Training loss: 0.428853
DEBUG:root:[ Iteration 87 ] Training loss: 0.438362
DEBUG:root:[ Iteration 90 ] Training loss: 0.433945
DEBUG:root:[ Iteration 93 ] Training loss: 0.440838
DEBUG:root:[ Iteration 96 ] Training loss: 0.424124
DEBUG:root:[ Iteration 99 ] Training loss: 0.430831
DEBUG:root:[ Iteration 100 ] Test loss: 0.436679
DEBUG:root:[ Iteration 102 ] Training loss: 0.434048
DEBUG:root:[ Iteration 105 ] Training loss: 0.438461
DEBUG:root:[ Iteration 108 ] Training loss: 0.432013
DEBUG:root:[ Iteration 111 ] Training loss: 0.435875
DEBUG:root:[ Iteration 114 ] Training loss: 0.427674
DEBUG:root:[ Iteration 117 ] Training loss: 0.429063
DEBUG:root:[ Iteration 120 ] Training loss: 0.433176
DEBUG:root:[ Iteration 120 ] Test loss: 0.436679
DEBUG:root:[ Iteration 123 ] Training loss: 0.43461
DEBUG:root:[ Iteration 126 ] Training loss: 0.430256
DEBUG:root:[ Iteration 129 ] Training loss: 0.431623
DEBUG:root:[ Iteration 132 ] Training loss: 0.435939
DEBUG:root:[ Iteration 135 ] Training loss: 0.439205
DEBUG:root:[ Iteration 138 ] Training loss: 0.432963
DEBUG:root:[ Iteration 140 ] Test loss: 0.436679
DEBUG:root:[ Iteration 141 ] Training loss: 0.438186
DEBUG:root:[ Iteration 144 ] Training loss: 0.432471
DEBUG:root:[ Iteration 147 ] Training loss: 0.429637
DEBUG:root:[ Iteration 150 ] Training loss: 0.420386
DEBUG:root:[ Iteration 153 ] Training loss: 0.427082
DEBUG:root:[ Iteration 156 ] Training loss: 0.430394
DEBUG:root:[ Iteration 159 ] Training loss: 0.432622
DEBUG:root:[ Iteration 160 ] Test loss: 0.436679
DEBUG:root:[ Iteration 162 ] Training loss: 0.434584
DEBUG:root:[ Iteration 165 ] Training loss: 0.439871
DEBUG:root:[ Iteration 168 ] Training loss: 0.426764
DEBUG:root:[ Iteration 171 ] Training loss: 0.429283
DEBUG:root:[ Iteration 174 ] Training loss: 0.428354
DEBUG:root:[ Iteration 177 ] Training loss: 0.440622
DEBUG:root:[ Iteration 180 ] Training loss: 0.440318
DEBUG:root:[ Iteration 180 ] Test loss: 0.436679
DEBUG:root:[ Iteration 183 ] Training loss: 0.436974
DEBUG:root:[ Iteration 186 ] Training loss: 0.440257
DEBUG:root:[ Iteration 189 ] Training loss: 0.430305
DEBUG:root:[ Iteration 192 ] Training loss: 0.440897
DEBUG:root:[ Iteration 195 ] Training loss: 0.433137
DEBUG:root:[ Iteration 198 ] Training loss: 0.436696
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_17h26m54s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.568145
DEBUG:root:[ Iteration 0 ] Test loss: 0.530168
DEBUG:root:[ Iteration 3 ] Training loss: 0.545664
DEBUG:root:[ Iteration 6 ] Training loss: 0.543355
DEBUG:root:[ Iteration 9 ] Training loss: 0.547166
DEBUG:root:[ Iteration 12 ] Training loss: 0.537233
DEBUG:root:[ Iteration 15 ] Training loss: 0.543483
DEBUG:root:[ Iteration 18 ] Training loss: 0.499042
DEBUG:root:[ Iteration 20 ] Test loss: 0.431183
DEBUG:root:[ Iteration 21 ] Training loss: 0.428826
DEBUG:root:[ Iteration 24 ] Training loss: 0.424098
DEBUG:root:[ Iteration 27 ] Training loss: 0.43051
DEBUG:root:[ Iteration 30 ] Training loss: 0.438613
DEBUG:root:[ Iteration 33 ] Training loss: 0.439366
DEBUG:root:[ Iteration 36 ] Training loss: 0.431127
DEBUG:root:[ Iteration 39 ] Training loss: 0.434802
DEBUG:root:[ Iteration 40 ] Test loss: 0.436413
DEBUG:root:[ Iteration 42 ] Training loss: 0.433041
DEBUG:root:[ Iteration 45 ] Training loss: 0.437075
DEBUG:root:[ Iteration 48 ] Training loss: 0.432065
DEBUG:root:[ Iteration 51 ] Training loss: 0.432579
DEBUG:root:[ Iteration 54 ] Training loss: 0.432328
DEBUG:root:[ Iteration 57 ] Training loss: 0.425227
DEBUG:root:[ Iteration 60 ] Training loss: 0.429617
DEBUG:root:[ Iteration 60 ] Test loss: 0.436413
DEBUG:root:[ Iteration 63 ] Training loss: 0.430304
DEBUG:root:[ Iteration 66 ] Training loss: 0.435763
DEBUG:root:[ Iteration 69 ] Training loss: 0.43412
DEBUG:root:[ Iteration 72 ] Training loss: 0.436811
DEBUG:root:[ Iteration 75 ] Training loss: 0.434044
DEBUG:root:[ Iteration 78 ] Training loss: 0.44107
DEBUG:root:[ Iteration 80 ] Test loss: 0.436413
DEBUG:root:[ Iteration 81 ] Training loss: 0.43446
DEBUG:root:[ Iteration 84 ] Training loss: 0.435414
DEBUG:root:[ Iteration 87 ] Training loss: 0.441036
DEBUG:root:[ Iteration 90 ] Training loss: 0.42715
DEBUG:root:[ Iteration 93 ] Training loss: 0.434384
DEBUG:root:[ Iteration 96 ] Training loss: 0.439826
DEBUG:root:[ Iteration 99 ] Training loss: 0.435537
DEBUG:root:[ Iteration 100 ] Test loss: 0.436413
DEBUG:root:[ Iteration 102 ] Training loss: 0.423775
DEBUG:root:[ Iteration 105 ] Training loss: 0.432464
DEBUG:root:[ Iteration 108 ] Training loss: 0.434999
DEBUG:root:[ Iteration 111 ] Training loss: 0.429689
DEBUG:root:[ Iteration 114 ] Training loss: 0.43518
DEBUG:root:[ Iteration 117 ] Training loss: 0.425781
DEBUG:root:[ Iteration 120 ] Training loss: 0.442241
DEBUG:root:[ Iteration 120 ] Test loss: 0.436413
DEBUG:root:[ Iteration 123 ] Training loss: 0.431871
DEBUG:root:[ Iteration 126 ] Training loss: 0.443161
DEBUG:root:[ Iteration 129 ] Training loss: 0.432
DEBUG:root:[ Iteration 132 ] Training loss: 0.441892
DEBUG:root:[ Iteration 135 ] Training loss: 0.429238
DEBUG:root:[ Iteration 138 ] Training loss: 0.433791
DEBUG:root:[ Iteration 140 ] Test loss: 0.436413
DEBUG:root:[ Iteration 141 ] Training loss: 0.437166
DEBUG:root:[ Iteration 144 ] Training loss: 0.439935
DEBUG:root:[ Iteration 147 ] Training loss: 0.4279
DEBUG:root:[ Iteration 150 ] Training loss: 0.432161
DEBUG:root:[ Iteration 153 ] Training loss: 0.438383
DEBUG:root:[ Iteration 156 ] Training loss: 0.434607
DEBUG:root:[ Iteration 159 ] Training loss: 0.43116
DEBUG:root:[ Iteration 160 ] Test loss: 0.436413
DEBUG:root:[ Iteration 162 ] Training loss: 0.435425
DEBUG:root:[ Iteration 165 ] Training loss: 0.436447
DEBUG:root:[ Iteration 168 ] Training loss: 0.436035
DEBUG:root:[ Iteration 171 ] Training loss: 0.44379
DEBUG:root:[ Iteration 174 ] Training loss: 0.430829
DEBUG:root:[ Iteration 177 ] Training loss: 0.435423
DEBUG:root:[ Iteration 180 ] Training loss: 0.437597
DEBUG:root:[ Iteration 180 ] Test loss: 0.436413
DEBUG:root:[ Iteration 183 ] Training loss: 0.430665
DEBUG:root:[ Iteration 186 ] Training loss: 0.428463
DEBUG:root:[ Iteration 189 ] Training loss: 0.430054
DEBUG:root:[ Iteration 192 ] Training loss: 0.438906
DEBUG:root:[ Iteration 195 ] Training loss: 0.434672
DEBUG:root:[ Iteration 198 ] Training loss: 0.435306
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.534847
DEBUG:root:[ Iteration 0 ] Test loss: 0.522365
DEBUG:root:[ Iteration 3 ] Training loss: 0.518316
DEBUG:root:[ Iteration 6 ] Training loss: 0.516655
DEBUG:root:[ Iteration 9 ] Training loss: 0.50975
DEBUG:root:[ Iteration 12 ] Training loss: 0.529059
DEBUG:root:[ Iteration 15 ] Training loss: 0.51858
DEBUG:root:[ Iteration 18 ] Training loss: 0.523109
DEBUG:root:[ Iteration 20 ] Test loss: 0.505318
DEBUG:root:[ Iteration 21 ] Training loss: 0.507857
DEBUG:root:[ Iteration 24 ] Training loss: 0.437383
DEBUG:root:[ Iteration 27 ] Training loss: 0.472616
DEBUG:root:[ Iteration 30 ] Training loss: 0.463727
DEBUG:root:[ Iteration 33 ] Training loss: 0.464006
DEBUG:root:[ Iteration 36 ] Training loss: 0.467105
DEBUG:root:[ Iteration 39 ] Training loss: 0.46672
DEBUG:root:[ Iteration 40 ] Test loss: 0.466503
DEBUG:root:[ Iteration 42 ] Training loss: 0.460087
DEBUG:root:[ Iteration 45 ] Training loss: 0.464629
DEBUG:root:[ Iteration 48 ] Training loss: 0.461031
DEBUG:root:[ Iteration 51 ] Training loss: 0.465786
DEBUG:root:[ Iteration 54 ] Training loss: 0.469721
DEBUG:root:[ Iteration 57 ] Training loss: 0.459692
DEBUG:root:[ Iteration 60 ] Training loss: 0.463187
DEBUG:root:[ Iteration 60 ] Test loss: 0.466503
DEBUG:root:[ Iteration 63 ] Training loss: 0.465557
DEBUG:root:[ Iteration 66 ] Training loss: 0.473248
DEBUG:root:[ Iteration 69 ] Training loss: 0.48134
DEBUG:root:[ Iteration 72 ] Training loss: 0.484335
DEBUG:root:[ Iteration 75 ] Training loss: 0.470667
DEBUG:root:[ Iteration 78 ] Training loss: 0.466714
DEBUG:root:[ Iteration 80 ] Test loss: 0.466503
DEBUG:root:[ Iteration 81 ] Training loss: 0.459924
DEBUG:root:[ Iteration 84 ] Training loss: 0.466985
DEBUG:root:[ Iteration 87 ] Training loss: 0.468601
DEBUG:root:[ Iteration 90 ] Training loss: 0.476189
DEBUG:root:[ Iteration 93 ] Training loss: 0.466201
DEBUG:root:[ Iteration 96 ] Training loss: 0.465823
DEBUG:root:[ Iteration 99 ] Training loss: 0.464983
DEBUG:root:[ Iteration 100 ] Test loss: 0.466503
DEBUG:root:[ Iteration 102 ] Training loss: 0.465909
DEBUG:root:[ Iteration 105 ] Training loss: 0.472701
DEBUG:root:[ Iteration 108 ] Training loss: 0.467217
DEBUG:root:[ Iteration 111 ] Training loss: 0.467779
DEBUG:root:[ Iteration 114 ] Training loss: 0.472641
DEBUG:root:[ Iteration 117 ] Training loss: 0.476128
DEBUG:root:[ Iteration 120 ] Training loss: 0.466845
DEBUG:root:[ Iteration 120 ] Test loss: 0.466503
DEBUG:root:[ Iteration 123 ] Training loss: 0.477765
DEBUG:root:[ Iteration 126 ] Training loss: 0.468295
DEBUG:root:[ Iteration 129 ] Training loss: 0.472258
DEBUG:root:[ Iteration 132 ] Training loss: 0.473909
DEBUG:root:[ Iteration 135 ] Training loss: 0.462548
DEBUG:root:[ Iteration 138 ] Training loss: 0.473876
DEBUG:root:[ Iteration 140 ] Test loss: 0.466503
DEBUG:root:[ Iteration 141 ] Training loss: 0.477256
DEBUG:root:[ Iteration 144 ] Training loss: 0.471347
DEBUG:root:[ Iteration 147 ] Training loss: 0.479671
DEBUG:root:[ Iteration 150 ] Training loss: 0.466998
DEBUG:root:[ Iteration 153 ] Training loss: 0.48299
DEBUG:root:[ Iteration 156 ] Training loss: 0.47268
DEBUG:root:[ Iteration 159 ] Training loss: 0.465084
DEBUG:root:[ Iteration 160 ] Test loss: 0.466503
DEBUG:root:[ Iteration 162 ] Training loss: 0.468068
DEBUG:root:[ Iteration 165 ] Training loss: 0.47132
DEBUG:root:[ Iteration 168 ] Training loss: 0.462258
DEBUG:root:[ Iteration 171 ] Training loss: 0.468674
DEBUG:root:[ Iteration 174 ] Training loss: 0.46943
DEBUG:root:[ Iteration 177 ] Training loss: 0.465053
DEBUG:root:[ Iteration 180 ] Training loss: 0.472723
DEBUG:root:[ Iteration 180 ] Test loss: 0.466503
DEBUG:root:[ Iteration 183 ] Training loss: 0.469214
DEBUG:root:[ Iteration 186 ] Training loss: 0.473271
DEBUG:root:[ Iteration 189 ] Training loss: 0.468351
DEBUG:root:[ Iteration 192 ] Training loss: 0.474128
DEBUG:root:[ Iteration 195 ] Training loss: 0.47268
DEBUG:root:[ Iteration 198 ] Training loss: 0.468024
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.449669
DEBUG:root:[ Iteration 0 ] Test loss: 0.450738
DEBUG:root:[ Iteration 3 ] Training loss: 0.442496
DEBUG:root:[ Iteration 6 ] Training loss: 0.487295
DEBUG:root:[ Iteration 9 ] Training loss: 0.457179
DEBUG:root:[ Iteration 12 ] Training loss: 0.446254
DEBUG:root:[ Iteration 15 ] Training loss: 0.449834
DEBUG:root:[ Iteration 18 ] Training loss: 0.45429
DEBUG:root:[ Iteration 20 ] Test loss: 0.456754
DEBUG:root:[ Iteration 21 ] Training loss: 0.460087
DEBUG:root:[ Iteration 24 ] Training loss: 0.455476
DEBUG:root:[ Iteration 27 ] Training loss: 0.464171
DEBUG:root:[ Iteration 30 ] Training loss: 0.468953
DEBUG:root:[ Iteration 33 ] Training loss: 0.475041
DEBUG:root:[ Iteration 36 ] Training loss: 0.467102
DEBUG:root:[ Iteration 39 ] Training loss: 0.475681
DEBUG:root:[ Iteration 40 ] Test loss: 0.459342
DEBUG:root:[ Iteration 42 ] Training loss: 0.466161
DEBUG:root:[ Iteration 45 ] Training loss: 0.469031
DEBUG:root:[ Iteration 48 ] Training loss: 0.466449
DEBUG:root:[ Iteration 51 ] Training loss: 0.465152
DEBUG:root:[ Iteration 54 ] Training loss: 0.461888
DEBUG:root:[ Iteration 57 ] Training loss: 0.46557
DEBUG:root:[ Iteration 60 ] Training loss: 0.46505
DEBUG:root:[ Iteration 60 ] Test loss: 0.466836
DEBUG:root:[ Iteration 63 ] Training loss: 0.441531
DEBUG:root:[ Iteration 66 ] Training loss: 0.478877
DEBUG:root:[ Iteration 69 ] Training loss: 0.455501
DEBUG:root:[ Iteration 72 ] Training loss: 0.471534
DEBUG:root:[ Iteration 75 ] Training loss: 0.442356
DEBUG:root:[ Iteration 78 ] Training loss: 0.456985
DEBUG:root:[ Iteration 80 ] Test loss: 0.454103
DEBUG:root:[ Iteration 81 ] Training loss: 0.471485
DEBUG:root:[ Iteration 84 ] Training loss: 0.412752
DEBUG:root:[ Iteration 87 ] Training loss: 0.436633
DEBUG:root:[ Iteration 90 ] Training loss: 0.474878
DEBUG:root:[ Iteration 93 ] Training loss: 0.439212
DEBUG:root:[ Iteration 96 ] Training loss: 0.475442
DEBUG:root:[ Iteration 99 ] Training loss: 0.474075
DEBUG:root:[ Iteration 100 ] Test loss: 0.46185
DEBUG:root:[ Iteration 102 ] Training loss: 0.462634
DEBUG:root:[ Iteration 105 ] Training loss: 0.481155
DEBUG:root:[ Iteration 108 ] Training loss: 0.468435
DEBUG:root:[ Iteration 111 ] Training loss: 0.463338
DEBUG:root:[ Iteration 114 ] Training loss: 0.470588
DEBUG:root:[ Iteration 117 ] Training loss: 0.457997
DEBUG:root:[ Iteration 120 ] Training loss: 0.463236
DEBUG:root:[ Iteration 120 ] Test loss: 0.467839
DEBUG:root:[ Iteration 123 ] Training loss: 0.464686
DEBUG:root:[ Iteration 126 ] Training loss: 0.473452
DEBUG:root:[ Iteration 129 ] Training loss: 0.473761
DEBUG:root:[ Iteration 132 ] Training loss: 0.471552
DEBUG:root:[ Iteration 135 ] Training loss: 0.478678
DEBUG:root:[ Iteration 138 ] Training loss: 0.458668
DEBUG:root:[ Iteration 140 ] Test loss: 0.467935
DEBUG:root:[ Iteration 141 ] Training loss: 0.468131
DEBUG:root:[ Iteration 144 ] Training loss: 0.484157
DEBUG:root:[ Iteration 147 ] Training loss: 0.476209
DEBUG:root:[ Iteration 150 ] Training loss: 0.466276
DEBUG:root:[ Iteration 153 ] Training loss: 0.47283
DEBUG:root:[ Iteration 156 ] Training loss: 0.475777
DEBUG:root:[ Iteration 159 ] Training loss: 0.466679
DEBUG:root:[ Iteration 160 ] Test loss: 0.469638
DEBUG:root:[ Iteration 162 ] Training loss: 0.47104
DEBUG:root:[ Iteration 165 ] Training loss: 0.465377
DEBUG:root:[ Iteration 168 ] Training loss: 0.479092
DEBUG:root:[ Iteration 171 ] Training loss: 0.48609
DEBUG:root:[ Iteration 174 ] Training loss: 0.482534
DEBUG:root:[ Iteration 177 ] Training loss: 0.485809
DEBUG:root:[ Iteration 180 ] Training loss: 0.469882
DEBUG:root:[ Iteration 180 ] Test loss: 0.469266
DEBUG:root:[ Iteration 183 ] Training loss: 0.465725
DEBUG:root:[ Iteration 186 ] Training loss: 0.476695
DEBUG:root:[ Iteration 189 ] Training loss: 0.471047
DEBUG:root:[ Iteration 192 ] Training loss: 0.464446
DEBUG:root:[ Iteration 195 ] Training loss: 0.475955
DEBUG:root:[ Iteration 198 ] Training loss: 0.474958
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_20h53m07s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.506313
DEBUG:root:[ Iteration 0 ] Test loss: 0.511257
DEBUG:root:[ Iteration 3 ] Training loss: 0.504425
DEBUG:root:[ Iteration 6 ] Training loss: 0.505995
DEBUG:root:[ Iteration 9 ] Training loss: 0.508304
DEBUG:root:[ Iteration 12 ] Training loss: 0.495667
DEBUG:root:[ Iteration 15 ] Training loss: 0.497174
DEBUG:root:[ Iteration 18 ] Training loss: 0.488412
DEBUG:root:[ Iteration 20 ] Test loss: 0.508002
DEBUG:root:[ Iteration 21 ] Training loss: 0.493854
DEBUG:root:[ Iteration 24 ] Training loss: 0.476827
DEBUG:root:[ Iteration 27 ] Training loss: 0.479588
DEBUG:root:[ Iteration 30 ] Training loss: 0.477428
DEBUG:root:[ Iteration 33 ] Training loss: 0.484303
DEBUG:root:[ Iteration 36 ] Training loss: 0.469655
DEBUG:root:[ Iteration 39 ] Training loss: 0.464996
DEBUG:root:[ Iteration 40 ] Test loss: 0.488327
DEBUG:root:[ Iteration 42 ] Training loss: 0.462655
DEBUG:root:[ Iteration 45 ] Training loss: 0.455975
DEBUG:root:[ Iteration 48 ] Training loss: 0.469564
DEBUG:root:[ Iteration 51 ] Training loss: 0.463536
DEBUG:root:[ Iteration 54 ] Training loss: 0.465718
DEBUG:root:[ Iteration 57 ] Training loss: 0.46774
DEBUG:root:[ Iteration 60 ] Training loss: 0.453256
DEBUG:root:[ Iteration 60 ] Test loss: 0.460157
DEBUG:root:[ Iteration 63 ] Training loss: 0.464905
DEBUG:root:[ Iteration 66 ] Training loss: 0.445495
DEBUG:root:[ Iteration 69 ] Training loss: 0.438526
DEBUG:root:[ Iteration 72 ] Training loss: 0.439719
DEBUG:root:[ Iteration 75 ] Training loss: 0.446773
DEBUG:root:[ Iteration 78 ] Training loss: 0.456474
DEBUG:root:[ Iteration 80 ] Test loss: 0.459016
DEBUG:root:[ Iteration 81 ] Training loss: 0.475421
DEBUG:root:[ Iteration 84 ] Training loss: 0.449121
DEBUG:root:[ Iteration 87 ] Training loss: 0.457166
DEBUG:root:[ Iteration 90 ] Training loss: 0.441315
DEBUG:root:[ Iteration 93 ] Training loss: 0.446864
DEBUG:root:[ Iteration 96 ] Training loss: 0.43237
DEBUG:root:[ Iteration 99 ] Training loss: 0.442461
DEBUG:root:[ Iteration 100 ] Test loss: 0.445854
DEBUG:root:[ Iteration 102 ] Training loss: 0.428068
DEBUG:root:[ Iteration 105 ] Training loss: 0.423358
DEBUG:root:[ Iteration 108 ] Training loss: 0.424648
DEBUG:root:[ Iteration 111 ] Training loss: 0.436238
DEBUG:root:[ Iteration 114 ] Training loss: 0.417861
DEBUG:root:[ Iteration 117 ] Training loss: 0.422106
DEBUG:root:[ Iteration 120 ] Training loss: 0.402812
DEBUG:root:[ Iteration 120 ] Test loss: 0.436932
DEBUG:root:[ Iteration 123 ] Training loss: 0.390863
DEBUG:root:[ Iteration 126 ] Training loss: 0.402579
DEBUG:root:[ Iteration 129 ] Training loss: 0.38049
DEBUG:root:[ Iteration 132 ] Training loss: 0.390791
DEBUG:root:[ Iteration 135 ] Training loss: 0.347129
DEBUG:root:[ Iteration 138 ] Training loss: 0.35973
DEBUG:root:[ Iteration 140 ] Test loss: 0.363146
DEBUG:root:[ Iteration 141 ] Training loss: 0.337614
DEBUG:root:[ Iteration 144 ] Training loss: 0.326469
DEBUG:root:[ Iteration 147 ] Training loss: 0.323672
DEBUG:root:[ Iteration 150 ] Training loss: 0.287123
DEBUG:root:[ Iteration 153 ] Training loss: 0.246207
DEBUG:root:[ Iteration 156 ] Training loss: 0.219209
DEBUG:root:[ Iteration 159 ] Training loss: 0.181449
DEBUG:root:[ Iteration 160 ] Test loss: 0.171045
DEBUG:root:[ Iteration 162 ] Training loss: 0.153289
DEBUG:root:[ Iteration 165 ] Training loss: 0.139827
DEBUG:root:[ Iteration 168 ] Training loss: 0.134437
DEBUG:root:[ Iteration 171 ] Training loss: 0.118841
DEBUG:root:[ Iteration 174 ] Training loss: 0.11013
DEBUG:root:[ Iteration 177 ] Training loss: 0.0980205
DEBUG:root:[ Iteration 180 ] Training loss: 0.0879077
DEBUG:root:[ Iteration 180 ] Test loss: 0.0916187
DEBUG:root:[ Iteration 183 ] Training loss: 0.0800006
DEBUG:root:[ Iteration 186 ] Training loss: 0.0666573
DEBUG:root:[ Iteration 189 ] Training loss: 0.0639398
DEBUG:root:[ Iteration 192 ] Training loss: 0.0562055
DEBUG:root:[ Iteration 195 ] Training loss: 0.0473433
DEBUG:root:[ Iteration 198 ] Training loss: 0.0425372
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_20h55m21s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.510144
DEBUG:root:[ Iteration 0 ] Test loss: 0.488651
DEBUG:root:[ Iteration 3 ] Training loss: 0.48643
DEBUG:root:[ Iteration 6 ] Training loss: 0.473292
DEBUG:root:[ Iteration 9 ] Training loss: 0.494053
DEBUG:root:[ Iteration 12 ] Training loss: 0.488602
DEBUG:root:[ Iteration 15 ] Training loss: 0.479542
DEBUG:root:[ Iteration 18 ] Training loss: 0.485175
DEBUG:root:[ Iteration 20 ] Test loss: 0.466604
DEBUG:root:[ Iteration 21 ] Training loss: 0.481922
DEBUG:root:[ Iteration 24 ] Training loss: 0.484468
DEBUG:root:[ Iteration 27 ] Training loss: 0.462422
DEBUG:root:[ Iteration 30 ] Training loss: 0.476737
DEBUG:root:[ Iteration 33 ] Training loss: 0.451855
DEBUG:root:[ Iteration 36 ] Training loss: 0.461814
DEBUG:root:[ Iteration 39 ] Training loss: 0.464349
DEBUG:root:[ Iteration 40 ] Test loss: 0.456557
DEBUG:root:[ Iteration 42 ] Training loss: 0.454903
DEBUG:root:[ Iteration 45 ] Training loss: 0.443813
DEBUG:root:[ Iteration 48 ] Training loss: 0.442005
DEBUG:root:[ Iteration 51 ] Training loss: 0.408822
DEBUG:root:[ Iteration 54 ] Training loss: 0.408091
DEBUG:root:[ Iteration 57 ] Training loss: 0.407134
DEBUG:root:[ Iteration 60 ] Training loss: 0.391744
DEBUG:root:[ Iteration 60 ] Test loss: 0.404767
DEBUG:root:[ Iteration 63 ] Training loss: 0.378844
DEBUG:root:[ Iteration 66 ] Training loss: 0.384176
DEBUG:root:[ Iteration 69 ] Training loss: 0.388168
DEBUG:root:[ Iteration 72 ] Training loss: 0.387847
DEBUG:root:[ Iteration 75 ] Training loss: 0.373124
DEBUG:root:[ Iteration 78 ] Training loss: 0.379001
DEBUG:root:[ Iteration 80 ] Test loss: 0.381851
DEBUG:root:[ Iteration 81 ] Training loss: 0.370083
DEBUG:root:[ Iteration 84 ] Training loss: 0.364166
DEBUG:root:[ Iteration 87 ] Training loss: 0.36573
DEBUG:root:[ Iteration 90 ] Training loss: 0.345506
DEBUG:root:[ Iteration 93 ] Training loss: 0.35626
DEBUG:root:[ Iteration 96 ] Training loss: 0.354236
DEBUG:root:[ Iteration 99 ] Training loss: 0.345511
DEBUG:root:[ Iteration 100 ] Test loss: 0.367614
DEBUG:root:[ Iteration 102 ] Training loss: 0.334665
DEBUG:root:[ Iteration 105 ] Training loss: 0.335399
DEBUG:root:[ Iteration 108 ] Training loss: 0.333347
DEBUG:root:[ Iteration 111 ] Training loss: 0.330092
DEBUG:root:[ Iteration 114 ] Training loss: 0.32731
DEBUG:root:[ Iteration 117 ] Training loss: 0.321356
DEBUG:root:[ Iteration 120 ] Training loss: 0.310943
DEBUG:root:[ Iteration 120 ] Test loss: 0.346969
DEBUG:root:[ Iteration 123 ] Training loss: 0.298524
DEBUG:root:[ Iteration 126 ] Training loss: 0.28946
DEBUG:root:[ Iteration 129 ] Training loss: 0.267429
DEBUG:root:[ Iteration 132 ] Training loss: 0.242097
DEBUG:root:[ Iteration 135 ] Training loss: 0.239017
DEBUG:root:[ Iteration 138 ] Training loss: 0.20942
DEBUG:root:[ Iteration 140 ] Test loss: 0.230042
DEBUG:root:[ Iteration 141 ] Training loss: 0.19011
DEBUG:root:[ Iteration 144 ] Training loss: 0.166709
DEBUG:root:[ Iteration 147 ] Training loss: 0.154679
DEBUG:root:[ Iteration 150 ] Training loss: 0.129338
DEBUG:root:[ Iteration 153 ] Training loss: 0.135065
DEBUG:root:[ Iteration 156 ] Training loss: 0.117005
DEBUG:root:[ Iteration 159 ] Training loss: 0.107964
DEBUG:root:[ Iteration 160 ] Test loss: 0.12664
DEBUG:root:[ Iteration 162 ] Training loss: 0.094953
DEBUG:root:[ Iteration 165 ] Training loss: 0.0846744
DEBUG:root:[ Iteration 168 ] Training loss: 0.0792538
DEBUG:root:[ Iteration 171 ] Training loss: 0.0686015
DEBUG:root:[ Iteration 174 ] Training loss: 0.0679945
DEBUG:root:[ Iteration 177 ] Training loss: 0.058356
DEBUG:root:[ Iteration 180 ] Training loss: 0.0541007
DEBUG:root:[ Iteration 180 ] Test loss: 0.0717202
DEBUG:root:[ Iteration 183 ] Training loss: 0.054699
DEBUG:root:[ Iteration 186 ] Training loss: 0.0476144
DEBUG:root:[ Iteration 189 ] Training loss: 0.0430215
DEBUG:root:[ Iteration 192 ] Training loss: 0.0378921
DEBUG:root:[ Iteration 195 ] Training loss: 0.0395557
DEBUG:root:[ Iteration 198 ] Training loss: 0.0364887
DEBUG:root:[ Iteration 200 ] Test loss: 0.0537393
DEBUG:root:[ Iteration 201 ] Training loss: 0.0353827
DEBUG:root:[ Iteration 204 ] Training loss: 0.035496
DEBUG:root:[ Iteration 207 ] Training loss: 0.0329886
DEBUG:root:[ Iteration 210 ] Training loss: 0.0262259
DEBUG:root:[ Iteration 213 ] Training loss: 0.0294839
DEBUG:root:[ Iteration 216 ] Training loss: 0.0242575
DEBUG:root:[ Iteration 219 ] Training loss: 0.0249339
DEBUG:root:[ Iteration 220 ] Test loss: 0.040054
DEBUG:root:[ Iteration 222 ] Training loss: 0.0225099
DEBUG:root:[ Iteration 225 ] Training loss: 0.0221403
DEBUG:root:[ Iteration 228 ] Training loss: 0.0230872
DEBUG:root:[ Iteration 231 ] Training loss: 0.0224055
DEBUG:root:[ Iteration 234 ] Training loss: 0.0186852
DEBUG:root:[ Iteration 237 ] Training loss: 0.0181215
DEBUG:root:[ Iteration 240 ] Training loss: 0.0197916
DEBUG:root:[ Iteration 240 ] Test loss: 0.0357925
DEBUG:root:[ Iteration 243 ] Training loss: 0.0174416
DEBUG:root:[ Iteration 246 ] Training loss: 0.0150643
DEBUG:root:[ Iteration 249 ] Training loss: 0.0189011
DEBUG:root:[ Iteration 252 ] Training loss: 0.0157349
DEBUG:root:[ Iteration 255 ] Training loss: 0.0156874
DEBUG:root:[ Iteration 258 ] Training loss: 0.0142764
DEBUG:root:[ Iteration 260 ] Test loss: 0.0293607
DEBUG:root:[ Iteration 261 ] Training loss: 0.0148297
DEBUG:root:[ Iteration 264 ] Training loss: 0.0129354
DEBUG:root:[ Iteration 267 ] Training loss: 0.0142378
DEBUG:root:[ Iteration 270 ] Training loss: 0.0128309
DEBUG:root:[ Iteration 273 ] Training loss: 0.0142698
DEBUG:root:[ Iteration 276 ] Training loss: 0.0126367
DEBUG:root:[ Iteration 279 ] Training loss: 0.0123575
DEBUG:root:[ Iteration 280 ] Test loss: 0.0270436
DEBUG:root:[ Iteration 282 ] Training loss: 0.0122691
DEBUG:root:[ Iteration 285 ] Training loss: 0.0119004
DEBUG:root:[ Iteration 288 ] Training loss: 0.0102251
DEBUG:root:[ Iteration 291 ] Training loss: 0.0109221
DEBUG:root:[ Iteration 294 ] Training loss: 0.0108663
DEBUG:root:[ Iteration 297 ] Training loss: 0.00969883
DEBUG:root:[ Iteration 300 ] Training loss: 0.00974742
DEBUG:root:[ Iteration 300 ] Test loss: 0.0235132
DEBUG:root:[ Iteration 303 ] Training loss: 0.0107863
DEBUG:root:[ Iteration 306 ] Training loss: 0.00923973
DEBUG:root:[ Iteration 309 ] Training loss: 0.00902378
DEBUG:root:[ Iteration 312 ] Training loss: 0.00935624
DEBUG:root:[ Iteration 315 ] Training loss: 0.00878763
DEBUG:root:[ Iteration 318 ] Training loss: 0.0098545
DEBUG:root:[ Iteration 320 ] Test loss: 0.0222151
DEBUG:root:[ Iteration 321 ] Training loss: 0.0078019
DEBUG:root:[ Iteration 324 ] Training loss: 0.00734619
DEBUG:root:[ Iteration 327 ] Training loss: 0.00886312
DEBUG:root:[ Iteration 330 ] Training loss: 0.00855192
DEBUG:root:[ Iteration 333 ] Training loss: 0.00789652
DEBUG:root:[ Iteration 336 ] Training loss: 0.00789259
DEBUG:root:[ Iteration 339 ] Training loss: 0.00704141
DEBUG:root:[ Iteration 340 ] Test loss: 0.0203402
DEBUG:root:[ Iteration 342 ] Training loss: 0.0066617
DEBUG:root:[ Iteration 345 ] Training loss: 0.00677075
DEBUG:root:[ Iteration 348 ] Training loss: 0.00728188
DEBUG:root:[ Iteration 351 ] Training loss: 0.0076513
DEBUG:root:[ Iteration 354 ] Training loss: 0.00741459
DEBUG:root:[ Iteration 357 ] Training loss: 0.00671289
DEBUG:root:[ Iteration 360 ] Training loss: 0.00641954
DEBUG:root:[ Iteration 360 ] Test loss: 0.0185756
DEBUG:root:[ Iteration 363 ] Training loss: 0.00625558
DEBUG:root:[ Iteration 366 ] Training loss: 0.00586761
DEBUG:root:[ Iteration 369 ] Training loss: 0.00628442
DEBUG:root:[ Iteration 372 ] Training loss: 0.00609521
DEBUG:root:[ Iteration 375 ] Training loss: 0.00583283
DEBUG:root:[ Iteration 378 ] Training loss: 0.00504001
DEBUG:root:[ Iteration 380 ] Test loss: 0.0179679
DEBUG:root:[ Iteration 381 ] Training loss: 0.00576285
DEBUG:root:[ Iteration 384 ] Training loss: 0.00547119
DEBUG:root:[ Iteration 387 ] Training loss: 0.00549417
DEBUG:root:[ Iteration 390 ] Training loss: 0.00569271
DEBUG:root:[ Iteration 393 ] Training loss: 0.00491249
DEBUG:root:[ Iteration 396 ] Training loss: 0.00564253
DEBUG:root:[ Iteration 399 ] Training loss: 0.00486488
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_21h16m25s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.426737
DEBUG:root:[ Iteration 0 ] Test loss: 0.425762
DEBUG:root:[ Iteration 3 ] Training loss: 0.403944
DEBUG:root:[ Iteration 6 ] Training loss: 0.388735
DEBUG:root:[ Iteration 9 ] Training loss: 0.403352
DEBUG:root:[ Iteration 12 ] Training loss: 0.357569
DEBUG:root:[ Iteration 15 ] Training loss: 0.350334
DEBUG:root:[ Iteration 18 ] Training loss: 0.33836
DEBUG:root:[ Iteration 20 ] Test loss: 0.349557
DEBUG:root:[ Iteration 21 ] Training loss: 0.313414
DEBUG:root:[ Iteration 24 ] Training loss: 0.303747
DEBUG:root:[ Iteration 27 ] Training loss: 0.291665
DEBUG:root:[ Iteration 30 ] Training loss: 0.275306
DEBUG:root:[ Iteration 33 ] Training loss: 0.274134
DEBUG:root:[ Iteration 36 ] Training loss: 0.251607
DEBUG:root:[ Iteration 39 ] Training loss: 0.22144
DEBUG:root:[ Iteration 40 ] Test loss: 0.243133
DEBUG:root:[ Iteration 42 ] Training loss: 0.180841
DEBUG:root:[ Iteration 45 ] Training loss: 0.174301
DEBUG:root:[ Iteration 48 ] Training loss: 0.168534
DEBUG:root:[ Iteration 51 ] Training loss: 0.152655
DEBUG:root:[ Iteration 54 ] Training loss: 0.134589
DEBUG:root:[ Iteration 57 ] Training loss: 0.124962
DEBUG:root:[ Iteration 60 ] Training loss: 0.110797
DEBUG:root:[ Iteration 60 ] Test loss: 0.150993
DEBUG:root:[ Iteration 63 ] Training loss: 0.138793
DEBUG:root:[ Iteration 66 ] Training loss: 0.108686
DEBUG:root:[ Iteration 69 ] Training loss: 0.0983912
DEBUG:root:[ Iteration 72 ] Training loss: 0.0908497
DEBUG:root:[ Iteration 75 ] Training loss: 0.0811998
DEBUG:root:[ Iteration 78 ] Training loss: 0.0653263
DEBUG:root:[ Iteration 80 ] Test loss: 0.10028
DEBUG:root:[ Iteration 81 ] Training loss: 0.0637899
DEBUG:root:[ Iteration 84 ] Training loss: 0.0614341
DEBUG:root:[ Iteration 87 ] Training loss: 0.0614247
DEBUG:root:[ Iteration 90 ] Training loss: 0.0519708
DEBUG:root:[ Iteration 93 ] Training loss: 0.0450824
DEBUG:root:[ Iteration 96 ] Training loss: 0.0479011
DEBUG:root:[ Iteration 99 ] Training loss: 0.0391554
DEBUG:root:[ Iteration 100 ] Test loss: 0.0544414
DEBUG:root:[ Iteration 102 ] Training loss: 0.0374228
DEBUG:root:[ Iteration 105 ] Training loss: 0.03418
DEBUG:root:[ Iteration 108 ] Training loss: 0.0275674
DEBUG:root:[ Iteration 111 ] Training loss: 0.0265363
DEBUG:root:[ Iteration 114 ] Training loss: 0.0246331
DEBUG:root:[ Iteration 117 ] Training loss: 0.0229862
DEBUG:root:[ Iteration 120 ] Training loss: 0.0198038
DEBUG:root:[ Iteration 120 ] Test loss: 0.0267242
DEBUG:root:[ Iteration 123 ] Training loss: 0.0190899
DEBUG:root:[ Iteration 126 ] Training loss: 0.0166253
DEBUG:root:[ Iteration 129 ] Training loss: 0.0153813
DEBUG:root:[ Iteration 132 ] Training loss: 0.0171664
DEBUG:root:[ Iteration 135 ] Training loss: 0.0143576
DEBUG:root:[ Iteration 138 ] Training loss: 0.0148115
DEBUG:root:[ Iteration 140 ] Test loss: 0.0163119
DEBUG:root:[ Iteration 141 ] Training loss: 0.0112487
DEBUG:root:[ Iteration 144 ] Training loss: 0.00998779
DEBUG:root:[ Iteration 147 ] Training loss: 0.0105002
DEBUG:root:[ Iteration 150 ] Training loss: 0.0106118
DEBUG:root:[ Iteration 153 ] Training loss: 0.00859876
DEBUG:root:[ Iteration 156 ] Training loss: 0.00839562
DEBUG:root:[ Iteration 159 ] Training loss: 0.0083531
DEBUG:root:[ Iteration 160 ] Test loss: 0.01096
DEBUG:root:[ Iteration 162 ] Training loss: 0.00779468
DEBUG:root:[ Iteration 165 ] Training loss: 0.00724714
DEBUG:root:[ Iteration 168 ] Training loss: 0.00649706
DEBUG:root:[ Iteration 171 ] Training loss: 0.00640602
DEBUG:root:[ Iteration 174 ] Training loss: 0.0054976
DEBUG:root:[ Iteration 177 ] Training loss: 0.00615463
DEBUG:root:[ Iteration 180 ] Training loss: 0.00549187
DEBUG:root:[ Iteration 180 ] Test loss: 0.00793684
DEBUG:root:[ Iteration 183 ] Training loss: 0.00546456
DEBUG:root:[ Iteration 186 ] Training loss: 0.0047716
DEBUG:root:[ Iteration 189 ] Training loss: 0.00505927
DEBUG:root:[ Iteration 192 ] Training loss: 0.00427114
DEBUG:root:[ Iteration 195 ] Training loss: 0.00446567
DEBUG:root:[ Iteration 198 ] Training loss: 0.00452639
DEBUG:root:[ Iteration 200 ] Test loss: 0.0064845
DEBUG:root:[ Iteration 201 ] Training loss: 0.00423871
DEBUG:root:[ Iteration 204 ] Training loss: 0.00360587
DEBUG:root:[ Iteration 207 ] Training loss: 0.00399853
DEBUG:root:[ Iteration 210 ] Training loss: 0.00397013
DEBUG:root:[ Iteration 213 ] Training loss: 0.00388261
DEBUG:root:[ Iteration 216 ] Training loss: 0.00337716
DEBUG:root:[ Iteration 219 ] Training loss: 0.00412135
DEBUG:root:[ Iteration 220 ] Test loss: 0.00539773
DEBUG:root:[ Iteration 222 ] Training loss: 0.00342753
DEBUG:root:[ Iteration 225 ] Training loss: 0.00355925
DEBUG:root:[ Iteration 228 ] Training loss: 0.00322671
DEBUG:root:[ Iteration 231 ] Training loss: 0.00358544
DEBUG:root:[ Iteration 234 ] Training loss: 0.0031626
DEBUG:root:[ Iteration 237 ] Training loss: 0.00272998
DEBUG:root:[ Iteration 240 ] Training loss: 0.00277212
DEBUG:root:[ Iteration 240 ] Test loss: 0.00472384
DEBUG:root:[ Iteration 243 ] Training loss: 0.00305964
DEBUG:root:[ Iteration 246 ] Training loss: 0.00258827
DEBUG:root:[ Iteration 249 ] Training loss: 0.00278001
DEBUG:root:[ Iteration 252 ] Training loss: 0.00267852
DEBUG:root:[ Iteration 255 ] Training loss: 0.00277895
DEBUG:root:[ Iteration 258 ] Training loss: 0.00257659
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.505113
DEBUG:root:[ Iteration 0 ] Test loss: 0.49772
DEBUG:root:[ Iteration 3 ] Training loss: 0.49874
DEBUG:root:[ Iteration 6 ] Training loss: 0.495841
DEBUG:root:[ Iteration 9 ] Training loss: 0.490391
DEBUG:root:[ Iteration 12 ] Training loss: 0.493524
DEBUG:root:[ Iteration 15 ] Training loss: 0.473346
DEBUG:root:[ Iteration 18 ] Training loss: 0.474337
DEBUG:root:[ Iteration 20 ] Test loss: 0.470473
DEBUG:root:[ Iteration 21 ] Training loss: 0.475564
DEBUG:root:[ Iteration 24 ] Training loss: 0.471574
DEBUG:root:[ Iteration 27 ] Training loss: 0.47237
DEBUG:root:[ Iteration 30 ] Training loss: 0.470539
DEBUG:root:[ Iteration 33 ] Training loss: 0.478609
DEBUG:root:[ Iteration 36 ] Training loss: 0.470513
DEBUG:root:[ Iteration 39 ] Training loss: 0.463861
DEBUG:root:[ Iteration 40 ] Test loss: 0.465553
DEBUG:root:[ Iteration 42 ] Training loss: 0.470315
DEBUG:root:[ Iteration 45 ] Training loss: 0.463641
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.436995
DEBUG:root:[ Iteration 0 ] Test loss: 0.441282
DEBUG:root:[ Iteration 3 ] Training loss: 0.43424
DEBUG:root:[ Iteration 6 ] Training loss: 0.428106
DEBUG:root:[ Iteration 9 ] Training loss: 0.415149
DEBUG:root:[ Iteration 12 ] Training loss: 0.408984
DEBUG:root:[ Iteration 15 ] Training loss: 0.40153
DEBUG:root:[ Iteration 18 ] Training loss: 0.38905
DEBUG:root:[ Iteration 20 ] Test loss: 0.391285
DEBUG:root:[ Iteration 21 ] Training loss: 0.372616
DEBUG:root:[ Iteration 24 ] Training loss: 0.371086
DEBUG:root:[ Iteration 27 ] Training loss: 0.350941
DEBUG:root:[ Iteration 30 ] Training loss: 0.338512
DEBUG:root:[ Iteration 33 ] Training loss: 0.320728
DEBUG:root:[ Iteration 36 ] Training loss: 0.323474
DEBUG:root:[ Iteration 39 ] Training loss: 0.316043
DEBUG:root:[ Iteration 40 ] Test loss: 0.320778
DEBUG:root:[ Iteration 42 ] Training loss: 0.308925
DEBUG:root:[ Iteration 45 ] Training loss: 0.289069
DEBUG:root:[ Iteration 48 ] Training loss: 0.28165
DEBUG:root:[ Iteration 51 ] Training loss: 0.277846
DEBUG:root:[ Iteration 54 ] Training loss: 0.266196
DEBUG:root:[ Iteration 57 ] Training loss: 0.241114
DEBUG:root:[ Iteration 60 ] Training loss: 0.23454
DEBUG:root:[ Iteration 60 ] Test loss: 0.233007
DEBUG:root:[ Iteration 63 ] Training loss: 0.211238
DEBUG:root:[ Iteration 66 ] Training loss: 0.204087
DEBUG:root:[ Iteration 69 ] Training loss: 0.176656
DEBUG:root:[ Iteration 72 ] Training loss: 0.161895
DEBUG:root:[ Iteration 75 ] Training loss: 0.156646
DEBUG:root:[ Iteration 78 ] Training loss: 0.130221
DEBUG:root:[ Iteration 80 ] Test loss: 0.129907
DEBUG:root:[ Iteration 81 ] Training loss: 0.133531
DEBUG:root:[ Iteration 84 ] Training loss: 0.111945
DEBUG:root:[ Iteration 87 ] Training loss: 0.102799
DEBUG:root:[ Iteration 90 ] Training loss: 0.0926342
DEBUG:root:[ Iteration 93 ] Training loss: 0.085271
DEBUG:root:[ Iteration 96 ] Training loss: 0.083506
DEBUG:root:[ Iteration 99 ] Training loss: 0.076437
DEBUG:root:[ Iteration 100 ] Test loss: 0.0719347
DEBUG:root:[ Iteration 102 ] Training loss: 0.0593087
DEBUG:root:[ Iteration 105 ] Training loss: 0.056192
DEBUG:root:[ Iteration 108 ] Training loss: 0.0438858
DEBUG:root:[ Iteration 111 ] Training loss: 0.0501035
DEBUG:root:[ Iteration 114 ] Training loss: 0.0450848
DEBUG:root:[ Iteration 117 ] Training loss: 0.0389633
DEBUG:root:[ Iteration 120 ] Training loss: 0.0366843
DEBUG:root:[ Iteration 120 ] Test loss: 0.0365252
DEBUG:root:[ Iteration 123 ] Training loss: 0.0347415
DEBUG:root:[ Iteration 126 ] Training loss: 0.0315394
DEBUG:root:[ Iteration 129 ] Training loss: 0.0254184
DEBUG:root:[ Iteration 132 ] Training loss: 0.025297
DEBUG:root:[ Iteration 135 ] Training loss: 0.0235699
DEBUG:root:[ Iteration 138 ] Training loss: 0.0246822
DEBUG:root:[ Iteration 140 ] Test loss: 0.0217358
DEBUG:root:[ Iteration 141 ] Training loss: 0.020852
DEBUG:root:[ Iteration 144 ] Training loss: 0.0204614
DEBUG:root:[ Iteration 147 ] Training loss: 0.0187562
DEBUG:root:[ Iteration 150 ] Training loss: 0.019663
DEBUG:root:[ Iteration 153 ] Training loss: 0.0194647
DEBUG:root:[ Iteration 156 ] Training loss: 0.0164371
DEBUG:root:[ Iteration 159 ] Training loss: 0.0178242
DEBUG:root:[ Iteration 160 ] Test loss: 0.0152971
DEBUG:root:[ Iteration 162 ] Training loss: 0.013855
DEBUG:root:[ Iteration 165 ] Training loss: 0.014566
DEBUG:root:[ Iteration 168 ] Training loss: 0.0151598
DEBUG:root:[ Iteration 171 ] Training loss: 0.013527
DEBUG:root:[ Iteration 174 ] Training loss: 0.0124743
DEBUG:root:[ Iteration 177 ] Training loss: 0.0130041
DEBUG:root:[ Iteration 180 ] Training loss: 0.0122876
DEBUG:root:[ Iteration 180 ] Test loss: 0.0118787
DEBUG:root:[ Iteration 183 ] Training loss: 0.0119771
DEBUG:root:[ Iteration 186 ] Training loss: 0.0111279
DEBUG:root:[ Iteration 189 ] Training loss: 0.0108323
DEBUG:root:[ Iteration 192 ] Training loss: 0.0114406
DEBUG:root:[ Iteration 195 ] Training loss: 0.0109906
DEBUG:root:[ Iteration 198 ] Training loss: 0.0109446
DEBUG:root:[ Iteration 200 ] Test loss: 0.00990578
DEBUG:root:[ Iteration 201 ] Training loss: 0.0101451
DEBUG:root:[ Iteration 204 ] Training loss: 0.00950566
DEBUG:root:[ Iteration 207 ] Training loss: 0.00906178
DEBUG:root:[ Iteration 210 ] Training loss: 0.00929515
DEBUG:root:[ Iteration 213 ] Training loss: 0.00920732
DEBUG:root:[ Iteration 216 ] Training loss: 0.00873798
DEBUG:root:[ Iteration 219 ] Training loss: 0.0102631
DEBUG:root:[ Iteration 220 ] Test loss: 0.00836857
DEBUG:root:[ Iteration 222 ] Training loss: 0.00843755
DEBUG:root:[ Iteration 225 ] Training loss: 0.00845763
DEBUG:root:[ Iteration 228 ] Training loss: 0.00803946
DEBUG:root:[ Iteration 231 ] Training loss: 0.0089548
DEBUG:root:[ Iteration 234 ] Training loss: 0.00778004
DEBUG:root:[ Iteration 237 ] Training loss: 0.00794183
DEBUG:root:[ Iteration 240 ] Training loss: 0.00760165
DEBUG:root:[ Iteration 240 ] Test loss: 0.00728256
DEBUG:root:[ Iteration 243 ] Training loss: 0.00751827
DEBUG:root:[ Iteration 246 ] Training loss: 0.00705852
DEBUG:root:[ Iteration 249 ] Training loss: 0.00730893
DEBUG:root:[ Iteration 252 ] Training loss: 0.00673044
DEBUG:root:[ Iteration 255 ] Training loss: 0.00716492
DEBUG:root:[ Iteration 258 ] Training loss: 0.00668236
DEBUG:root:[ Iteration 260 ] Test loss: 0.00639537
DEBUG:root:[ Iteration 261 ] Training loss: 0.00580578
DEBUG:root:[ Iteration 264 ] Training loss: 0.00653882
DEBUG:root:[ Iteration 267 ] Training loss: 0.0068177
DEBUG:root:[ Iteration 270 ] Training loss: 0.00613602
DEBUG:root:[ Iteration 273 ] Training loss: 0.0057041
DEBUG:root:[ Iteration 276 ] Training loss: 0.00600467
DEBUG:root:[ Iteration 279 ] Training loss: 0.00578663
DEBUG:root:[ Iteration 280 ] Test loss: 0.00594422
DEBUG:root:[ Iteration 282 ] Training loss: 0.00576622
DEBUG:root:[ Iteration 285 ] Training loss: 0.00623613
DEBUG:root:[ Iteration 288 ] Training loss: 0.0065812
DEBUG:root:[ Iteration 291 ] Training loss: 0.00560147
DEBUG:root:[ Iteration 294 ] Training loss: 0.00556825
DEBUG:root:[ Iteration 297 ] Training loss: 0.00487673
DEBUG:root:[ Iteration 300 ] Training loss: 0.00557314
DEBUG:root:[ Iteration 300 ] Test loss: 0.00522006
DEBUG:root:[ Iteration 303 ] Training loss: 0.00507396
DEBUG:root:[ Iteration 306 ] Training loss: 0.00545253
DEBUG:root:[ Iteration 309 ] Training loss: 0.0054201
DEBUG:root:[ Iteration 312 ] Training loss: 0.00509685
DEBUG:root:[ Iteration 315 ] Training loss: 0.00518812
DEBUG:root:[ Iteration 318 ] Training loss: 0.0049697
DEBUG:root:[ Iteration 320 ] Test loss: 0.00476622
DEBUG:root:[ Iteration 321 ] Training loss: 0.0050442
DEBUG:root:[ Iteration 324 ] Training loss: 0.00507961
DEBUG:root:[ Iteration 327 ] Training loss: 0.00488777
DEBUG:root:[ Iteration 330 ] Training loss: 0.00493424
DEBUG:root:[ Iteration 333 ] Training loss: 0.00460043
DEBUG:root:[ Iteration 336 ] Training loss: 0.00464588
DEBUG:root:[ Iteration 339 ] Training loss: 0.00482083
DEBUG:root:[ Iteration 340 ] Test loss: 0.00448036
DEBUG:root:[ Iteration 342 ] Training loss: 0.00463595
DEBUG:root:[ Iteration 345 ] Training loss: 0.0040495
DEBUG:root:[ Iteration 348 ] Training loss: 0.0047713
DEBUG:root:[ Iteration 351 ] Training loss: 0.00432163
DEBUG:root:[ Iteration 354 ] Training loss: 0.00448094
DEBUG:root:[ Iteration 357 ] Training loss: 0.00433401
DEBUG:root:[ Iteration 360 ] Training loss: 0.00455572
DEBUG:root:[ Iteration 360 ] Test loss: 0.00413638
DEBUG:root:[ Iteration 363 ] Training loss: 0.00388582
DEBUG:root:[ Iteration 366 ] Training loss: 0.00414703
DEBUG:root:[ Iteration 369 ] Training loss: 0.00422178
DEBUG:root:[ Iteration 372 ] Training loss: 0.00451555
DEBUG:root:[ Iteration 375 ] Training loss: 0.00410852
DEBUG:root:[ Iteration 378 ] Training loss: 0.0040523
DEBUG:root:[ Iteration 380 ] Test loss: 0.00387898
DEBUG:root:[ Iteration 381 ] Training loss: 0.00373854
DEBUG:root:[ Iteration 384 ] Training loss: 0.00381028
DEBUG:root:[ Iteration 387 ] Training loss: 0.00387507
DEBUG:root:[ Iteration 390 ] Training loss: 0.00406682
DEBUG:root:[ Iteration 393 ] Training loss: 0.00439803
DEBUG:root:[ Iteration 396 ] Training loss: 0.00393342
DEBUG:root:[ Iteration 399 ] Training loss: 0.00398001
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-11-2016_23h42m43s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.49506
DEBUG:root:[ Iteration 0 ] Test loss: 0.491983
DEBUG:root:[ Iteration 3 ] Training loss: 0.494326
DEBUG:root:[ Iteration 6 ] Training loss: 0.497728
DEBUG:root:[ Iteration 9 ] Training loss: 0.497425
DEBUG:root:[ Iteration 12 ] Training loss: 0.495956
DEBUG:root:[ Iteration 15 ] Training loss: 0.491638
DEBUG:root:[ Iteration 18 ] Training loss: 0.495773
DEBUG:root:[ Iteration 20 ] Test loss: 0.487239
DEBUG:root:[ Iteration 21 ] Training loss: 0.497606
DEBUG:root:[ Iteration 24 ] Training loss: 0.505623
DEBUG:root:[ Iteration 27 ] Training loss: 0.50689
DEBUG:root:[ Iteration 30 ] Training loss: 0.501854
DEBUG:root:[ Iteration 33 ] Training loss: 0.507263
DEBUG:root:[ Iteration 36 ] Training loss: 0.50268
DEBUG:root:[ Iteration 39 ] Training loss: 0.505286
DEBUG:root:[ Iteration 40 ] Test loss: 0.501911
DEBUG:root:[ Iteration 42 ] Training loss: 0.507126
DEBUG:root:[ Iteration 45 ] Training loss: 0.515894
DEBUG:root:[ Iteration 48 ] Training loss: 0.505734
DEBUG:root:[ Iteration 51 ] Training loss: 0.501121
DEBUG:root:[ Iteration 54 ] Training loss: 0.502309
DEBUG:root:[ Iteration 57 ] Training loss: 0.507273
DEBUG:root:[ Iteration 60 ] Training loss: 0.50876
DEBUG:root:[ Iteration 60 ] Test loss: 0.503325
DEBUG:root:[ Iteration 63 ] Training loss: 0.513121
DEBUG:root:[ Iteration 66 ] Training loss: 0.509714
DEBUG:root:[ Iteration 69 ] Training loss: 0.502984
DEBUG:root:[ Iteration 72 ] Training loss: 0.502416
DEBUG:root:[ Iteration 75 ] Training loss: 0.509194
DEBUG:root:[ Iteration 78 ] Training loss: 0.511896
DEBUG:root:[ Iteration 80 ] Test loss: 0.506234
DEBUG:root:[ Iteration 81 ] Training loss: 0.511584
DEBUG:root:[ Iteration 84 ] Training loss: 0.510798
DEBUG:root:[ Iteration 87 ] Training loss: 0.504784
DEBUG:root:[ Iteration 90 ] Training loss: 0.497775
DEBUG:root:[ Iteration 93 ] Training loss: 0.510859
DEBUG:root:[ Iteration 96 ] Training loss: 0.509873
DEBUG:root:[ Iteration 99 ] Training loss: 0.511735
DEBUG:root:[ Iteration 100 ] Test loss: 0.496741
DEBUG:root:[ Iteration 102 ] Training loss: 0.503781
DEBUG:root:[ Iteration 105 ] Training loss: 0.506975
DEBUG:root:[ Iteration 108 ] Training loss: 0.509201
DEBUG:root:[ Iteration 111 ] Training loss: 0.513839
DEBUG:root:[ Iteration 114 ] Training loss: 0.497598
DEBUG:root:[ Iteration 117 ] Training loss: 0.495477
DEBUG:root:[ Iteration 120 ] Training loss: 0.503625
DEBUG:root:[ Iteration 120 ] Test loss: 0.499077
DEBUG:root:[ Iteration 123 ] Training loss: 0.507712
DEBUG:root:[ Iteration 126 ] Training loss: 0.510231
DEBUG:root:[ Iteration 129 ] Training loss: 0.499222
DEBUG:root:[ Iteration 132 ] Training loss: 0.502964
DEBUG:root:[ Iteration 135 ] Training loss: 0.502042
DEBUG:root:[ Iteration 138 ] Training loss: 0.508956
DEBUG:root:[ Iteration 140 ] Test loss: 0.495772
DEBUG:root:[ Iteration 141 ] Training loss: 0.502414
DEBUG:root:[ Iteration 144 ] Training loss: 0.497224
DEBUG:root:[ Iteration 147 ] Training loss: 0.501458
DEBUG:root:[ Iteration 150 ] Training loss: 0.498454
DEBUG:root:[ Iteration 153 ] Training loss: 0.495794
DEBUG:root:[ Iteration 156 ] Training loss: 0.501236
DEBUG:root:[ Iteration 159 ] Training loss: 0.500881
DEBUG:root:[ Iteration 160 ] Test loss: 0.493254
DEBUG:root:[ Iteration 162 ] Training loss: 0.50547
DEBUG:root:[ Iteration 165 ] Training loss: 0.502226
DEBUG:root:[ Iteration 168 ] Training loss: 0.501707
DEBUG:root:[ Iteration 171 ] Training loss: 0.502291
DEBUG:root:[ Iteration 174 ] Training loss: 0.494294
DEBUG:root:[ Iteration 177 ] Training loss: 0.493839
DEBUG:root:[ Iteration 180 ] Training loss: 0.497677
DEBUG:root:[ Iteration 180 ] Test loss: 0.492835
DEBUG:root:[ Iteration 183 ] Training loss: 0.496784
DEBUG:root:[ Iteration 186 ] Training loss: 0.503037
DEBUG:root:[ Iteration 189 ] Training loss: 0.503342
DEBUG:root:[ Iteration 192 ] Training loss: 0.48981
DEBUG:root:[ Iteration 195 ] Training loss: 0.491309
DEBUG:root:[ Iteration 198 ] Training loss: 0.487738
DEBUG:root:[ Iteration 200 ] Test loss: 0.486494
DEBUG:root:[ Iteration 201 ] Training loss: 0.487322
DEBUG:root:[ Iteration 204 ] Training loss: 0.491389
DEBUG:root:[ Iteration 207 ] Training loss: 0.48852
DEBUG:root:[ Iteration 210 ] Training loss: 0.48005
DEBUG:root:[ Iteration 213 ] Training loss: 0.461567
DEBUG:root:[ Iteration 216 ] Training loss: 0.471087
DEBUG:root:[ Iteration 219 ] Training loss: 0.471807
DEBUG:root:[ Iteration 220 ] Test loss: 0.473142
DEBUG:root:[ Iteration 222 ] Training loss: 0.462436
DEBUG:root:[ Iteration 225 ] Training loss: 0.457133
DEBUG:root:[ Iteration 228 ] Training loss: 0.461787
DEBUG:root:[ Iteration 231 ] Training loss: 0.453657
DEBUG:root:[ Iteration 234 ] Training loss: 0.448173
DEBUG:root:[ Iteration 237 ] Training loss: 0.457596
DEBUG:root:[ Iteration 240 ] Training loss: 0.448815
DEBUG:root:[ Iteration 240 ] Test loss: 0.446726
DEBUG:root:[ Iteration 243 ] Training loss: 0.44446
DEBUG:root:[ Iteration 246 ] Training loss: 0.450135
DEBUG:root:[ Iteration 249 ] Training loss: 0.447134
DEBUG:root:[ Iteration 252 ] Training loss: 0.441604
DEBUG:root:[ Iteration 255 ] Training loss: 0.444595
DEBUG:root:[ Iteration 258 ] Training loss: 0.433441
DEBUG:root:[ Iteration 260 ] Test loss: 0.425355
DEBUG:root:[ Iteration 261 ] Training loss: 0.419985
DEBUG:root:[ Iteration 264 ] Training loss: 0.423058
DEBUG:root:[ Iteration 267 ] Training loss: 0.435367
DEBUG:root:[ Iteration 270 ] Training loss: 0.429275
DEBUG:root:[ Iteration 273 ] Training loss: 0.424633
DEBUG:root:[ Iteration 276 ] Training loss: 0.429677
DEBUG:root:[ Iteration 279 ] Training loss: 0.410412
DEBUG:root:[ Iteration 280 ] Test loss: 0.411993
DEBUG:root:[ Iteration 282 ] Training loss: 0.418875
DEBUG:root:[ Iteration 285 ] Training loss: 0.41313
DEBUG:root:[ Iteration 288 ] Training loss: 0.408736
DEBUG:root:[ Iteration 291 ] Training loss: 0.418916
DEBUG:root:[ Iteration 294 ] Training loss: 0.416107
DEBUG:root:[ Iteration 297 ] Training loss: 0.401539
DEBUG:root:[ Iteration 300 ] Training loss: 0.385127
DEBUG:root:[ Iteration 300 ] Test loss: 0.37915
DEBUG:root:[ Iteration 303 ] Training loss: 0.350151
DEBUG:root:[ Iteration 306 ] Training loss: 0.307426
DEBUG:root:[ Iteration 309 ] Training loss: 0.25922
DEBUG:root:[ Iteration 312 ] Training loss: 0.250141
DEBUG:root:[ Iteration 315 ] Training loss: 0.237285
DEBUG:root:[ Iteration 318 ] Training loss: 0.211936
DEBUG:root:[ Iteration 320 ] Test loss: 0.18191
DEBUG:root:[ Iteration 321 ] Training loss: 0.183107
DEBUG:root:[ Iteration 324 ] Training loss: 0.142576
DEBUG:root:[ Iteration 327 ] Training loss: 0.121857
DEBUG:root:[ Iteration 330 ] Training loss: 0.0931982
DEBUG:root:[ Iteration 333 ] Training loss: 0.0747588
DEBUG:root:[ Iteration 336 ] Training loss: 0.060689
DEBUG:root:[ Iteration 339 ] Training loss: 0.0408254
DEBUG:root:[ Iteration 340 ] Test loss: 0.038903
DEBUG:root:[ Iteration 342 ] Training loss: 0.0345443
DEBUG:root:[ Iteration 345 ] Training loss: 0.0274092
DEBUG:root:[ Iteration 348 ] Training loss: 0.0238774
DEBUG:root:[ Iteration 351 ] Training loss: 0.0181445
DEBUG:root:[ Iteration 354 ] Training loss: 0.0166506
DEBUG:root:[ Iteration 357 ] Training loss: 0.0126352
DEBUG:root:[ Iteration 360 ] Training loss: 0.0116396
DEBUG:root:[ Iteration 360 ] Test loss: 0.0125739
DEBUG:root:[ Iteration 363 ] Training loss: 0.0105909
DEBUG:root:[ Iteration 366 ] Training loss: 0.00968001
DEBUG:root:[ Iteration 369 ] Training loss: 0.00883645
DEBUG:root:[ Iteration 372 ] Training loss: 0.00857127
DEBUG:root:[ Iteration 375 ] Training loss: 0.00857496
DEBUG:root:[ Iteration 378 ] Training loss: 0.00741143
DEBUG:root:[ Iteration 380 ] Test loss: 0.00762356
DEBUG:root:[ Iteration 381 ] Training loss: 0.0072218
DEBUG:root:[ Iteration 384 ] Training loss: 0.0063634
DEBUG:root:[ Iteration 387 ] Training loss: 0.00711018
DEBUG:root:[ Iteration 390 ] Training loss: 0.00620856
DEBUG:root:[ Iteration 393 ] Training loss: 0.00652194
DEBUG:root:[ Iteration 396 ] Training loss: 0.00545576
DEBUG:root:[ Iteration 399 ] Training loss: 0.00532957
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_00h08m36s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.392012
DEBUG:root:[ Iteration 0 ] Test loss: 0.391773
DEBUG:root:[ Iteration 3 ] Training loss: 0.372109
DEBUG:root:[ Iteration 6 ] Training loss: 0.373819
DEBUG:root:[ Iteration 9 ] Training loss: 0.346594
DEBUG:root:[ Iteration 12 ] Training loss: 0.360382
DEBUG:root:[ Iteration 15 ] Training loss: 0.369167
DEBUG:root:[ Iteration 18 ] Training loss: 0.364545
DEBUG:root:[ Iteration 20 ] Test loss: 0.380283
DEBUG:root:[ Iteration 21 ] Training loss: 0.374683
DEBUG:root:[ Iteration 24 ] Training loss: 0.381132
DEBUG:root:[ Iteration 27 ] Training loss: 0.351563
DEBUG:root:[ Iteration 30 ] Training loss: 0.335572
DEBUG:root:[ Iteration 33 ] Training loss: 0.34003
DEBUG:root:[ Iteration 36 ] Training loss: 0.337979
DEBUG:root:[ Iteration 39 ] Training loss: 0.331287
DEBUG:root:[ Iteration 40 ] Test loss: 0.338024
DEBUG:root:[ Iteration 42 ] Training loss: 0.325302
DEBUG:root:[ Iteration 45 ] Training loss: 0.340094
DEBUG:root:[ Iteration 48 ] Training loss: 0.319152
DEBUG:root:[ Iteration 51 ] Training loss: 0.325346
DEBUG:root:[ Iteration 54 ] Training loss: 0.337328
DEBUG:root:[ Iteration 57 ] Training loss: 0.339199
DEBUG:root:[ Iteration 60 ] Training loss: 0.353452
DEBUG:root:[ Iteration 60 ] Test loss: 0.338153
DEBUG:root:[ Iteration 63 ] Training loss: 0.325259
DEBUG:root:[ Iteration 66 ] Training loss: 0.325479
DEBUG:root:[ Iteration 69 ] Training loss: 0.317685
DEBUG:root:[ Iteration 72 ] Training loss: 0.324171
DEBUG:root:[ Iteration 75 ] Training loss: 0.290078
DEBUG:root:[ Iteration 78 ] Training loss: 0.308036
DEBUG:root:[ Iteration 80 ] Test loss: 0.31386
DEBUG:root:[ Iteration 81 ] Training loss: 0.313682
DEBUG:root:[ Iteration 84 ] Training loss: 0.317677
DEBUG:root:[ Iteration 87 ] Training loss: 0.310421
DEBUG:root:[ Iteration 90 ] Training loss: 0.28831
DEBUG:root:[ Iteration 93 ] Training loss: 0.272785
DEBUG:root:[ Iteration 96 ] Training loss: 0.271924
DEBUG:root:[ Iteration 99 ] Training loss: 0.277743
DEBUG:root:[ Iteration 100 ] Test loss: 0.295086
DEBUG:root:[ Iteration 102 ] Training loss: 0.256221
DEBUG:root:[ Iteration 105 ] Training loss: 0.257134
DEBUG:root:[ Iteration 108 ] Training loss: 0.240689
DEBUG:root:[ Iteration 111 ] Training loss: 0.230844
DEBUG:root:[ Iteration 114 ] Training loss: 0.222763
DEBUG:root:[ Iteration 117 ] Training loss: 0.224823
DEBUG:root:[ Iteration 120 ] Training loss: 0.217884
DEBUG:root:[ Iteration 120 ] Test loss: 0.222434
DEBUG:root:[ Iteration 123 ] Training loss: 0.207725
DEBUG:root:[ Iteration 126 ] Training loss: 0.205239
DEBUG:root:[ Iteration 129 ] Training loss: 0.199936
DEBUG:root:[ Iteration 132 ] Training loss: 0.182758
DEBUG:root:[ Iteration 135 ] Training loss: 0.188614
DEBUG:root:[ Iteration 138 ] Training loss: 0.170849
DEBUG:root:[ Iteration 140 ] Test loss: 0.18367
DEBUG:root:[ Iteration 141 ] Training loss: 0.168125
DEBUG:root:[ Iteration 144 ] Training loss: 0.1599
DEBUG:root:[ Iteration 147 ] Training loss: 0.14926
DEBUG:root:[ Iteration 150 ] Training loss: 0.15935
DEBUG:root:[ Iteration 153 ] Training loss: 0.154997
DEBUG:root:[ Iteration 156 ] Training loss: 0.13847
DEBUG:root:[ Iteration 159 ] Training loss: 0.14283
DEBUG:root:[ Iteration 160 ] Test loss: 0.148284
DEBUG:root:[ Iteration 162 ] Training loss: 0.142774
DEBUG:root:[ Iteration 165 ] Training loss: 0.147023
DEBUG:root:[ Iteration 168 ] Training loss: 0.124624
DEBUG:root:[ Iteration 171 ] Training loss: 0.123937
DEBUG:root:[ Iteration 174 ] Training loss: 0.108441
DEBUG:root:[ Iteration 177 ] Training loss: 0.119944
DEBUG:root:[ Iteration 180 ] Training loss: 0.09358
DEBUG:root:[ Iteration 180 ] Test loss: 0.118751
DEBUG:root:[ Iteration 183 ] Training loss: 0.112996
DEBUG:root:[ Iteration 186 ] Training loss: 0.0987354
DEBUG:root:[ Iteration 189 ] Training loss: 0.0907026
DEBUG:root:[ Iteration 192 ] Training loss: 0.0925406
DEBUG:root:[ Iteration 195 ] Training loss: 0.102671
DEBUG:root:[ Iteration 198 ] Training loss: 0.100943
DEBUG:root:[ Iteration 200 ] Test loss: 0.0940809
DEBUG:root:[ Iteration 201 ] Training loss: 0.0907732
DEBUG:root:[ Iteration 204 ] Training loss: 0.0827
DEBUG:root:[ Iteration 207 ] Training loss: 0.0930675
DEBUG:root:[ Iteration 210 ] Training loss: 0.0758071
DEBUG:root:[ Iteration 213 ] Training loss: 0.0701739
DEBUG:root:[ Iteration 216 ] Training loss: 0.0847808
DEBUG:root:[ Iteration 219 ] Training loss: 0.0711651
DEBUG:root:[ Iteration 220 ] Test loss: 0.0774947
DEBUG:root:[ Iteration 222 ] Training loss: 0.0848649
DEBUG:root:[ Iteration 225 ] Training loss: 0.0713524
DEBUG:root:[ Iteration 228 ] Training loss: 0.0732106
DEBUG:root:[ Iteration 231 ] Training loss: 0.0664951
DEBUG:root:[ Iteration 234 ] Training loss: 0.062773
DEBUG:root:[ Iteration 237 ] Training loss: 0.0591121
DEBUG:root:[ Iteration 240 ] Training loss: 0.0539891
DEBUG:root:[ Iteration 240 ] Test loss: 0.065868
DEBUG:root:[ Iteration 243 ] Training loss: 0.0648275
DEBUG:root:[ Iteration 246 ] Training loss: 0.0570336
DEBUG:root:[ Iteration 249 ] Training loss: 0.056975
DEBUG:root:[ Iteration 252 ] Training loss: 0.0524197
DEBUG:root:[ Iteration 255 ] Training loss: 0.0519902
DEBUG:root:[ Iteration 258 ] Training loss: 0.0589518
DEBUG:root:[ Iteration 260 ] Test loss: 0.0597039
DEBUG:root:[ Iteration 261 ] Training loss: 0.0656098
DEBUG:root:[ Iteration 264 ] Training loss: 0.059451
DEBUG:root:[ Iteration 267 ] Training loss: 0.0574805
DEBUG:root:[ Iteration 270 ] Training loss: 0.0474115
DEBUG:root:[ Iteration 273 ] Training loss: 0.0469569
DEBUG:root:[ Iteration 276 ] Training loss: 0.0472475
DEBUG:root:[ Iteration 279 ] Training loss: 0.0503115
DEBUG:root:[ Iteration 280 ] Test loss: 0.0549921
DEBUG:root:[ Iteration 282 ] Training loss: 0.0500408
DEBUG:root:[ Iteration 285 ] Training loss: 0.0634867
DEBUG:root:[ Iteration 288 ] Training loss: 0.0648124
DEBUG:root:[ Iteration 291 ] Training loss: 0.0425804
DEBUG:root:[ Iteration 294 ] Training loss: 0.0456264
DEBUG:root:[ Iteration 297 ] Training loss: 0.0524129
DEBUG:root:[ Iteration 300 ] Training loss: 0.0529313
DEBUG:root:[ Iteration 300 ] Test loss: 0.0521029
DEBUG:root:[ Iteration 303 ] Training loss: 0.0385665
DEBUG:root:[ Iteration 306 ] Training loss: 0.0491254
DEBUG:root:[ Iteration 309 ] Training loss: 0.0488095
DEBUG:root:[ Iteration 312 ] Training loss: 0.0521996
DEBUG:root:[ Iteration 315 ] Training loss: 0.0403565
DEBUG:root:[ Iteration 318 ] Training loss: 0.0463718
DEBUG:root:[ Iteration 320 ] Test loss: 0.0491174
DEBUG:root:[ Iteration 321 ] Training loss: 0.043019
DEBUG:root:[ Iteration 324 ] Training loss: 0.0485241
DEBUG:root:[ Iteration 327 ] Training loss: 0.0424749
DEBUG:root:[ Iteration 330 ] Training loss: 0.0353181
DEBUG:root:[ Iteration 333 ] Training loss: 0.0293788
DEBUG:root:[ Iteration 336 ] Training loss: 0.0544658
DEBUG:root:[ Iteration 339 ] Training loss: 0.0398025
DEBUG:root:[ Iteration 340 ] Test loss: 0.0484833
DEBUG:root:[ Iteration 342 ] Training loss: 0.0440842
DEBUG:root:[ Iteration 345 ] Training loss: 0.0351712
DEBUG:root:[ Iteration 348 ] Training loss: 0.0422588
DEBUG:root:[ Iteration 351 ] Training loss: 0.0412785
DEBUG:root:[ Iteration 354 ] Training loss: 0.0447649
DEBUG:root:[ Iteration 357 ] Training loss: 0.0474999
DEBUG:root:[ Iteration 360 ] Training loss: 0.0537633
DEBUG:root:[ Iteration 360 ] Test loss: 0.0468441
DEBUG:root:[ Iteration 363 ] Training loss: 0.0323066
DEBUG:root:[ Iteration 366 ] Training loss: 0.0446857
DEBUG:root:[ Iteration 369 ] Training loss: 0.034114
DEBUG:root:[ Iteration 372 ] Training loss: 0.0441402
DEBUG:root:[ Iteration 375 ] Training loss: 0.0539382
DEBUG:root:[ Iteration 378 ] Training loss: 0.0363858
DEBUG:root:[ Iteration 380 ] Test loss: 0.044735
DEBUG:root:[ Iteration 381 ] Training loss: 0.0425639
DEBUG:root:[ Iteration 384 ] Training loss: 0.0399855
DEBUG:root:[ Iteration 387 ] Training loss: 0.0359681
DEBUG:root:[ Iteration 390 ] Training loss: 0.043658
DEBUG:root:[ Iteration 393 ] Training loss: 0.0492987
DEBUG:root:[ Iteration 396 ] Training loss: 0.0293151
DEBUG:root:[ Iteration 399 ] Training loss: 0.0401296
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_16h09m01s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.939127
DEBUG:root:[ Iteration 0 ] Test loss: 0.935976
DEBUG:root:[ Iteration 3 ] Training loss: 0.494387
DEBUG:root:[ Iteration 6 ] Training loss: 0.471439
DEBUG:root:[ Iteration 9 ] Training loss: 0.488611
DEBUG:root:[ Iteration 12 ] Training loss: 0.484007
DEBUG:root:[ Iteration 15 ] Training loss: 0.48123
DEBUG:root:[ Iteration 18 ] Training loss: 0.4983
DEBUG:root:[ Iteration 20 ] Test loss: 0.476147
DEBUG:root:[ Iteration 21 ] Training loss: 0.504446
DEBUG:root:[ Iteration 24 ] Training loss: 0.476766
DEBUG:root:[ Iteration 27 ] Training loss: 0.474824
DEBUG:root:[ Iteration 30 ] Training loss: 0.383624
DEBUG:root:[ Iteration 33 ] Training loss: 0.356774
DEBUG:root:[ Iteration 36 ] Training loss: 0.365335
DEBUG:root:[ Iteration 39 ] Training loss: 0.366437
DEBUG:root:[ Iteration 40 ] Test loss: 0.371573
DEBUG:root:[ Iteration 42 ] Training loss: 0.367206
DEBUG:root:[ Iteration 45 ] Training loss: 0.369308
DEBUG:root:[ Iteration 48 ] Training loss: 0.381196
DEBUG:root:[ Iteration 51 ] Training loss: 0.339962
DEBUG:root:[ Iteration 54 ] Training loss: 0.380228
DEBUG:root:[ Iteration 57 ] Training loss: 0.384627
DEBUG:root:[ Iteration 60 ] Training loss: 0.396889
DEBUG:root:[ Iteration 60 ] Test loss: 0.383083
DEBUG:root:[ Iteration 63 ] Training loss: 0.377193
DEBUG:root:[ Iteration 66 ] Training loss: 0.366372
DEBUG:root:[ Iteration 69 ] Training loss: 0.358919
DEBUG:root:[ Iteration 72 ] Training loss: 0.386558
DEBUG:root:[ Iteration 75 ] Training loss: 0.383635
DEBUG:root:[ Iteration 78 ] Training loss: 0.368701
DEBUG:root:[ Iteration 80 ] Test loss: 0.381229
DEBUG:root:[ Iteration 81 ] Training loss: 0.363481
DEBUG:root:[ Iteration 84 ] Training loss: 0.384553
DEBUG:root:[ Iteration 87 ] Training loss: 0.377888
DEBUG:root:[ Iteration 90 ] Training loss: 0.395092
DEBUG:root:[ Iteration 93 ] Training loss: 0.364011
DEBUG:root:[ Iteration 96 ] Training loss: 0.393686
DEBUG:root:[ Iteration 99 ] Training loss: 0.386161
DEBUG:root:[ Iteration 100 ] Test loss: 0.381845
DEBUG:root:[ Iteration 102 ] Training loss: 0.383011
DEBUG:root:[ Iteration 105 ] Training loss: 0.374099
DEBUG:root:[ Iteration 108 ] Training loss: 0.367478
DEBUG:root:[ Iteration 111 ] Training loss: 0.373305
DEBUG:root:[ Iteration 114 ] Training loss: 0.386762
DEBUG:root:[ Iteration 117 ] Training loss: 0.388942
DEBUG:root:[ Iteration 120 ] Training loss: 0.406345
DEBUG:root:[ Iteration 120 ] Test loss: 0.389645
DEBUG:root:[ Iteration 123 ] Training loss: 0.381547
DEBUG:root:[ Iteration 126 ] Training loss: 0.377834
DEBUG:root:[ Iteration 129 ] Training loss: 0.379423
DEBUG:root:[ Iteration 132 ] Training loss: 0.401115
DEBUG:root:[ Iteration 135 ] Training loss: 0.383605
DEBUG:root:[ Iteration 138 ] Training loss: 0.396614
DEBUG:root:[ Iteration 140 ] Test loss: 0.389645
DEBUG:root:[ Iteration 141 ] Training loss: 0.389909
DEBUG:root:[ Iteration 144 ] Training loss: 0.383165
DEBUG:root:[ Iteration 147 ] Training loss: 0.385343
DEBUG:root:[ Iteration 150 ] Training loss: 0.391775
DEBUG:root:[ Iteration 153 ] Training loss: 0.382004
DEBUG:root:[ Iteration 156 ] Training loss: 0.395248
DEBUG:root:[ Iteration 159 ] Training loss: 0.386451
DEBUG:root:[ Iteration 160 ] Test loss: 0.389645
DEBUG:root:[ Iteration 162 ] Training loss: 0.38432
DEBUG:root:[ Iteration 165 ] Training loss: 0.389365
DEBUG:root:[ Iteration 168 ] Training loss: 0.379676
DEBUG:root:[ Iteration 171 ] Training loss: 0.386612
DEBUG:root:[ Iteration 174 ] Training loss: 0.39848
DEBUG:root:[ Iteration 177 ] Training loss: 0.406238
DEBUG:root:[ Iteration 180 ] Training loss: 0.395849
DEBUG:root:[ Iteration 180 ] Test loss: 0.389645
DEBUG:root:[ Iteration 183 ] Training loss: 0.397394
DEBUG:root:[ Iteration 186 ] Training loss: 0.377233
DEBUG:root:[ Iteration 189 ] Training loss: 0.394007
DEBUG:root:[ Iteration 192 ] Training loss: 0.380725
DEBUG:root:[ Iteration 195 ] Training loss: 0.385856
DEBUG:root:[ Iteration 198 ] Training loss: 0.40006
DEBUG:root:[ Iteration 200 ] Test loss: 0.389645
DEBUG:root:[ Iteration 201 ] Training loss: 0.386083
DEBUG:root:[ Iteration 204 ] Training loss: 0.381017
DEBUG:root:[ Iteration 207 ] Training loss: 0.399575
DEBUG:root:[ Iteration 210 ] Training loss: 0.380215
DEBUG:root:[ Iteration 213 ] Training loss: 0.403434
DEBUG:root:[ Iteration 216 ] Training loss: 0.39305
DEBUG:root:[ Iteration 219 ] Training loss: 0.37596
DEBUG:root:[ Iteration 220 ] Test loss: 0.389645
DEBUG:root:[ Iteration 222 ] Training loss: 0.382329
DEBUG:root:[ Iteration 225 ] Training loss: 0.398179
DEBUG:root:[ Iteration 228 ] Training loss: 0.392108
DEBUG:root:[ Iteration 231 ] Training loss: 0.394882
DEBUG:root:[ Iteration 234 ] Training loss: 0.398801
DEBUG:root:[ Iteration 237 ] Training loss: 0.383639
DEBUG:root:[ Iteration 240 ] Training loss: 0.390847
DEBUG:root:[ Iteration 240 ] Test loss: 0.389645
DEBUG:root:[ Iteration 243 ] Training loss: 0.382404
DEBUG:root:[ Iteration 246 ] Training loss: 0.384874
DEBUG:root:[ Iteration 249 ] Training loss: 0.407078
DEBUG:root:[ Iteration 252 ] Training loss: 0.394639
DEBUG:root:[ Iteration 255 ] Training loss: 0.394061
DEBUG:root:[ Iteration 258 ] Training loss: 0.381747
DEBUG:root:[ Iteration 260 ] Test loss: 0.389645
DEBUG:root:[ Iteration 261 ] Training loss: 0.394525
DEBUG:root:[ Iteration 264 ] Training loss: 0.404383
DEBUG:root:[ Iteration 267 ] Training loss: 0.40421
DEBUG:root:[ Iteration 270 ] Training loss: 0.386308
DEBUG:root:[ Iteration 273 ] Training loss: 0.358305
DEBUG:root:[ Iteration 276 ] Training loss: 0.405251
DEBUG:root:[ Iteration 279 ] Training loss: 0.365678
DEBUG:root:[ Iteration 280 ] Test loss: 0.389645
DEBUG:root:[ Iteration 282 ] Training loss: 0.377831
DEBUG:root:[ Iteration 285 ] Training loss: 0.387874
DEBUG:root:Saving...
DEBUG:root:[ Iteration 0 ] Training loss: 0.848685
DEBUG:root:[ Iteration 0 ] Test loss: 0.833756
DEBUG:root:[ Iteration 3 ] Training loss: 0.814486
DEBUG:root:[ Iteration 6 ] Training loss: 0.784362
DEBUG:root:[ Iteration 9 ] Training loss: 0.637761
DEBUG:root:[ Iteration 12 ] Training loss: 0.352507
DEBUG:root:[ Iteration 15 ] Training loss: 0.378942
DEBUG:root:[ Iteration 18 ] Training loss: 0.361367
DEBUG:root:[ Iteration 20 ] Test loss: 0.366814
DEBUG:root:[ Iteration 21 ] Training loss: 0.371161
DEBUG:root:[ Iteration 24 ] Training loss: 0.372686
DEBUG:root:[ Iteration 27 ] Training loss: 0.367746
DEBUG:root:[ Iteration 30 ] Training loss: 0.363776
DEBUG:root:[ Iteration 33 ] Training loss: 0.358782
DEBUG:root:[ Iteration 36 ] Training loss: 0.360365
DEBUG:root:[ Iteration 39 ] Training loss: 0.356078
DEBUG:root:[ Iteration 40 ] Test loss: 0.35976
DEBUG:root:[ Iteration 42 ] Training loss: 0.361992
DEBUG:root:[ Iteration 45 ] Training loss: 0.351197
DEBUG:root:[ Iteration 48 ] Training loss: 0.351137
DEBUG:root:[ Iteration 51 ] Training loss: 0.343642
DEBUG:root:[ Iteration 54 ] Training loss: 0.349756
DEBUG:root:[ Iteration 57 ] Training loss: 0.336859
DEBUG:root:[ Iteration 60 ] Training loss: 0.351121
DEBUG:root:[ Iteration 60 ] Test loss: 0.353086
DEBUG:root:[ Iteration 63 ] Training loss: 0.353381
DEBUG:root:[ Iteration 66 ] Training loss: 0.329704
DEBUG:root:[ Iteration 69 ] Training loss: 0.343053
DEBUG:root:[ Iteration 72 ] Training loss: 0.328977
DEBUG:root:[ Iteration 75 ] Training loss: 0.318214
DEBUG:root:[ Iteration 78 ] Training loss: 0.314529
DEBUG:root:[ Iteration 80 ] Test loss: 0.319232
DEBUG:root:[ Iteration 81 ] Training loss: 0.312238
DEBUG:root:[ Iteration 84 ] Training loss: 0.289965
DEBUG:root:[ Iteration 87 ] Training loss: 0.303981
DEBUG:root:[ Iteration 90 ] Training loss: 0.310117
DEBUG:root:[ Iteration 93 ] Training loss: 0.302153
DEBUG:root:[ Iteration 96 ] Training loss: 0.294162
DEBUG:root:[ Iteration 99 ] Training loss: 0.289068
DEBUG:root:[ Iteration 100 ] Test loss: 0.277318
DEBUG:root:[ Iteration 102 ] Training loss: 0.274362
DEBUG:root:[ Iteration 105 ] Training loss: 0.257768
DEBUG:root:[ Iteration 108 ] Training loss: 0.259219
DEBUG:root:[ Iteration 111 ] Training loss: 0.263314
DEBUG:root:[ Iteration 114 ] Training loss: 0.221888
DEBUG:root:[ Iteration 117 ] Training loss: 0.231658
DEBUG:root:[ Iteration 120 ] Training loss: 0.200974
DEBUG:root:[ Iteration 120 ] Test loss: 0.218585
DEBUG:root:[ Iteration 123 ] Training loss: 0.202525
DEBUG:root:[ Iteration 126 ] Training loss: 0.196762
DEBUG:root:[ Iteration 129 ] Training loss: 0.192222
DEBUG:root:[ Iteration 132 ] Training loss: 0.179806
DEBUG:root:[ Iteration 135 ] Training loss: 0.166396
DEBUG:root:[ Iteration 138 ] Training loss: 0.161927
DEBUG:root:[ Iteration 140 ] Test loss: 0.163741
DEBUG:root:[ Iteration 141 ] Training loss: 0.167428
DEBUG:root:[ Iteration 144 ] Training loss: 0.142376
DEBUG:root:[ Iteration 147 ] Training loss: 0.131422
DEBUG:root:[ Iteration 150 ] Training loss: 0.165807
DEBUG:root:[ Iteration 153 ] Training loss: 0.117485
DEBUG:root:[ Iteration 156 ] Training loss: 0.123571
DEBUG:root:[ Iteration 159 ] Training loss: 0.106484
DEBUG:root:[ Iteration 160 ] Test loss: 0.121729
DEBUG:root:[ Iteration 162 ] Training loss: 0.115558
DEBUG:root:[ Iteration 165 ] Training loss: 0.0984779
DEBUG:root:[ Iteration 168 ] Training loss: 0.0891589
DEBUG:root:[ Iteration 171 ] Training loss: 0.106964
DEBUG:root:[ Iteration 174 ] Training loss: 0.0981745
DEBUG:root:[ Iteration 177 ] Training loss: 0.101475
DEBUG:root:[ Iteration 180 ] Training loss: 0.0945145
DEBUG:root:[ Iteration 180 ] Test loss: 0.106269
DEBUG:root:[ Iteration 183 ] Training loss: 0.0896578
DEBUG:root:[ Iteration 186 ] Training loss: 0.10055
DEBUG:root:[ Iteration 189 ] Training loss: 0.0803721
DEBUG:root:[ Iteration 192 ] Training loss: 0.0863144
DEBUG:root:[ Iteration 195 ] Training loss: 0.0739936
DEBUG:root:[ Iteration 198 ] Training loss: 0.0764858
DEBUG:root:[ Iteration 200 ] Test loss: 0.0790605
DEBUG:root:[ Iteration 201 ] Training loss: 0.0660504
DEBUG:root:[ Iteration 204 ] Training loss: 0.0830953
DEBUG:root:[ Iteration 207 ] Training loss: 0.049714
DEBUG:root:[ Iteration 210 ] Training loss: 0.0571683
DEBUG:root:[ Iteration 213 ] Training loss: 0.0557242
DEBUG:root:[ Iteration 216 ] Training loss: 0.0564071
DEBUG:root:[ Iteration 219 ] Training loss: 0.0572418
DEBUG:root:[ Iteration 220 ] Test loss: 0.0659098
DEBUG:root:[ Iteration 222 ] Training loss: 0.0530179
DEBUG:root:[ Iteration 225 ] Training loss: 0.0666859
DEBUG:root:[ Iteration 228 ] Training loss: 0.0526933
DEBUG:root:[ Iteration 231 ] Training loss: 0.0605533
DEBUG:root:[ Iteration 234 ] Training loss: 0.0437137
DEBUG:root:[ Iteration 237 ] Training loss: 0.0557121
DEBUG:root:[ Iteration 240 ] Training loss: 0.0364152
DEBUG:root:[ Iteration 240 ] Test loss: 0.0600001
DEBUG:root:[ Iteration 243 ] Training loss: 0.0516541
DEBUG:root:[ Iteration 246 ] Training loss: 0.0472785
DEBUG:root:[ Iteration 249 ] Training loss: 0.0401811
DEBUG:root:[ Iteration 252 ] Training loss: 0.0373997
DEBUG:root:[ Iteration 255 ] Training loss: 0.0529321
DEBUG:root:[ Iteration 258 ] Training loss: 0.0451247
DEBUG:root:[ Iteration 260 ] Test loss: 0.0545772
DEBUG:root:[ Iteration 261 ] Training loss: 0.0385618
DEBUG:root:[ Iteration 264 ] Training loss: 0.0432495
DEBUG:root:[ Iteration 267 ] Training loss: 0.0713842
DEBUG:root:[ Iteration 270 ] Training loss: 0.0423723
DEBUG:root:[ Iteration 273 ] Training loss: 0.0475728
DEBUG:root:[ Iteration 276 ] Training loss: 0.0469085
DEBUG:root:[ Iteration 279 ] Training loss: 0.0493162
DEBUG:root:[ Iteration 280 ] Test loss: 0.0503002
DEBUG:root:[ Iteration 282 ] Training loss: 0.049684
DEBUG:root:[ Iteration 285 ] Training loss: 0.0447109
DEBUG:root:[ Iteration 288 ] Training loss: 0.0387935
DEBUG:root:[ Iteration 291 ] Training loss: 0.04009
DEBUG:root:[ Iteration 294 ] Training loss: 0.0317064
DEBUG:root:[ Iteration 297 ] Training loss: 0.0471319
DEBUG:root:[ Iteration 300 ] Training loss: 0.054459
DEBUG:root:[ Iteration 300 ] Test loss: 0.0490678
DEBUG:root:[ Iteration 303 ] Training loss: 0.0460726
DEBUG:root:[ Iteration 306 ] Training loss: 0.0366563
DEBUG:root:[ Iteration 309 ] Training loss: 0.049624
DEBUG:root:[ Iteration 312 ] Training loss: 0.0343797
DEBUG:root:[ Iteration 315 ] Training loss: 0.0473633
DEBUG:root:[ Iteration 318 ] Training loss: 0.0462595
DEBUG:root:[ Iteration 320 ] Test loss: 0.0461673
DEBUG:root:[ Iteration 321 ] Training loss: 0.0429522
DEBUG:root:[ Iteration 324 ] Training loss: 0.0546659
DEBUG:root:[ Iteration 327 ] Training loss: 0.0439583
DEBUG:root:[ Iteration 330 ] Training loss: 0.0330911
DEBUG:root:[ Iteration 333 ] Training loss: 0.0352079
DEBUG:root:[ Iteration 336 ] Training loss: 0.0291624
DEBUG:root:[ Iteration 339 ] Training loss: 0.043948
DEBUG:root:[ Iteration 340 ] Test loss: 0.04453
DEBUG:root:[ Iteration 342 ] Training loss: 0.0273318
DEBUG:root:[ Iteration 345 ] Training loss: 0.0315874
DEBUG:root:[ Iteration 348 ] Training loss: 0.0416759
DEBUG:root:[ Iteration 351 ] Training loss: 0.0362428
DEBUG:root:[ Iteration 354 ] Training loss: 0.0287341
DEBUG:root:[ Iteration 357 ] Training loss: 0.0329103
DEBUG:root:[ Iteration 360 ] Training loss: 0.0321243
DEBUG:root:[ Iteration 360 ] Test loss: 0.0435929
DEBUG:root:[ Iteration 363 ] Training loss: 0.0430263
DEBUG:root:[ Iteration 366 ] Training loss: 0.0387153
DEBUG:root:[ Iteration 369 ] Training loss: 0.0390815
DEBUG:root:[ Iteration 372 ] Training loss: 0.0347883
DEBUG:root:[ Iteration 375 ] Training loss: 0.0327425
DEBUG:root:[ Iteration 378 ] Training loss: 0.0373526
DEBUG:root:[ Iteration 380 ] Test loss: 0.0425099
DEBUG:root:[ Iteration 381 ] Training loss: 0.0367105
DEBUG:root:[ Iteration 384 ] Training loss: 0.0382504
DEBUG:root:[ Iteration 387 ] Training loss: 0.0450618
DEBUG:root:[ Iteration 390 ] Training loss: 0.0377514
DEBUG:root:[ Iteration 393 ] Training loss: 0.0347891
DEBUG:root:[ Iteration 396 ] Training loss: 0.0357839
DEBUG:root:[ Iteration 399 ] Training loss: 0.03892
DEBUG:root:[ Iteration 400 ] Test loss: 0.0418156
DEBUG:root:[ Iteration 402 ] Training loss: 0.0363078
DEBUG:root:[ Iteration 405 ] Training loss: 0.0393772
DEBUG:root:[ Iteration 408 ] Training loss: 0.0368999
DEBUG:root:[ Iteration 411 ] Training loss: 0.0311405
DEBUG:root:[ Iteration 414 ] Training loss: 0.024189
DEBUG:root:[ Iteration 417 ] Training loss: 0.0373591
DEBUG:root:[ Iteration 420 ] Training loss: 0.0402944
DEBUG:root:[ Iteration 420 ] Test loss: 0.0412325
DEBUG:root:[ Iteration 423 ] Training loss: 0.0425528
DEBUG:root:[ Iteration 426 ] Training loss: 0.0358892
DEBUG:root:[ Iteration 429 ] Training loss: 0.0410053
DEBUG:root:[ Iteration 432 ] Training loss: 0.035756
DEBUG:root:[ Iteration 435 ] Training loss: 0.0379651
DEBUG:root:[ Iteration 438 ] Training loss: 0.0312154
DEBUG:root:[ Iteration 440 ] Test loss: 0.0401573
DEBUG:root:[ Iteration 441 ] Training loss: 0.0243349
DEBUG:root:[ Iteration 444 ] Training loss: 0.0282082
DEBUG:root:[ Iteration 447 ] Training loss: 0.0280387
DEBUG:root:[ Iteration 450 ] Training loss: 0.0382687
DEBUG:root:[ Iteration 453 ] Training loss: 0.0451492
DEBUG:root:[ Iteration 456 ] Training loss: 0.0336381
DEBUG:root:[ Iteration 459 ] Training loss: 0.028943
DEBUG:root:[ Iteration 460 ] Test loss: 0.0401563
DEBUG:root:[ Iteration 462 ] Training loss: 0.0308416
DEBUG:root:[ Iteration 465 ] Training loss: 0.0396925
DEBUG:root:[ Iteration 468 ] Training loss: 0.0378415
DEBUG:root:[ Iteration 471 ] Training loss: 0.0388889
DEBUG:root:[ Iteration 474 ] Training loss: 0.0342518
DEBUG:root:[ Iteration 477 ] Training loss: 0.0424117
DEBUG:root:[ Iteration 480 ] Training loss: 0.0452619
DEBUG:root:[ Iteration 480 ] Test loss: 0.0392254
DEBUG:root:[ Iteration 483 ] Training loss: 0.0246053
DEBUG:root:[ Iteration 486 ] Training loss: 0.0308257
DEBUG:root:[ Iteration 489 ] Training loss: 0.0391715
DEBUG:root:[ Iteration 492 ] Training loss: 0.0396978
DEBUG:root:[ Iteration 495 ] Training loss: 0.0376071
DEBUG:root:[ Iteration 498 ] Training loss: 0.025273
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_16h25m13s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.891016
DEBUG:root:[ Iteration 0 ] Test loss: 0.874817
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_22h54m29s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.781281
DEBUG:root:[ Iteration 0 ] Test loss: 0.877457
DEBUG:root:[ Iteration 3 ] Training loss: 0.394529
DEBUG:root:[ Iteration 6 ] Training loss: 0.428868
DEBUG:root:[ Iteration 9 ] Training loss: 0.359555
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net3/model.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.381083
DEBUG:root:[ Iteration 0 ] Test loss: 0.379902
DEBUG:root:[ Iteration 3 ] Training loss: 0.403279
DEBUG:root:[ Iteration 6 ] Training loss: 0.386866
DEBUG:root:[ Iteration 9 ] Training loss: 0.395296
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net3/model.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.378684
DEBUG:root:[ Iteration 0 ] Training loss: 0.392857
DEBUG:root:[ Iteration 0 ] Test loss: 0.379902
DEBUG:root:[ Iteration 3 ] Training loss: 0.396278
DEBUG:root:[ Iteration 6 ] Training loss: 0.380332
DEBUG:root:[ Iteration 9 ] Training loss: 0.402317
DEBUG:root:[ Iteration 12 ] Training loss: 0.401563
DEBUG:root:[ Iteration 15 ] Training loss: 0.379624
DEBUG:root:[ Iteration 18 ] Training loss: 0.399997
DEBUG:root:[ Iteration 20 ] Test loss: 0.379902
DEBUG:root:[ Iteration 21 ] Training loss: 0.387741
DEBUG:root:[ Iteration 24 ] Training loss: 0.380973
DEBUG:root:[ Iteration 27 ] Training loss: 0.372072
DEBUG:root:[ Iteration 30 ] Training loss: 0.397409
DEBUG:root:[ Iteration 33 ] Training loss: 0.386918
DEBUG:root:[ Iteration 36 ] Training loss: 0.418943
DEBUG:root:[ Iteration 39 ] Training loss: 0.394727
DEBUG:root:[ Iteration 40 ] Test loss: 0.379902
DEBUG:root:[ Iteration 42 ] Training loss: 0.385382
DEBUG:root:[ Iteration 45 ] Training loss: 0.368666
DEBUG:root:[ Iteration 48 ] Training loss: 0.395853
DEBUG:root:[ Iteration 51 ] Training loss: 0.401367
DEBUG:root:[ Iteration 54 ] Training loss: 0.396792
DEBUG:root:[ Iteration 57 ] Training loss: 0.400508
DEBUG:root:[ Iteration 60 ] Training loss: 0.371607
DEBUG:root:[ Iteration 60 ] Test loss: 0.379902
DEBUG:root:[ Iteration 63 ] Training loss: 0.384042
DEBUG:root:[ Iteration 66 ] Training loss: 0.392211
DEBUG:root:[ Iteration 69 ] Training loss: 0.399246
DEBUG:root:[ Iteration 72 ] Training loss: 0.380614
DEBUG:root:[ Iteration 75 ] Training loss: 0.382057
DEBUG:root:[ Iteration 78 ] Training loss: 0.384721
DEBUG:root:[ Iteration 80 ] Test loss: 0.379902
DEBUG:root:[ Iteration 81 ] Training loss: 0.379629
DEBUG:root:[ Iteration 84 ] Training loss: 0.398275
DEBUG:root:[ Iteration 87 ] Training loss: 0.394961
DEBUG:root:[ Iteration 90 ] Training loss: 0.385686
DEBUG:root:[ Iteration 93 ] Training loss: 0.393177
DEBUG:root:[ Iteration 96 ] Training loss: 0.382341
DEBUG:root:[ Iteration 99 ] Training loss: 0.383003
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net3/model.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.859466
DEBUG:root:[ Iteration 3 ] Training loss: 0.826163
DEBUG:root:[ Iteration 6 ] Training loss: 0.814369
DEBUG:root:[ Iteration 9 ] Training loss: 0.808617
DEBUG:root:[ Iteration 12 ] Training loss: 0.851344
DEBUG:root:[ Iteration 15 ] Training loss: 0.844975
DEBUG:root:[ Iteration 18 ] Training loss: 0.849023
DEBUG:root:[ Iteration 0 ] Training loss: 0.854404
DEBUG:root:[ Iteration 3 ] Training loss: 0.817435
DEBUG:root:[ Iteration 6 ] Training loss: 0.841863
DEBUG:root:[ Iteration 9 ] Training loss: 0.787435
DEBUG:root:[ Iteration 12 ] Training loss: 0.81702
DEBUG:root:[ Iteration 15 ] Training loss: 0.85471
DEBUG:root:[ Iteration 18 ] Training loss: 0.370904
DEBUG:root:[ Iteration 20 ] Test loss: 0.379861
DEBUG:root:[ Iteration 21 ] Training loss: 0.383517
DEBUG:root:[ Iteration 24 ] Training loss: 0.381714
DEBUG:root:[ Iteration 27 ] Training loss: 0.398067
DEBUG:root:[ Iteration 30 ] Training loss: 0.39056
DEBUG:root:[ Iteration 33 ] Training loss: 0.378755
DEBUG:root:[ Iteration 36 ] Training loss: 0.399528
DEBUG:root:[ Iteration 39 ] Training loss: 0.389341
DEBUG:root:[ Iteration 40 ] Test loss: 0.379902
DEBUG:root:[ Iteration 42 ] Training loss: 0.400721
DEBUG:root:[ Iteration 45 ] Training loss: 0.383196
DEBUG:root:[ Iteration 48 ] Training loss: 0.374443
DEBUG:root:[ Iteration 51 ] Training loss: 0.389439
DEBUG:root:[ Iteration 54 ] Training loss: 0.402819
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_23h41m50s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.393079
DEBUG:root:[ Iteration 3 ] Training loss: 0.409521
DEBUG:root:[ Iteration 6 ] Training loss: 0.388433
DEBUG:root:[ Iteration 9 ] Training loss: 0.376555
DEBUG:root:[ Iteration 12 ] Training loss: 0.385664
DEBUG:root:[ Iteration 15 ] Training loss: 0.379285
DEBUG:root:[ Iteration 18 ] Training loss: 0.385981
DEBUG:root:[ Iteration 0 ] Training loss: 0.394069
DEBUG:root:[ Iteration 3 ] Training loss: 0.389083
DEBUG:root:[ Iteration 6 ] Training loss: 0.370767
DEBUG:root:[ Iteration 9 ] Training loss: 0.387078
DEBUG:root:[ Iteration 12 ] Training loss: 0.394623
DEBUG:root:[ Iteration 15 ] Training loss: 0.383029
DEBUG:root:[ Iteration 18 ] Training loss: 0.370587
DEBUG:root:[ Iteration 0 ] Training loss: 0.398996
DEBUG:root:[ Iteration 3 ] Training loss: 0.395596
DEBUG:root:[ Iteration 6 ] Training loss: 0.396679
DEBUG:root:[ Iteration 9 ] Training loss: 0.381423
DEBUG:root:[ Iteration 12 ] Training loss: 0.386202
DEBUG:root:[ Iteration 15 ] Training loss: 0.389952
DEBUG:root:[ Iteration 18 ] Training loss: 0.377865
DEBUG:root:[ Iteration 20 ] Test loss: 0.38646
DEBUG:root:[ Iteration 21 ] Training loss: 0.40119
DEBUG:root:[ Iteration 24 ] Training loss: 0.408048
DEBUG:root:[ Iteration 27 ] Training loss: 0.38226
DEBUG:root:[ Iteration 30 ] Training loss: 0.38163
DEBUG:root:[ Iteration 33 ] Training loss: 0.395161
DEBUG:root:[ Iteration 36 ] Training loss: 0.403721
DEBUG:root:[ Iteration 39 ] Training loss: 0.38109
DEBUG:root:[ Iteration 40 ] Test loss: 0.379106
DEBUG:root:[ Iteration 42 ] Training loss: 0.396166
DEBUG:root:[ Iteration 45 ] Training loss: 0.384203
DEBUG:root:[ Iteration 48 ] Training loss: 0.39702
DEBUG:root:[ Iteration 51 ] Training loss: 0.383372
DEBUG:root:[ Iteration 54 ] Training loss: 0.402644
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/net3/model.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.463775
DEBUG:root:[ Iteration 3 ] Training loss: 0.346501
DEBUG:root:[ Iteration 6 ] Training loss: 0.386291
DEBUG:root:[ Iteration 9 ] Training loss: 0.387325
DEBUG:root:[ Iteration 12 ] Training loss: 0.342434
DEBUG:root:[ Iteration 15 ] Training loss: 0.325191
DEBUG:root:[ Iteration 18 ] Training loss: 0.313735
DEBUG:root:[ Iteration 20 ] Test loss: 0.297809
DEBUG:root:[ Iteration 21 ] Training loss: 0.321776
DEBUG:root:[ Iteration 24 ] Training loss: 0.222522
DEBUG:root:[ Iteration 27 ] Training loss: 0.201206
DEBUG:root:[ Iteration 30 ] Training loss: 0.199184
DEBUG:root:[ Iteration 33 ] Training loss: 0.138593
DEBUG:root:[ Iteration 36 ] Training loss: 0.107188
DEBUG:root:[ Iteration 39 ] Training loss: 0.0781815
DEBUG:root:[ Iteration 40 ] Test loss: 0.0712859
DEBUG:root:[ Iteration 42 ] Training loss: 0.0766011
DEBUG:root:[ Iteration 45 ] Training loss: 0.0753201
DEBUG:root:[ Iteration 48 ] Training loss: 0.0584413
DEBUG:root:[ Iteration 51 ] Training loss: 0.06884
DEBUG:root:[ Iteration 54 ] Training loss: 0.0594037
DEBUG:root:[ Iteration 57 ] Training loss: 0.0517344
DEBUG:root:[ Iteration 60 ] Training loss: 0.0435588
DEBUG:root:[ Iteration 63 ] Training loss: 0.0484299
DEBUG:root:[ Iteration 66 ] Training loss: 0.055868
DEBUG:root:[ Iteration 69 ] Training loss: 0.0435221
DEBUG:root:[ Iteration 72 ] Training loss: 0.0478923
DEBUG:root:[ Iteration 75 ] Training loss: 0.0490214
DEBUG:root:[ Iteration 78 ] Training loss: 0.0399528
DEBUG:root:[ Iteration 80 ] Test loss: 0.0427314
DEBUG:root:[ Iteration 81 ] Training loss: 0.0493494
DEBUG:root:[ Iteration 84 ] Training loss: 0.0413373
DEBUG:root:[ Iteration 87 ] Training loss: 0.0475901
DEBUG:root:[ Iteration 90 ] Training loss: 0.0504492
DEBUG:root:[ Iteration 93 ] Training loss: 0.0313855
DEBUG:root:[ Iteration 96 ] Training loss: 0.0400219
DEBUG:root:[ Iteration 99 ] Training loss: 0.0479415
DEBUG:root:[ Iteration 100 ] Test loss: 0.0343904
DEBUG:root:[ Iteration 102 ] Training loss: 0.0352243
DEBUG:root:[ Iteration 105 ] Training loss: 0.0301307
DEBUG:root:[ Iteration 108 ] Training loss: 0.0382441
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_23h53m29s.ckpt
DEBUG:root:Optimization done.
DEBUG:root:[ Iteration 0 ] Training loss: 0.66934
DEBUG:root:[ Iteration 3 ] Training loss: 0.442604
DEBUG:root:[ Iteration 6 ] Training loss: 0.483356
DEBUG:root:[ Iteration 9 ] Training loss: 0.484019
DEBUG:root:[ Iteration 12 ] Training loss: 0.505924
DEBUG:root:[ Iteration 15 ] Training loss: 0.482236
DEBUG:root:[ Iteration 18 ] Training loss: 0.494066
DEBUG:root:[ Iteration 20 ] Test loss: 0.507288
DEBUG:root:[ Iteration 21 ] Training loss: 0.515574
DEBUG:root:[ Iteration 24 ] Training loss: 0.468291
DEBUG:root:[ Iteration 27 ] Training loss: 0.496129
DEBUG:root:[ Iteration 30 ] Training loss: 0.49319
DEBUG:root:[ Iteration 33 ] Training loss: 0.503052
DEBUG:root:[ Iteration 36 ] Training loss: 0.482517
DEBUG:root:[ Iteration 39 ] Training loss: 0.517775
DEBUG:root:[ Iteration 40 ] Test loss: 0.511331
DEBUG:root:[ Iteration 42 ] Training loss: 0.518159
DEBUG:root:[ Iteration 45 ] Training loss: 0.485802
DEBUG:root:[ Iteration 48 ] Training loss: 0.4894
DEBUG:root:[ Iteration 51 ] Training loss: 0.489646
DEBUG:root:[ Iteration 54 ] Training loss: 0.519943
DEBUG:root:Saving...
DEBUG:root:Saved model to /home/annal/Izzy/vision_amt/Net/tensor/./net3/net3_02-12-2016_23h58m44s.ckpt
DEBUG:root:Optimization done.
